"""
행동인식 헬퍼 클래스
3-tier fallback 전략: HuggingFace Transformers → OpenCV → Simulation
"""

import numpy as np
from PIL import Image
import streamlit as st
from typing import Optional, List, Dict, Tuple, Any, Union
import warnings
import sys
import os

# BaseImageProcessor import
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from core.base_processor import BaseImageProcessor


class VideoHelper(BaseImageProcessor):
    """
    비디오 행동인식 헬퍼 클래스
    - 1순위: HuggingFace Transformers (transformers 패키지 + VideoMAE/TimeSformer 모델)
    - 2순위: OpenCV only (비디오 처리, Optical Flow만 가능, ML 모델 없음)
    - 3순위: Simulation mode (기본 비디오 처리 시뮬레이션)
    """

    def __init__(self):
        """
        VideoHelper 초기화
        - 3-tier fallback으로 사용 가능한 모드 감지
        - 디바이스 감지 (CPU/GPU)
        """
        super().__init__()
        self.mode = None  # 'transformers', 'opencv', 'simulation'
        self.device = None  # 'cuda', 'cpu', None
        self.model = None
        self.processor = None
        self.pipeline = None

        self._initialize()

    def _initialize(self):
        """
        3-tier fallback으로 초기화
        """
        # Tier 1: Try HuggingFace Transformers
        if self._try_transformers():
            self.mode = 'transformers'
            st.success("✅ 행동인식 준비 완료 (HuggingFace Transformers)")
            return

        # Tier 2: Try OpenCV only
        if self._try_opencv():
            self.mode = 'opencv'
            st.info("ℹ️ OpenCV 모드 활성화 (비디오 처리 가능, ML 모델 미사용)\n\n"
                   "행동 분류 기능을 사용하려면:\n"
                   "```bash\n"
                   "pip install transformers torch\n"
                   "```")
            return

        # Tier 3: Fallback to simulation
        self.mode = 'simulation'
        st.warning("⚠️ 시뮬레이션 모드 (실제 비디오 처리 미사용)\n\n"
                  "실제 기능을 사용하려면:\n"
                  "```bash\n"
                  "pip install opencv-python transformers torch\n"
                  "```")

    def _try_transformers(self) -> bool:
        """
        HuggingFace Transformers로 로드 시도
        VideoMAE, TimeSformer, X-CLIP 등 비디오 모델 지원
        """
        try:
            import transformers
            import torch

            # 디바이스 감지
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            if self.device == "cpu":
                st.info("ℹ️ GPU를 사용할 수 없어 CPU로 실행합니다. (비디오 처리는 느릴 수 있음)")

            # 필요한 모듈이 있는지만 확인 (실제 모델은 나중에 로드)
            return True

        except ImportError:
            return False
        except Exception as e:
            st.error(f"Transformers 초기화 실패: {e}")
            return False

    def _try_opencv(self) -> bool:
        """
        OpenCV 사용 가능 여부 확인
        비디오 처리와 Optical Flow는 가능하지만 ML 모델은 없음
        """
        try:
            import cv2
            return True
        except ImportError:
            return False
        except Exception as e:
            return False

    def _detect_device(self) -> Optional[str]:
        """
        CUDA 디바이스 감지
        Returns:
            'cuda', 'cpu', or None
        """
        try:
            import torch
            return "cuda" if torch.cuda.is_available() else "cpu"
        except ImportError:
            return None

    def get_mode(self) -> str:
        """
        현재 동작 모드 반환
        Returns:
            'transformers', 'opencv', 'simulation'
        """
        return self.mode

    def get_device(self) -> Optional[str]:
        """
        현재 디바이스 반환
        Returns:
            'cuda', 'cpu', or None
        """
        return self.device

    def is_available(self, feature: str) -> bool:
        """
        특정 기능 사용 가능 여부 확인

        Args:
            feature: 'video_processing', 'optical_flow', 'action_classification'

        Returns:
            bool: 기능 사용 가능 여부
        """
        if feature == 'video_processing':
            return self.mode in ['transformers', 'opencv']
        elif feature == 'optical_flow':
            return self.mode in ['transformers', 'opencv']
        elif feature == 'action_classification':
            return self.mode == 'transformers'
        else:
            return False


@st.cache_resource
def get_video_helper() -> VideoHelper:
    """
    캐시된 VideoHelper 인스턴스 반환 (싱글톤 패턴)

    Returns:
        VideoHelper: 캐시된 헬퍼 인스턴스
    """
    return VideoHelper()
