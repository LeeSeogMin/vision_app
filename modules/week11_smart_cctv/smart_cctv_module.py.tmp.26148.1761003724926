"""
Week 11: Smart CCTV Monitoring System
êµìœ¡ìš© ìŠ¤ë§ˆíŠ¸ CCTV ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

Author: Smart Vision Team
Date: 2025-01-20
"""

import streamlit as st
import cv2
import numpy as np
from pathlib import Path
import sys
from typing import List, Dict, Tuple, Optional
import time
from collections import deque, defaultdict
import csv
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from core.base_processor import BaseImageProcessor


class SmartCCTVModule(BaseImageProcessor):
    """
    ìŠ¤ë§ˆíŠ¸ CCTV ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë©”ì¸ ëª¨ë“ˆ

    êµìœ¡ìš©ìœ¼ë¡œ ê°„ì†Œí™”ëœ CCTV ì‹œìŠ¤í…œ:
    - YOLOv8 ê°ì²´ íƒì§€
    - ByteTrack ì¶”ì 
    - ROI ê¸°ë°˜ ì´ë²¤íŠ¸ ê°ì§€
    - íˆíŠ¸ë§µ ë¶„ì„
    - ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ
    """

    def __init__(self):
        super().__init__()
        self.name = "Week 11: Smart CCTV System"

        # ì¶”ì  ê´€ë ¨ ìƒíƒœ
        if 'tracks' not in st.session_state:
            st.session_state.tracks = {}  # {track_id: track_info}
        if 'next_track_id' not in st.session_state:
            st.session_state.next_track_id = 1
        if 'heatmap' not in st.session_state:
            st.session_state.heatmap = None
        if 'event_log' not in st.session_state:
            st.session_state.event_log = []
        if 'roi_points' not in st.session_state:
            st.session_state.roi_points = []

    def render(self):
        """ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ - 5ê°œ íƒ­"""
        st.title("ğŸ¥ Week 11: Smart CCTV Monitoring System")

        st.markdown("""
        ### êµìœ¡ìš© ìŠ¤ë§ˆíŠ¸ CCTV ì‹œìŠ¤í…œ

        **í•µì‹¬ ê¸°ëŠ¥**:
        - ğŸ¯ YOLOv8 ì‹¤ì‹œê°„ íƒì§€ (ì‚¬ëŒ/ì°¨ëŸ‰/ë™ë¬¼)
        - ğŸ” ByteTrack ê°ì²´ ì¶”ì 
        - ğŸš¨ ROI ê¸°ë°˜ ì´ë²¤íŠ¸ ê°ì§€ (ì¹¨ì…/ë°°íšŒ)
        - ğŸ”¥ íˆíŠ¸ë§µ ë¶„ì„ (ê²½ë¡œ ì‹œê°í™”)
        - ğŸ“Š ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ (í†µê³„/ë¡œê·¸)
        """)

        # 6ê°œ íƒ­ ìƒì„±
        tabs = st.tabs([
            "ğŸ“š 1. CCTV ì‹œìŠ¤í…œ ì´ë¡ ",
            "ğŸ¯ 2. íƒì§€ ë° ì¶”ì ",
            "ğŸš¨ 3. ROI ë° ì´ë²¤íŠ¸",
            "ğŸ”¥ 4. íˆíŠ¸ë§µ ë¶„ì„",
            "ğŸ“Š 5. ëŒ€ì‹œë³´ë“œ",
            "ğŸ® 6. ì‹¤ìŠµ ì‹œë®¬ë ˆì´ì…˜"
        ])

        with tabs[0]:
            self.render_theory()

        with tabs[1]:
            self.render_detection_tracking()

        with tabs[2]:
            self.render_roi_events()

        with tabs[3]:
            self.render_heatmap()

        with tabs[4]:
            self.render_dashboard()

        with tabs[5]:
            self.render_simulation()

    def render_theory(self):
        """Tab 1: CCTV ì‹œìŠ¤í…œ ì´ë¡ """
        st.header("ğŸ“š ìŠ¤ë§ˆíŠ¸ CCTV ì‹œìŠ¤í…œ ì´ë¡ ")

        st.markdown("---")

        # 1. ì „í†µ CCTV vs AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ CCTV
        st.subheader("1ï¸âƒ£ ì „í†µ CCTV vs AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ CCTV")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            #### ğŸ¬ ì „í†µ CCTV

            **íŠ¹ì§•**:
            - ì˜ìƒ ë…¹í™” ë° ì €ì¥
            - ì‚¬ëŒì´ ì§ì ‘ ëª¨ë‹ˆí„°ë§
            - ì‚¬í›„ í™•ì¸ ì¤‘ì‹¬
            - ë‹¨ìˆœ ì›€ì§ì„ ê°ì§€

            **í•œê³„**:
            - 24ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¸ë ¥ í•„ìš”
            - ì‚¬ê±´ ë°œìƒ í›„ í™•ì¸
            - ì •í™•í•œ ë¶„ì„ ì–´ë ¤ì›€
            - ëŒ€ëŸ‰ ì˜ìƒ ê²€ìƒ‰ ì‹œê°„ ì†Œìš”

            **í™œìš©**:
            - ê¸°ë³¸ ë³´ì•ˆ
            - ì¦ê±° ìë£Œ
            - ì‚¬í›„ ì¡°ì‚¬
            """)

        with col2:
            st.markdown("""
            #### ğŸ¤– AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ CCTV

            **íŠ¹ì§•**:
            - ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë° ì¶”ì 
            - ìë™ ì´ë²¤íŠ¸ ê°ì§€
            - ì‚¬ì „ ì˜ˆë°© ì¤‘ì‹¬
            - ì§€ëŠ¥í˜• ì•Œë¦¼ ì‹œìŠ¤í…œ

            **ì¥ì **:
            - ì‹¤ì‹œê°„ ìë™ ëª¨ë‹ˆí„°ë§
            - ì¦‰ì‹œ ì´ë²¤íŠ¸ ì•Œë¦¼
            - ì •í™•í•œ ê°ì²´ ì¸ì‹
            - ë¹ ë¥¸ ê²€ìƒ‰ ë° ë¶„ì„

            **í™œìš©**:
            - ì¹¨ì… ê°ì§€
            - êµí†µ ë¶„ì„
            - êµ°ì¤‘ ê´€ë¦¬
            - ì‘ì—…ì¥ ì•ˆì „
            """)

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: AI ê¸°ë°˜ CCTVëŠ” 'ì‚¬í›„ í™•ì¸'ì—ì„œ 'ì‚¬ì „ ì˜ˆë°©'ìœ¼ë¡œ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜")

        # 2. ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ
        st.markdown("---")
        st.subheader("2ï¸âƒ£ ìŠ¤ë§ˆíŠ¸ CCTV ì‹œìŠ¤í…œ êµ¬ì„±")

        st.code("""
ìŠ¤ë§ˆíŠ¸ CCTV ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ì…ë ¥ ê³„ì¸µ (Input Layer)                 â”‚
â”‚  â€¢ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ (íŒŒì¼/ì›¹ìº /IPì¹´ë©”ë¼)             â”‚
â”‚  â€¢ í”„ë ˆì„ ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™”)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        íƒì§€ ê³„ì¸µ (Detection Layer)               â”‚
â”‚  â€¢ YOLOv8: ì‚¬ëŒ, ì°¨ëŸ‰, ë™ë¬¼ íƒì§€                 â”‚
â”‚  â€¢ ë°”ìš´ë”© ë°•ìŠ¤ + ì‹ ë¢°ë„ ì ìˆ˜                     â”‚
â”‚  â€¢ í´ë˜ìŠ¤ í•„í„°ë§                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ì¶”ì  ê³„ì¸µ (Tracking Layer)                â”‚
â”‚  â€¢ ByteTrack: ID í• ë‹¹ ë° ì¶”ì                     â”‚
â”‚  â€¢ Kalman Filter: ìœ„ì¹˜ ì˜ˆì¸¡                      â”‚
â”‚  â€¢ ê¶¤ì  ê¸°ë¡ (Trajectory)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ë¶„ì„ ê³„ì¸µ (Analysis Layer)                â”‚
â”‚  â€¢ ROI êµì°¨ ê²€ì‚¬ (ì¹¨ì… ê°ì§€)                     â”‚
â”‚  â€¢ ë°°íšŒ ê°ì§€ (ì²´ë¥˜ ì‹œê°„)                         â”‚
â”‚  â€¢ íˆíŠ¸ë§µ ìƒì„± (ì´ë™ ê²½ë¡œ)                       â”‚
â”‚  â€¢ í†µê³„ ì§‘ê³„ (ì¹´ìš´íŒ…)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ì¶œë ¥ ê³„ì¸µ (Output Layer)                  â”‚
â”‚  â€¢ ì‹œê°í™” (ë°”ìš´ë”© ë°•ìŠ¤, ê¶¤ì , ROI)               â”‚
â”‚  â€¢ ì´ë²¤íŠ¸ ë¡œê·¸ (CSV)                             â”‚
â”‚  â€¢ ì•Œë¦¼ (ì½˜ì†”/ì´ë©”ì¼/SMS)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """, language="text")

        # 3. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
        st.markdown("---")
        st.subheader("3ï¸âƒ£ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜")

        st.markdown("#### ğŸ“Š ê°ì²´ íƒì§€ ëª¨ë¸ ë¹„êµ")

        comparison_data = {
            "ëª¨ë¸": ["YOLOv8n", "YOLOv8s", "YOLOv8m", "Faster R-CNN", "SSD"],
            "íŒŒë¼ë¯¸í„°": ["3.2M", "11.2M", "25.9M", "41.8M", "23.5M"],
            "ì •í™•ë„ (mAP)": ["37.3%", "44.9%", "50.2%", "42.0%", "25.1%"],
            "FPS (CPU)": ["~25", "~15", "~8", "~5", "~10"],
            "FPS (GPU)": ["~140", "~90", "~60", "~20", "~45"],
            "ìš©ë„": ["ì‹¤ì‹œê°„", "ê· í˜•", "ì •í™•ë„", "ì •ë°€", "ê²½ëŸ‰"]
        }

        st.table(comparison_data)

        st.info("ğŸ’¡ **êµìœ¡ ì„ íƒ**: YOLOv8n (nano) - ë¹ ë¥¸ ì†ë„ + ì ì ˆí•œ ì •í™•ë„")

        st.markdown("#### ğŸ” ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ ë¹„êµ")

        tracking_data = {
            "ì•Œê³ ë¦¬ì¦˜": ["ByteTrack", "DeepSORT", "SORT", "CenterTrack"],
            "ì¶”ì  ë°©ì‹": ["Detection-based", "Detection + ReID", "Detection-based", "Detection-based"],
            "ì •í™•ë„": ["â­â­â­â­â­", "â­â­â­â­", "â­â­â­", "â­â­â­â­"],
            "ì†ë„": ["â­â­â­â­â­", "â­â­â­", "â­â­â­â­â­", "â­â­â­â­"],
            "ë³µì¡ë„": ["ì¤‘ê°„", "ë†’ìŒ", "ë‚®ìŒ", "ì¤‘ê°„"],
            "íŠ¹ì§•": ["ê³ ì† + ê³ ì •í™•ë„", "ì™¸í˜• íŠ¹ì§• ì‚¬ìš©", "ë§¤ìš° ê°„ë‹¨", "ì¶”ì  + íƒì§€ ë™ì‹œ"]
        }

        st.table(tracking_data)

        st.info("ğŸ’¡ **êµìœ¡ ì„ íƒ**: ByteTrack (ê°„ì†Œí™”) - ìµœì‹  ì•Œê³ ë¦¬ì¦˜, ë†’ì€ ì„±ëŠ¥")

        # 4. ì£¼ìš” í™œìš© ë¶„ì•¼
        st.markdown("---")
        st.subheader("4ï¸âƒ£ ìŠ¤ë§ˆíŠ¸ CCTV í™œìš© ë¶„ì•¼")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("""
            #### ğŸ¢ ë³´ì•ˆ ë° ì•ˆì „

            - **ì¹¨ì… ê°ì§€**: ê¸ˆì§€ êµ¬ì—­ ì¹¨ì…
            - **ë°°íšŒ ê°ì§€**: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í–‰ë™
            - **í­ë ¥ ê°ì§€**: ì‹¸ì›€, ì“°ëŸ¬ì§
            - **í™”ì¬/ì—°ê¸° ê°ì§€**: ì¬ë‚œ ëŒ€ì‘

            **ì ìš© ì‚¬ë¡€**:
            - ì€í–‰, ê´€ê³µì„œ
            - ì£¼íƒ, ì•„íŒŒíŠ¸
            - ê³µì¥, ì°½ê³ 
            """)

        with col2:
            st.markdown("""
            #### ğŸš— êµí†µ ë° ë„ì‹œ

            - **ì°¨ëŸ‰ ê³„ìˆ˜**: êµí†µëŸ‰ ë¶„ì„
            - **ë¶ˆë²• ì£¼ì •ì°¨**: ìë™ ë‹¨ì†
            - **ì‚¬ê³  ê°ì§€**: ì¦‰ì‹œ ëŒ€ì‘
            - **í˜¼ì¡ë„ ë¶„ì„**: êµí†µ ìµœì í™”

            **ì ìš© ì‚¬ë¡€**:
            - ë„ë¡œ, êµì°¨ë¡œ
            - ì£¼ì°¨ì¥
            - í†¨ê²Œì´íŠ¸
            """)

        with col3:
            st.markdown("""
            #### ğŸ›ï¸ ìƒì—… ë° ë¶„ì„

            - **ê³ ê° ë™ì„ **: ë§¤ì¥ ë°°ì¹˜ ìµœì í™”
            - **ëŒ€ê¸° ì‹œê°„**: ê³„ì‚°ëŒ€ ì¸ë ¥ ë°°ì¹˜
            - **í•«ìŠ¤íŒŸ ë¶„ì„**: ì¸ê¸° êµ¬ì—­ íŒŒì•…
            - **ì¬ê³  ê´€ë¦¬**: ì§„ì—´ëŒ€ ëª¨ë‹ˆí„°ë§

            **ì ìš© ì‚¬ë¡€**:
            - ì†Œë§¤ì , ë§ˆíŠ¸
            - ì‡¼í•‘ëª°
            - ë ˆìŠ¤í† ë‘
            """)

        # 5. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ (ê°„ì†Œí™”)
        st.markdown("---")
        st.subheader("5ï¸âƒ£ êµìœ¡ìš© ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            #### ğŸ’» í•˜ë“œì›¨ì–´

            **ìµœì†Œ ì‚¬ì–‘** (CPU ëª¨ë“œ):
            - CPU: Intel i5 ì´ìƒ
            - RAM: 8GB
            - ì €ì¥ê³µê°„: 5GB
            - ì›¹ìº  ë˜ëŠ” ìƒ˜í”Œ ì˜ìƒ

            **ê¶Œì¥ ì‚¬ì–‘** (GPU ëª¨ë“œ):
            - CPU: Intel i7 ì´ìƒ
            - RAM: 16GB
            - GPU: NVIDIA GTX 1660 (6GB VRAM)
            - ì €ì¥ê³µê°„: 10GB
            """)

        with col2:
            st.markdown("""
            #### ğŸ“¦ ì†Œí”„íŠ¸ì›¨ì–´

            **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬**:
            ```bash
            pip install opencv-python
            pip install ultralytics
            pip install numpy matplotlib
            pip install streamlit plotly
            ```

            **ì„ íƒ ì‚¬í•­**:
            - Google Colab (ë¬´ë£Œ GPU)
            - CUDA Toolkit (ë¡œì»¬ GPU)
            """)

        st.success("""
        âœ… **êµìœ¡ ëª©ì  ê°„ì†Œí™”**:
        - AWS/í´ë¼ìš°ë“œ ë¶ˆí•„ìš” â†’ ë¡œì»¬ ì‹¤í–‰
        - PostgreSQL ë¶ˆí•„ìš” â†’ CSV ë¡œê·¸
        - ë³µì¡í•œ ì¸ì¦ ë¶ˆí•„ìš” â†’ ë‹¨ìˆœ ì‹¤í–‰
        - ê³ ê°€ ì¥ë¹„ ë¶ˆí•„ìš” â†’ ì¼ë°˜ ë…¸íŠ¸ë¶
        """)

    def render_detection_tracking(self):
        """Tab 2: íƒì§€ ë° ì¶”ì """
        st.header("ğŸ¯ íƒì§€ ë° ì¶”ì  (Detection & Tracking)")

        st.markdown("---")

        # YOLOv8 íƒì§€
        st.subheader("1ï¸âƒ£ YOLOv8 ê°ì²´ íƒì§€")

        st.markdown("""
        #### ğŸ¯ YOLOv8 ê°œìš”

        **YOLO (You Only Look Once)**ëŠ” ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ ìµœì‹  ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

        **YOLOv8 íŠ¹ì§•**:
        - **ì†ë„**: ì‹¤ì‹œê°„ ì²˜ë¦¬ (30-140 FPS)
        - **ì •í™•ë„**: COCO ë°ì´í„°ì…‹ 50% mAP
        - **ê²½ëŸ‰í™”**: nano ëª¨ë¸ 3.2M íŒŒë¼ë¯¸í„°
        - **ë‹¤ì–‘ì„±**: n/s/m/l/x 5ê°€ì§€ í¬ê¸°
        """)

        st.code("""
# YOLOv8 ê¸°ë³¸ ì‚¬ìš©ë²•
from ultralytics import YOLO

# 1. ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')  # nano ëª¨ë¸ (ê°€ì¥ ë¹ ë¦„)

# 2. ì¶”ë¡ 
results = model(frame, conf=0.5)  # ì‹ ë¢°ë„ 50% ì´ìƒ

# 3. ê²°ê³¼ ì¶”ì¶œ
for result in results:
    boxes = result.boxes  # ë°”ìš´ë”© ë°•ìŠ¤
    for box in boxes:
        # ì¢Œí‘œ
        x1, y1, x2, y2 = box.xyxy[0]

        # ì‹ ë¢°ë„
        confidence = box.conf[0]

        # í´ë˜ìŠ¤ (0: ì‚¬ëŒ, 2: ì°¨ëŸ‰, ...)
        class_id = int(box.cls[0])

        print(f"Class: {class_id}, Conf: {confidence:.2f}")
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: YOLOv8ì€ í•œ ë²ˆì˜ forward passë¡œ ëª¨ë“  ê°ì²´ íƒì§€ (ë¹ ë¦„)")

        # COCO í´ë˜ìŠ¤
        with st.expander("ğŸ“‹ COCO ë°ì´í„°ì…‹ ì£¼ìš” í´ë˜ìŠ¤ (80ê°œ)"):
            st.code("""
COCO Classes (ì¼ë¶€):
-------------------
0: person (ì‚¬ëŒ)
1: bicycle (ìì „ê±°)
2: car (ì°¨ëŸ‰)
3: motorcycle (ì˜¤í† ë°”ì´)
5: bus (ë²„ìŠ¤)
7: truck (íŠ¸ëŸ­)
14: bird (ìƒˆ)
15: cat (ê³ ì–‘ì´)
16: dog (ê°œ)

# CCTV ìš©ë„ë¡œ í•„í„°ë§
target_classes = [0, 2, 5, 7]  # ì‚¬ëŒ, ì°¨ëŸ‰, ë²„ìŠ¤, íŠ¸ëŸ­
results = model(frame, classes=target_classes)
            """, language="python")

        # ByteTrack ì¶”ì 
        st.markdown("---")
        st.subheader("2ï¸âƒ£ ByteTrack ê°ì²´ ì¶”ì ")

        st.markdown("""
        #### ğŸ” ByteTrack ê°œìš”

        **ByteTrack**ëŠ” 2021ë…„ ì œì•ˆëœ ìµœì‹  ë‹¤ì¤‘ ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

        **í•µì‹¬ ì•„ì´ë””ì–´**:
        1. **High Score Detection**: ì‹ ë¢°ë„ ë†’ì€ íƒì§€ â†’ Track ë§¤ì¹­
        2. **Low Score Detection**: ì‹ ë¢°ë„ ë‚®ì€ íƒì§€ â†’ ê¸°ì¡´ Track ë³µêµ¬
        3. **Kalman Filter**: ìœ„ì¹˜ ì˜ˆì¸¡ìœ¼ë¡œ ê°€ë ¤ì§(occlusion) ì²˜ë¦¬

        **ì¥ì **:
        - ê°€ë ¤ì§„ ê°ì²´ë„ ì¶”ì  ìœ ì§€
        - ë†’ì€ ì •í™•ë„ (MOT17: 80.3% MOTA)
        - ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (30 FPS)
        """)

        st.code("""
# ByteTrack ê°„ì†Œí™” êµ¬í˜„ (êµìœ¡ìš©)
class SimpleByteTrack:
    def __init__(self):
        self.tracks = {}  # {track_id: track_info}
        self.next_id = 1
        self.max_age = 30  # 30í”„ë ˆì„ ë™ì•ˆ ë¯¸íƒì§€ ì‹œ ì‚­ì œ

    def update(self, detections):
        \"\"\"
        detections: List[Dict]
            [{'bbox': [x1,y1,x2,y2], 'conf': 0.9, 'class': 0}, ...]
        \"\"\"

        # 1. ê³ ì‹ ë¢°ë„ íƒì§€ (conf >= 0.5)
        high_dets = [d for d in detections if d['conf'] >= 0.5]

        # 2. ì €ì‹ ë¢°ë„ íƒì§€ (0.1 <= conf < 0.5)
        low_dets = [d for d in detections if 0.1 <= d['conf'] < 0.5]

        # 3. ê³ ì‹ ë¢°ë„ íƒì§€ì™€ ê¸°ì¡´ Track ë§¤ì¹­
        matches, unmatched_dets, unmatched_tracks = self.match(high_dets, self.tracks)

        # 4. ë§¤ì¹­ëœ Track ì—…ë°ì´íŠ¸
        for det_idx, track_id in matches:
            self.tracks[track_id].update(high_dets[det_idx])

        # 5. ë¯¸ë§¤ì¹­ Trackê³¼ ì €ì‹ ë¢°ë„ íƒì§€ ì¬ë§¤ì¹­
        matches2, unmatched_low, still_unmatched = self.match(low_dets, unmatched_tracks)

        for det_idx, track_id in matches2:
            self.tracks[track_id].update(low_dets[det_idx])

        # 6. ìƒˆë¡œìš´ Track ìƒì„±
        for det_idx in unmatched_dets:
            self.tracks[self.next_id] = Track(self.next_id, high_dets[det_idx])
            self.next_id += 1

        # 7. ì˜¤ë˜ëœ Track ì‚­ì œ
        self.remove_old_tracks()

        return self.tracks

    def match(self, detections, tracks):
        \"\"\"IoU ê¸°ë°˜ í—ê°€ë¦¬ì•ˆ ë§¤ì¹­\"\"\"
        if len(detections) == 0 or len(tracks) == 0:
            return [], list(range(len(detections))), list(tracks.keys())

        # IoU í–‰ë ¬ ê³„ì‚°
        iou_matrix = np.zeros((len(detections), len(tracks)))
        track_ids = list(tracks.keys())

        for i, det in enumerate(detections):
            for j, track_id in enumerate(track_ids):
                iou = self.calculate_iou(det['bbox'], tracks[track_id].bbox)
                iou_matrix[i, j] = iou

        # í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ (ê°„ì†Œí™”: greedy matching)
        matches = []
        matched_dets = set()
        matched_tracks = set()

        # IoU 0.5 ì´ìƒë§Œ ë§¤ì¹­
        threshold = 0.5
        while True:
            max_iou = np.max(iou_matrix)
            if max_iou < threshold:
                break

            i, j = np.unravel_index(np.argmax(iou_matrix), iou_matrix.shape)
            matches.append((i, track_ids[j]))
            matched_dets.add(i)
            matched_tracks.add(track_ids[j])

            iou_matrix[i, :] = 0
            iou_matrix[:, j] = 0

        unmatched_dets = [i for i in range(len(detections)) if i not in matched_dets]
        unmatched_tracks = [tid for tid in track_ids if tid not in matched_tracks]

        return matches, unmatched_dets, unmatched_tracks

    def calculate_iou(self, box1, box2):
        \"\"\"IoU (Intersection over Union) ê³„ì‚°\"\"\"
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2

        # êµì§‘í•©
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)

        inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)

        # í•©ì§‘í•©
        area1 = (x1_max - x1_min) * (y1_max - y1_min)
        area2 = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = area1 + area2 - inter_area

        return inter_area / union_area if union_area > 0 else 0

class Track:
    \"\"\"ê°œë³„ Track í´ë˜ìŠ¤\"\"\"
    def __init__(self, track_id, detection):
        self.id = track_id
        self.bbox = detection['bbox']
        self.class_id = detection['class']
        self.confidence = detection['conf']

        # ê¶¤ì 
        self.history = deque(maxlen=30)  # ìµœê·¼ 30í”„ë ˆì„
        center = self.get_center(self.bbox)
        self.history.append(center)

        # ì‹œê°„
        self.age = 0  # Track ìƒì„± í›„ í”„ë ˆì„ ìˆ˜
        self.time_since_update = 0  # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ í›„ í”„ë ˆì„ ìˆ˜

    def update(self, detection):
        \"\"\"íƒì§€ ê²°ê³¼ë¡œ Track ì—…ë°ì´íŠ¸\"\"\"
        self.bbox = detection['bbox']
        self.confidence = detection['conf']

        center = self.get_center(self.bbox)
        self.history.append(center)

        self.age += 1
        self.time_since_update = 0

    def predict(self):
        \"\"\"Kalman Filter ì˜ˆì¸¡ (ê°„ì†Œí™”: ë“±ì† ëª¨ë¸)\"\"\"
        if len(self.history) >= 2:
            # ì†ë„ = ë§ˆì§€ë§‰ 2í”„ë ˆì„ ë³€ìœ„
            velocity = (
                self.history[-1][0] - self.history[-2][0],
                self.history[-1][1] - self.history[-2][1]
            )

            # ì˜ˆì¸¡ ìœ„ì¹˜ = í˜„ì¬ ìœ„ì¹˜ + ì†ë„
            pred_center = (
                self.history[-1][0] + velocity[0],
                self.history[-1][1] + velocity[1]
            )

            # bbox ì—…ë°ì´íŠ¸
            w = self.bbox[2] - self.bbox[0]
            h = self.bbox[3] - self.bbox[1]
            self.bbox = [
                pred_center[0] - w/2,
                pred_center[1] - h/2,
                pred_center[0] + w/2,
                pred_center[1] + h/2
            ]

        self.time_since_update += 1

    @staticmethod
    def get_center(bbox):
        \"\"\"bbox ì¤‘ì‹¬ì \"\"\"
        return ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: ByteTrackì€ ì €ì‹ ë¢°ë„ íƒì§€ë„ í™œìš©í•´ ê°€ë ¤ì§„ ê°ì²´ ì¶”ì ")

        # í†µí•© ì˜ˆì œ
        st.markdown("---")
        st.subheader("3ï¸âƒ£ YOLOv8 + ByteTrack í†µí•©")

        st.code("""
# í†µí•© ì˜ˆì œ (í”„ë ˆì„ë³„ ì²˜ë¦¬)
import cv2
from ultralytics import YOLO

# ì´ˆê¸°í™”
model = YOLO('yolov8n.pt')
tracker = SimpleByteTrack()

# ë¹„ë””ì˜¤ ì²˜ë¦¬
cap = cv2.VideoCapture('surveillance.mp4')

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # 1. YOLOv8 íƒì§€
    results = model(frame, conf=0.3, classes=[0, 2])  # ì‚¬ëŒ, ì°¨ëŸ‰

    # 2. íƒì§€ ê²°ê³¼ ë³€í™˜
    detections = []
    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = float(box.conf[0])
            class_id = int(box.cls[0])

            detections.append({
                'bbox': [x1, y1, x2, y2],
                'conf': conf,
                'class': class_id
            })

    # 3. ByteTrack ì¶”ì 
    tracks = tracker.update(detections)

    # 4. ì‹œê°í™”
    for track_id, track in tracks.items():
        x1, y1, x2, y2 = map(int, track.bbox)

        # ë°”ìš´ë”© ë°•ìŠ¤
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # Track ID
        label = f"ID:{track_id} {track.confidence:.2f}"
        cv2.putText(frame, label, (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # ê¶¤ì 
        if len(track.history) > 1:
            points = np.array(track.history, dtype=np.int32)
            cv2.polylines(frame, [points], False, (0, 0, 255), 2)

    cv2.imshow('Smart CCTV', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
        """, language="python")

        st.success("""
        âœ… **í†µí•© ì²˜ë¦¬ íë¦„**:
        1. YOLOv8ìœ¼ë¡œ í”„ë ˆì„ë§ˆë‹¤ ê°ì²´ íƒì§€
        2. ByteTrackìœ¼ë¡œ íƒì§€ ê²°ê³¼ë¥¼ Trackì— ë§¤ì¹­
        3. ê° Trackì— ê³ ìœ  ID ë¶€ì—¬
        4. ê¶¤ì  ì‹œê°í™”ë¡œ ì´ë™ ê²½ë¡œ í‘œì‹œ
        """)

        # ì„±ëŠ¥ ìµœì í™” íŒ
        st.markdown("---")
        st.subheader("4ï¸âƒ£ ì„±ëŠ¥ ìµœì í™” íŒ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            #### âš¡ ì†ë„ í–¥ìƒ

            ```python
            # 1. ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©
            model = YOLO('yolov8n.pt')  # nano

            # 2. ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ
            results = model(frame, imgsz=640)  # ê¸°ë³¸ 640

            # 3. ë°°ì¹˜ ì²˜ë¦¬ (ë‹¤ì¤‘ ì¹´ë©”ë¼)
            results = model([frame1, frame2], batch=True)

            # 4. GPU ì‚¬ìš©
            model = YOLO('yolov8n.pt').to('cuda')

            # 5. í”„ë ˆì„ ìŠ¤í‚µ
            if frame_count % 2 == 0:  # 2í”„ë ˆì„ë§ˆë‹¤
                results = model(frame)
            ```
            """)

        with col2:
            st.markdown("""
            #### ğŸ¯ ì •í™•ë„ í–¥ìƒ

            ```python
            # 1. ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
            results = model(frame, conf=0.5)  # ê¸°ë³¸ 0.25

            # 2. NMS ì„ê³„ê°’ ì¡°ì •
            results = model(frame, iou=0.5)  # ê¸°ë³¸ 0.7

            # 3. í´ë˜ìŠ¤ í•„í„°ë§
            results = model(frame, classes=[0])  # ì‚¬ëŒë§Œ

            # 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            frame = cv2.GaussianBlur(frame, (5,5), 0)

            # 5. TTA (Test Time Augmentation)
            results = model(frame, augment=True)
            ```
            """)

    def render_roi_events(self):
        """Tab 3: ROI ë° ì´ë²¤íŠ¸ ê°ì§€"""
        st.header("ğŸš¨ ROI ë° ì´ë²¤íŠ¸ ê°ì§€")

        st.markdown("---")

        # ROI ê°œë…
        st.subheader("1ï¸âƒ£ ROI (Region of Interest) ê°œë…")

        st.markdown("""
        #### ğŸ“ ROIë€?

        **ROI (Region of Interest)**ëŠ” ê´€ì‹¬ ì˜ì—­ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

        **CCTVì—ì„œì˜ í™œìš©**:
        - ì¹¨ì… ê¸ˆì§€ êµ¬ì—­ ì„¤ì •
        - ê³„ìˆ˜ ë¼ì¸ (counting line)
        - ì£¼ì°¨ êµ¬ì—­
        - ìœ„í—˜ êµ¬ì—­

        **í‘œí˜„ ë°©ì‹**:
        - **ì‚¬ê°í˜•**: `[x1, y1, x2, y2]`
        - **í´ë¦¬ê³¤**: `[(x1,y1), (x2,y2), (x3,y3), ...]`
        """)

        st.code("""
# ROI ì„¤ì • ì˜ˆì œ
import cv2
import numpy as np

# 1. ì‚¬ê°í˜• ROI
roi_rect = [100, 100, 400, 300]  # x1, y1, x2, y2

def is_in_rect_roi(point, roi):
    x, y = point
    x1, y1, x2, y2 = roi
    return x1 <= x <= x2 and y1 <= y <= y2

# 2. í´ë¦¬ê³¤ ROI
roi_polygon = np.array([
    [100, 200],  # ì¢Œìƒ
    [400, 200],  # ìš°ìƒ
    [450, 400],  # ìš°í•˜
    [50, 400]    # ì¢Œí•˜
], dtype=np.int32)

def is_in_polygon_roi(point, roi):
    \"\"\"OpenCV pointPolygonTest ì‚¬ìš©\"\"\"
    result = cv2.pointPolygonTest(roi, point, False)
    return result >= 0  # 0: ê²½ê³„, 1: ë‚´ë¶€, -1: ì™¸ë¶€

# 3. ROI ì‹œê°í™”
def draw_roi(frame, roi_polygon, color=(0, 255, 0)):
    # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
    overlay = frame.copy()
    cv2.fillPoly(overlay, [roi_polygon], color)
    frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)

    # ê²½ê³„ì„ 
    cv2.polylines(frame, [roi_polygon], True, color, 2)

    return frame
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: ROIëŠ” ì „ì²´ í”„ë ˆì„ì´ ì•„ë‹Œ íŠ¹ì • ì˜ì—­ë§Œ ëª¨ë‹ˆí„°ë§í•´ íš¨ìœ¨ í–¥ìƒ")

        # ì¹¨ì… ê°ì§€
        st.markdown("---")
        st.subheader("2ï¸âƒ£ ì¹¨ì… ê°ì§€ (Intrusion Detection)")

        st.markdown("""
        #### ğŸš¨ ì¹¨ì… ê°ì§€ ì•Œê³ ë¦¬ì¦˜

        **ì •ì˜**: ê¸ˆì§€ êµ¬ì—­ì— ê°ì²´ê°€ ì§„ì…í–ˆëŠ”ì§€ í™•ì¸

        **ì²˜ë¦¬ íë¦„**:
        1. ROI í´ë¦¬ê³¤ ì •ì˜
        2. ê°ì²´ ì¤‘ì‹¬ì  ê³„ì‚°
        3. ì¤‘ì‹¬ì ì´ ROI ë‚´ë¶€ì¸ì§€ ê²€ì‚¬
        4. ì¼ì • ì‹œê°„ ì²´ë¥˜ ì‹œ ì•Œë¦¼
        """)

        st.code("""
# ì¹¨ì… ê°ì§€ êµ¬í˜„
class IntrusionDetector:
    def __init__(self, roi_polygon, alert_threshold_seconds=3):
        self.roi = roi_polygon
        self.threshold = alert_threshold_seconds
        self.intrusion_tracks = {}  # {track_id: first_intrusion_time}

    def check_intrusion(self, tracks, current_time):
        \"\"\"
        tracks: Dict[int, Track] - í˜„ì¬ í”„ë ˆì„ì˜ ëª¨ë“  Track
        current_time: float - í˜„ì¬ ì‹œê°„ (ì´ˆ)
        \"\"\"
        alerts = []

        for track_id, track in tracks.items():
            # ì¤‘ì‹¬ì  ê³„ì‚°
            center = track.get_center(track.bbox)

            # ROI ë‚´ë¶€ ê²€ì‚¬
            is_inside = cv2.pointPolygonTest(self.roi, center, False) >= 0

            if is_inside:
                # ì²˜ìŒ ì¹¨ì…í•œ ê²½ìš°
                if track_id not in self.intrusion_tracks:
                    self.intrusion_tracks[track_id] = current_time

                # ì²´ë¥˜ ì‹œê°„ ê³„ì‚°
                duration = current_time - self.intrusion_tracks[track_id]

                # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
                if duration >= self.threshold:
                    alerts.append({
                        'type': 'INTRUSION',
                        'track_id': track_id,
                        'duration': duration,
                        'position': center,
                        'message': f'Track {track_id} in ROI for {duration:.1f}s'
                    })
            else:
                # ROI ì™¸ë¶€ë¡œ ë‚˜ê°„ ê²½ìš° ê¸°ë¡ ì‚­ì œ
                if track_id in self.intrusion_tracks:
                    del self.intrusion_tracks[track_id]

        return alerts

    def draw_intrusion_overlay(self, frame, tracks):
        \"\"\"ì¹¨ì… ì‹œê°í™”\"\"\"
        # ROI ê·¸ë¦¬ê¸°
        overlay = frame.copy()
        cv2.fillPoly(overlay, [self.roi], (0, 0, 255))  # ë¹¨ê°„ìƒ‰
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        cv2.polylines(frame, [self.roi], True, (0, 0, 255), 3)

        # ì¹¨ì… ì¤‘ì¸ Track ê°•ì¡°
        for track_id in self.intrusion_tracks:
            if track_id in tracks:
                track = tracks[track_id]
                x1, y1, x2, y2 = map(int, track.bbox)

                # ë¹¨ê°„ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)

                # ê²½ê³  í…ìŠ¤íŠ¸
                cv2.putText(frame, "INTRUSION!", (x1, y1-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        return frame

# ì‚¬ìš© ì˜ˆì œ
roi = np.array([[100, 200], [400, 200], [450, 400], [50, 400]])
detector = IntrusionDetector(roi, alert_threshold_seconds=3)

# í”„ë ˆì„ë³„ ì²˜ë¦¬
for frame_idx, frame in enumerate(video_frames):
    # YOLOv8 + ByteTrack
    detections = yolo_model(frame)
    tracks = tracker.update(detections)

    # ì¹¨ì… ê°ì§€
    current_time = frame_idx / fps  # ì´ˆ ë‹¨ìœ„
    alerts = detector.check_intrusion(tracks, current_time)

    # ì•Œë¦¼ ì²˜ë¦¬
    for alert in alerts:
        print(f"[ALERT] {alert['message']}")
        log_to_csv(alert)
        # send_notification(alert)  # ì´ë©”ì¼/SMS

    # ì‹œê°í™”
    frame = detector.draw_intrusion_overlay(frame, tracks)
    cv2.imshow('Intrusion Detection', frame)
        """, language="python")

        st.success("âœ… **ì¹¨ì… ê°ì§€ í•µì‹¬**: ROI ë‚´ë¶€ ì²´ë¥˜ ì‹œê°„ìœ¼ë¡œ ì˜¤íƒ (false positive) ìµœì†Œí™”")

        # ë°°íšŒ ê°ì§€
        st.markdown("---")
        st.subheader("3ï¸âƒ£ ë°°íšŒ ê°ì§€ (Loitering Detection)")

        st.markdown("""
        #### ğŸ‘€ ë°°íšŒ ê°ì§€ ì•Œê³ ë¦¬ì¦˜

        **ì •ì˜**: íŠ¹ì • ì˜ì—­ì—ì„œ ì˜¤ëœ ì‹œê°„ ë¨¸ë¬¼ê±°ë‚˜ ë°˜ë³µì ìœ¼ë¡œ ì™”ë‹¤ê°”ë‹¤ í•˜ëŠ” í–‰ë™ ê°ì§€

        **ì²˜ë¦¬ íë¦„**:
        1. Track ê¶¤ì  ê¸°ë¡ (ìµœê·¼ Ní”„ë ˆì„)
        2. ì´ë™ ê±°ë¦¬ ê³„ì‚°
        3. ì²´ë¥˜ ì‹œê°„ ê³„ì‚°
        4. ì´ë™ ê±°ë¦¬ ì‘ê³  + ì²´ë¥˜ ì‹œê°„ ê¸´ ê²½ìš° ë°°íšŒë¡œ íŒë‹¨
        """)

        st.code("""
# ë°°íšŒ ê°ì§€ êµ¬í˜„
class LoiteringDetector:
    def __init__(self, min_duration_seconds=10, max_movement_pixels=100):
        self.min_duration = min_duration_seconds
        self.max_movement = max_movement_pixels
        self.loitering_tracks = {}  # {track_id: start_time}

    def check_loitering(self, tracks, current_time, fps=30):
        \"\"\"
        tracks: Dict[int, Track]
        current_time: float - ì´ˆ ë‹¨ìœ„
        fps: int - í”„ë ˆì„ ë ˆì´íŠ¸
        \"\"\"
        alerts = []

        for track_id, track in tracks.items():
            # ê¶¤ì ì´ ì¶©ë¶„íˆ ìŒ“ì¸ ê²½ìš°ë§Œ íŒë‹¨
            min_frames = int(self.min_duration * fps)
            if len(track.history) < min_frames:
                continue

            # ìµœê·¼ Nì´ˆ ë™ì•ˆì˜ ì´ë™ ê±°ë¦¬ ê³„ì‚°
            recent_history = list(track.history)[-min_frames:]
            total_movement = self.calculate_total_movement(recent_history)

            # ë°°íšŒ ì¡°ê±´: ì´ë™ ê±°ë¦¬ ì‘ìŒ + ì²´ë¥˜ ì‹œê°„ ê¹€
            if total_movement < self.max_movement:
                # ì²˜ìŒ ë°°íšŒë¡œ íŒë‹¨ëœ ê²½ìš°
                if track_id not in self.loitering_tracks:
                    self.loitering_tracks[track_id] = current_time

                # ë°°íšŒ ì‹œê°„ ê³„ì‚°
                duration = current_time - self.loitering_tracks[track_id]

                alerts.append({
                    'type': 'LOITERING',
                    'track_id': track_id,
                    'duration': duration,
                    'movement': total_movement,
                    'position': track.history[-1],
                    'message': f'Track {track_id} loitering for {duration:.1f}s (moved {total_movement:.0f}px)'
                })
            else:
                # ì´ë™ ê±°ë¦¬ê°€ í¬ë©´ ë°°íšŒ ì•„ë‹˜
                if track_id in self.loitering_tracks:
                    del self.loitering_tracks[track_id]

        return alerts

    def calculate_total_movement(self, history):
        \"\"\"ê¶¤ì ì˜ ì´ ì´ë™ ê±°ë¦¬ (í”½ì…€)\"\"\"
        if len(history) < 2:
            return 0

        total = 0
        for i in range(1, len(history)):
            p1 = history[i-1]
            p2 = history[i]
            distance = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)
            total += distance

        return total

    def draw_loitering_overlay(self, frame, tracks):
        \"\"\"ë°°íšŒ ì‹œê°í™”\"\"\"
        for track_id in self.loitering_tracks:
            if track_id in tracks:
                track = tracks[track_id]
                x1, y1, x2, y2 = map(int, track.bbox)

                # ì£¼í™©ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 165, 255), 3)

                # ê²½ê³  í…ìŠ¤íŠ¸
                cv2.putText(frame, "LOITERING!", (x1, y1-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)

                # ê¶¤ì  ê·¸ë¦¬ê¸°
                if len(track.history) > 1:
                    points = np.array(track.history, dtype=np.int32)
                    cv2.polylines(frame, [points], False, (0, 165, 255), 2)

        return frame

# ì‚¬ìš© ì˜ˆì œ
detector = LoiteringDetector(min_duration_seconds=10, max_movement_pixels=100)

for frame_idx, frame in enumerate(video_frames):
    # YOLOv8 + ByteTrack
    detections = yolo_model(frame)
    tracks = tracker.update(detections)

    # ë°°íšŒ ê°ì§€
    current_time = frame_idx / fps
    alerts = detector.check_loitering(tracks, current_time, fps)

    # ì•Œë¦¼ ì²˜ë¦¬
    for alert in alerts:
        print(f"[ALERT] {alert['message']}")

    # ì‹œê°í™”
    frame = detector.draw_loitering_overlay(frame, tracks)
    cv2.imshow('Loitering Detection', frame)
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: ë°°íšŒ = ì²´ë¥˜ ì‹œê°„ ê¸¸ê³  + ì´ë™ ê±°ë¦¬ ì§§ìŒ")

        # ì¶”ê°€ ì´ë²¤íŠ¸
        st.markdown("---")
        st.subheader("4ï¸âƒ£ ê¸°íƒ€ ì´ë²¤íŠ¸ ê°ì§€")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            #### ğŸ“Š ê°ì²´ ê³„ìˆ˜ (Counting)

            ```python
            class LineCrossingCounter:
                def __init__(self, line_start, line_end):
                    self.line = (line_start, line_end)
                    self.crossed_tracks = set()
                    self.count = 0

                def check_crossing(self, tracks):
                    for track_id, track in tracks.items():
                        if track_id in self.crossed_tracks:
                            continue

                        if len(track.history) >= 2:
                            p1 = track.history[-2]
                            p2 = track.history[-1]

                            # ì„ ë¶„ êµì°¨ ê²€ì‚¬
                            if self.line_intersect(p1, p2):
                                self.count += 1
                                self.crossed_tracks.add(track_id)

                    return self.count

                def line_intersect(self, p1, p2):
                    # CCW ì•Œê³ ë¦¬ì¦˜
                    # ...
                    pass
            ```
            """)

        with col2:
            st.markdown("""
            #### ğŸš— ì†ë„ ì¸¡ì •

            ```python
            def estimate_speed(track, fps, pixels_per_meter):
                \"\"\"
                track: Track ê°ì²´
                fps: í”„ë ˆì„ ë ˆì´íŠ¸
                pixels_per_meter: í”½ì…€-ë¯¸í„° ë³€í™˜
                \"\"\"
                if len(track.history) < 2:
                    return 0

                # ìµœê·¼ 2í”„ë ˆì„ ë³€ìœ„ (í”½ì…€)
                p1 = track.history[-2]
                p2 = track.history[-1]
                displacement_px = np.sqrt(
                    (p2[0]-p1[0])**2 + (p2[1]-p1[1])**2
                )

                # ê±°ë¦¬ (ë¯¸í„°)
                distance_m = displacement_px / pixels_per_meter

                # ì‹œê°„ (ì´ˆ)
                time_s = 1 / fps

                # ì†ë„ (m/s)
                speed_ms = distance_m / time_s

                # km/h ë³€í™˜
                speed_kmh = speed_ms * 3.6

                return speed_kmh
            ```
            """)

    def render_heatmap(self):
        """Tab 4: íˆíŠ¸ë§µ ë¶„ì„"""
        st.header("ğŸ”¥ íˆíŠ¸ë§µ ë¶„ì„ (Heatmap Analysis)")

        st.markdown("---")

        # íˆíŠ¸ë§µ ê°œë…
        st.subheader("1ï¸âƒ£ íˆíŠ¸ë§µì´ë€?")

        st.markdown("""
        #### ğŸŒ¡ï¸ íˆíŠ¸ë§µ (Heatmap) ê°œìš”

        **ì •ì˜**: ê°ì²´ì˜ ì´ë™ ê²½ë¡œ ë° ì²´ë¥˜ ì‹œê°„ì„ ìƒ‰ìƒìœ¼ë¡œ ì‹œê°í™”

        **í™œìš©**:
        - **ì†Œë§¤ì **: ê³ ê° ë™ì„ , ì¸ê¸° êµ¬ì—­ íŒŒì•…
        - **êµí†µ**: í˜¼ì¡ êµ¬ì—­ ë¶„ì„
        - **ë³´ì•ˆ**: í™œë™ ë¹ˆë„ ë†’ì€ ì˜ì—­
        - **ì‘ì—…ì¥**: ìœ„í—˜ êµ¬ì—­ ì¶œì… ë¹ˆë„

        **ìƒ‰ìƒ ë§¤í•‘**:
        - ğŸ”µ íŒŒë€ìƒ‰: ë‚®ì€ í™œë™
        - ğŸŸ¢ ì´ˆë¡ìƒ‰: ì¤‘ê°„ í™œë™
        - ğŸŸ¡ ë…¸ë€ìƒ‰: ë†’ì€ í™œë™
        - ğŸ”´ ë¹¨ê°„ìƒ‰: ë§¤ìš° ë†’ì€ í™œë™
        """)

        st.code("""
# íˆíŠ¸ë§µ ìƒì„± êµ¬í˜„
class HeatmapGenerator:
    def __init__(self, frame_shape, decay_factor=0.99):
        \"\"\"
        frame_shape: (height, width) - í”„ë ˆì„ í¬ê¸°
        decay_factor: float - ì‹œê°„ì— ë”°ë¥¸ ê°ì‡  (0.99 = ì²œì²œíˆ ì‚¬ë¼ì§)
        \"\"\"
        self.height, self.width = frame_shape

        # íˆíŠ¸ë§µ ëˆ„ì  ë°°ì—´ (float32)
        self.heatmap = np.zeros((self.height, self.width), dtype=np.float32)

        self.decay_factor = decay_factor

    def update(self, tracks):
        \"\"\"Track ìœ„ì¹˜ë¥¼ íˆíŠ¸ë§µì— ëˆ„ì \"\"\"

        # 1. ì‹œê°„ ê°ì‡  (ì˜¤ë˜ëœ ì •ë³´ ì ì°¨ ì‚¬ë¼ì§)
        self.heatmap *= self.decay_factor

        # 2. í˜„ì¬ Track ìœ„ì¹˜ ëˆ„ì 
        for track_id, track in tracks.items():
            center = track.get_center(track.bbox)
            x, y = map(int, center)

            # ë²”ìœ„ ì²´í¬
            if 0 <= x < self.width and 0 <= y < self.height:
                # Gaussian ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ½ê²Œ ëˆ„ì 
                self.add_gaussian_blob(x, y, radius=20, intensity=1.0)

    def add_gaussian_blob(self, x, y, radius=20, intensity=1.0):
        \"\"\"íŠ¹ì • ìœ„ì¹˜ì— Gaussian ë¶„í¬ë¡œ ê°’ ëˆ„ì \"\"\"
        # ë²”ìœ„ ì„¤ì •
        x_min = max(0, x - radius)
        x_max = min(self.width, x + radius)
        y_min = max(0, y - radius)
        y_max = min(self.height, y + radius)

        # Gaussian ì»¤ë„ ìƒì„±
        for i in range(y_min, y_max):
            for j in range(x_min, x_max):
                # ê±°ë¦¬ ê³„ì‚°
                dist = np.sqrt((j - x)**2 + (i - y)**2)

                # Gaussian í•¨ìˆ˜
                if dist <= radius:
                    value = intensity * np.exp(-(dist**2) / (2 * (radius/3)**2))
                    self.heatmap[i, j] += value

    def get_heatmap_overlay(self, frame, alpha=0.5, colormap=cv2.COLORMAP_JET):
        \"\"\"
        íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ ìƒì„±

        Parameters:
            frame: ì›ë³¸ í”„ë ˆì„
            alpha: íˆ¬ëª…ë„ (0-1)
            colormap: OpenCV ì»¬ëŸ¬ë§µ
        \"\"\"
        # 1. ì •ê·œí™” (0-255)
        heatmap_normalized = cv2.normalize(self.heatmap, None, 0, 255,
                                          cv2.NORM_MINMAX).astype(np.uint8)

        # 2. ì»¬ëŸ¬ë§µ ì ìš©
        heatmap_colored = cv2.applyColorMap(heatmap_normalized, colormap)

        # 3. ì›ë³¸ í”„ë ˆì„ê³¼ í•©ì„±
        overlay = cv2.addWeighted(frame, 1-alpha, heatmap_colored, alpha, 0)

        return overlay

    def get_hotspots(self, threshold_percentile=90):
        \"\"\"
        í•«ìŠ¤íŒŸ (í™œë™ ë¹ˆë„ ë†’ì€ ì˜ì—­) ì¶”ì¶œ

        Parameters:
            threshold_percentile: ìƒìœ„ N% ì˜ì—­ì„ í•«ìŠ¤íŒŸìœ¼ë¡œ ê°„ì£¼

        Returns:
            List of hotspot regions (x, y, intensity)
        \"\"\"
        # ì„ê³„ê°’ ê³„ì‚°
        threshold = np.percentile(self.heatmap, threshold_percentile)

        # í•«ìŠ¤íŒŸ ì˜ì—­ ì¶”ì¶œ
        hotspot_mask = (self.heatmap > threshold).astype(np.uint8)

        # ì—°ê²° ì»´í¬ë„ŒíŠ¸ ë¶„ì„
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            hotspot_mask, connectivity=8
        )

        hotspots = []
        for i in range(1, num_labels):  # 0ì€ ë°°ê²½
            x, y = centroids[i]
            intensity = self.heatmap[int(y), int(x)]
            area = stats[i, cv2.CC_STAT_AREA]

            hotspots.append({
                'center': (int(x), int(y)),
                'intensity': float(intensity),
                'area': int(area)
            })

        # ê°•ë„ ìˆœ ì •ë ¬
        hotspots.sort(key=lambda h: h['intensity'], reverse=True)

        return hotspots

# ì‚¬ìš© ì˜ˆì œ
heatmap_gen = HeatmapGenerator(frame_shape=(720, 1280), decay_factor=0.995)

for frame in video_frames:
    # YOLOv8 + ByteTrack
    detections = yolo_model(frame)
    tracks = tracker.update(detections)

    # íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸
    heatmap_gen.update(tracks)

    # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
    overlay = heatmap_gen.get_heatmap_overlay(frame, alpha=0.6)

    # í•«ìŠ¤íŒŸ ì¶”ì¶œ ë° í‘œì‹œ
    hotspots = heatmap_gen.get_hotspots(threshold_percentile=95)
    for idx, hotspot in enumerate(hotspots[:5]):  # ìƒìœ„ 5ê°œ
        x, y = hotspot['center']
        cv2.circle(overlay, (x, y), 30, (255, 255, 255), 2)
        cv2.putText(overlay, f"#{idx+1}", (x-10, y+10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

    cv2.imshow('Heatmap', overlay)
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: íˆíŠ¸ë§µì€ ì‹œê°„ì— ë”°ë¼ ê°ì‡ (decay)ë˜ì–´ ìµœê·¼ í™œë™ ê°•ì¡°")

        # íˆíŠ¸ë§µ ì‹œê°í™” ì˜µì…˜
        st.markdown("---")
        st.subheader("2ï¸âƒ£ íˆíŠ¸ë§µ ì‹œê°í™” ì˜µì…˜")

        st.markdown("""
        #### ğŸ¨ OpenCV ì»¬ëŸ¬ë§µ

        OpenCVëŠ” ë‹¤ì–‘í•œ ì»¬ëŸ¬ë§µì„ ì œê³µí•©ë‹ˆë‹¤:
        """)

        st.code("""
# ì£¼ìš” ì»¬ëŸ¬ë§µ
colormaps = {
    'JET': cv2.COLORMAP_JET,           # ğŸ”µğŸŸ¢ğŸŸ¡ğŸ”´ (ê¸°ë³¸, ê°€ì¥ ì§ê´€ì )
    'HOT': cv2.COLORMAP_HOT,           # âš«ğŸ”´ğŸŸ¡âšª (ì—´í™”ìƒ ì¹´ë©”ë¼ ìŠ¤íƒ€ì¼)
    'VIRIDIS': cv2.COLORMAP_VIRIDIS,   # ğŸŸ£ğŸ”µğŸŸ¢ğŸŸ¡ (ê³¼í•™ì , ìƒ‰ë§¹ ì¹œí™”ì )
    'TURBO': cv2.COLORMAP_TURBO,       # ğŸ”µğŸŸ¢ğŸŸ¡ğŸ”´ (JET ê°œì„  ë²„ì „)
    'RAINBOW': cv2.COLORMAP_RAINBOW,   # ğŸŸ£ğŸ”µğŸŸ¢ğŸŸ¡ğŸŸ ğŸ”´ (ë¬´ì§€ê°œ)
    'BONE': cv2.COLORMAP_BONE,         # âš«âšª (X-ray ìŠ¤íƒ€ì¼)
}

# ì ìš©
heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)
        """, language="python")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            #### ğŸ“Š í†µê³„ ë¶„ì„

            ```python
            def analyze_heatmap(heatmap):
                \"\"\"íˆíŠ¸ë§µ í†µê³„ ë¶„ì„\"\"\"

                # ê¸°ë³¸ í†µê³„
                stats = {
                    'mean': np.mean(heatmap),
                    'median': np.median(heatmap),
                    'max': np.max(heatmap),
                    'std': np.std(heatmap)
                }

                # í™œë™ ë¶„í¬
                hist, bins = np.histogram(
                    heatmap.flatten(),
                    bins=50
                )

                # í•«ìŠ¤íŒŸ ë¹„ìœ¨
                threshold = np.percentile(heatmap, 90)
                hotspot_ratio = np.sum(heatmap > threshold) / heatmap.size

                stats['hotspot_ratio'] = hotspot_ratio

                return stats
            ```
            """)

        with col2:
            st.markdown("""
            #### ğŸ• ì‹œê°„ëŒ€ë³„ ë¶„ì„

            ```python
            class TimeBasedHeatmap:
                def __init__(self, frame_shape):
                    self.heatmaps = defaultdict(
                        lambda: np.zeros(frame_shape, dtype=np.float32)
                    )

                def update(self, tracks, hour):
                    \"\"\"ì‹œê°„ëŒ€ë³„ë¡œ íˆíŠ¸ë§µ ë¶„ë¦¬\"\"\"
                    for track in tracks.values():
                        center = track.get_center(track.bbox)
                        x, y = map(int, center)

                        # í•´ë‹¹ ì‹œê°„ëŒ€ íˆíŠ¸ë§µì— ëˆ„ì 
                        self.heatmaps[hour][y, x] += 1

                def get_peak_hours(self):
                    \"\"\"ê°€ì¥ í™œë™ì´ ë§ì€ ì‹œê°„ëŒ€\"\"\"
                    hour_activity = {
                        hour: np.sum(heatmap)
                        for hour, heatmap in self.heatmaps.items()
                    }
                    return sorted(hour_activity.items(),
                                 key=lambda x: x[1],
                                 reverse=True)
            ```
            """)

    def render_dashboard(self):
        """Tab 5: ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ"""
        st.header("ğŸ“Š ëŒ€ì‹œë³´ë“œ (Dashboard)")

        st.markdown("---")

        # ì‹¤ì‹œê°„ í†µê³„
        st.subheader("1ï¸âƒ£ ì‹¤ì‹œê°„ í†µê³„")

        st.markdown("""
        #### ğŸ“ˆ ì£¼ìš” ì§€í‘œ (KPI)

        CCTV ì‹œìŠ¤í…œì—ì„œ ì¶”ì í•  ì£¼ìš” ì§€í‘œ:
        - í˜„ì¬ íƒì§€ ê°ì²´ ìˆ˜
        - ì´ ì¶”ì  ID ìˆ˜
        - ì´ë²¤íŠ¸ ë°œìƒ íšŸìˆ˜ (ì¹¨ì…/ë°°íšŒ)
        - í‰ê·  FPS
        - ROI ì¹¨ì… íšŸìˆ˜
        """)

        st.code("""
# ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
class DashboardMetrics:
    def __init__(self):
        self.reset()

    def reset(self):
        \"\"\"ë©”íŠ¸ë¦­ ì´ˆê¸°í™”\"\"\"
        self.total_detections = 0
        self.total_tracks = 0
        self.intrusion_events = 0
        self.loitering_events = 0
        self.fps_history = deque(maxlen=30)
        self.track_class_counts = defaultdict(int)  # {class_id: count}
        self.hourly_activity = defaultdict(int)  # {hour: count}

    def update(self, detections, tracks, events, fps, current_hour):
        \"\"\"í”„ë ˆì„ë³„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸\"\"\"

        # íƒì§€/ì¶”ì  ìˆ˜
        self.total_detections += len(detections)
        self.total_tracks = len(tracks)

        # FPS
        self.fps_history.append(fps)

        # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸
        for det in detections:
            self.track_class_counts[det['class']] += 1

        # ì´ë²¤íŠ¸ ì¹´ìš´íŠ¸
        for event in events:
            if event['type'] == 'INTRUSION':
                self.intrusion_events += 1
            elif event['type'] == 'LOITERING':
                self.loitering_events += 1

        # ì‹œê°„ëŒ€ë³„ í™œë™
        self.hourly_activity[current_hour] += len(detections)

    def get_summary(self):
        \"\"\"ìš”ì•½ í†µê³„\"\"\"
        return {
            'current_tracks': self.total_tracks,
            'total_detections': self.total_detections,
            'intrusion_count': self.intrusion_events,
            'loitering_count': self.loitering_events,
            'avg_fps': np.mean(self.fps_history) if self.fps_history else 0,
            'class_distribution': dict(self.track_class_counts),
            'peak_hour': max(self.hourly_activity.items(),
                           key=lambda x: x[1])[0] if self.hourly_activity else None
        }

# Streamlit ëŒ€ì‹œë³´ë“œ ì˜ˆì œ
def render_dashboard(metrics):
    st.title("ğŸ¥ Smart CCTV Dashboard")

    summary = metrics.get_summary()

    # 1í–‰: ì£¼ìš” ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("í˜„ì¬ ì¶”ì  ì¤‘", summary['current_tracks'])

    with col2:
        st.metric("ì´ íƒì§€ ìˆ˜", summary['total_detections'])

    with col3:
        st.metric("ì¹¨ì… ì´ë²¤íŠ¸", summary['intrusion_count'],
                 delta="+" + str(summary['intrusion_count']) if summary['intrusion_count'] > 0 else None)

    with col4:
        st.metric("í‰ê·  FPS", f"{summary['avg_fps']:.1f}")

    # 2í–‰: ì°¨íŠ¸
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("í´ë˜ìŠ¤ë³„ íƒì§€ ë¶„í¬")
        if summary['class_distribution']:
            class_names = {0: 'Person', 2: 'Car', 3: 'Motorcycle'}
            chart_data = {
                class_names.get(k, f'Class {k}'): v
                for k, v in summary['class_distribution'].items()
            }
            st.bar_chart(chart_data)

    with col2:
        st.subheader("ì‹œê°„ëŒ€ë³„ í™œë™")
        hourly_data = pd.DataFrame({
            'Hour': list(metrics.hourly_activity.keys()),
            'Activity': list(metrics.hourly_activity.values())
        })
        st.line_chart(hourly_data.set_index('Hour'))
        """, language="python")

        st.info("ğŸ’¡ **êµìœ¡ í¬ì¸íŠ¸**: ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¡œ ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§")

        # ì´ë²¤íŠ¸ ë¡œê·¸
        st.markdown("---")
        st.subheader("2ï¸âƒ£ ì´ë²¤íŠ¸ ë¡œê·¸ (CSV)")

        st.markdown("""
        #### ğŸ“ ë¡œê·¸ ì‹œìŠ¤í…œ

        ê°„ì†Œí™” ë²„ì „ì—ì„œëŠ” CSV íŒŒì¼ë¡œ ì´ë²¤íŠ¸ ê¸°ë¡:
        """)

        st.code("""
# CSV ë¡œê¹… ì‹œìŠ¤í…œ
import csv
from datetime import datetime
from pathlib import Path

class EventLogger:
    def __init__(self, log_dir='logs'):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)

        # ë‚ ì§œë³„ ë¡œê·¸ íŒŒì¼
        today = datetime.now().strftime('%Y%m%d')
        self.log_file = self.log_dir / f'events_{today}.csv'

        # í—¤ë” ì‘ì„± (íŒŒì¼ì´ ì—†ì„ ê²½ìš°)
        if not self.log_file.exists():
            self.write_header()

    def write_header(self):
        \"\"\"CSV í—¤ë” ì‘ì„±\"\"\"
        with open(self.log_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'Timestamp',
                'Event Type',
                'Track ID',
                'Position X',
                'Position Y',
                'Duration',
                'Confidence',
                'Class',
                'Message'
            ])

    def log_event(self, event):
        \"\"\"ì´ë²¤íŠ¸ ê¸°ë¡\"\"\"
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]

        with open(self.log_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp,
                event.get('type', 'UNKNOWN'),
                event.get('track_id', ''),
                event.get('position', [0, 0])[0],
                event.get('position', [0, 0])[1],
                event.get('duration', 0),
                event.get('confidence', 0),
                event.get('class', ''),
                event.get('message', '')
            ])

    def read_logs(self, limit=100):
        \"\"\"ìµœê·¼ ë¡œê·¸ ì½ê¸°\"\"\"
        if not self.log_file.exists():
            return []

        with open(self.log_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            logs = list(reader)

        # ìµœê·¼ Nê°œë§Œ ë°˜í™˜
        return logs[-limit:]

# ì‚¬ìš© ì˜ˆì œ
logger = EventLogger(log_dir='logs')

# ì´ë²¤íŠ¸ ë°œìƒ ì‹œ
for event in alerts:
    logger.log_event(event)
    print(f"[LOG] {event['message']}")

# Streamlitì—ì„œ ë¡œê·¸ í‘œì‹œ
st.subheader("Recent Events")
logs = logger.read_logs(limit=50)
df = pd.DataFrame(logs)
st.dataframe(df, use_container_width=True)
        """, language="python")

        st.success("âœ… **ê°„ì†Œí™”**: CSV ë¡œê·¸ â†’ í”„ë¡œë•ì…˜ì—ì„œëŠ” PostgreSQL/MongoDB ì‚¬ìš©")

        # ì•Œë¦¼ ì‹œìŠ¤í…œ
        st.markdown("---")
        st.subheader("3ï¸âƒ£ ì•Œë¦¼ ì‹œìŠ¤í…œ (êµìœ¡ìš©)")

        st.markdown("""
        #### ğŸ”” ì•Œë¦¼ ë°©ì‹

        **êµìœ¡ìš© ê°„ì†Œí™”**:
        - âœ… ì½˜ì†” ì¶œë ¥ (`print`)
        - âœ… Streamlit í† ìŠ¤íŠ¸ ì•Œë¦¼
        - âŒ ì´ë©”ì¼ (SMTP ì„¤ì • í•„ìš”)
        - âŒ SMS (Twilio ê³„ì • í•„ìš”)
        - âŒ Webhook (ì„œë²„ í•„ìš”)
        """)

        st.code("""
# ê°„ë‹¨í•œ ì•Œë¦¼ ì‹œìŠ¤í…œ
class SimpleAlertSystem:
    def __init__(self):
        self.alert_history = deque(maxlen=100)

    def send_alert(self, event):
        \"\"\"ì•Œë¦¼ ë°œì†¡\"\"\"

        # 1. ì½˜ì†” ì¶œë ¥
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"[{timestamp}] [ALERT] {event['type']}: {event['message']}")

        # 2. íˆìŠ¤í† ë¦¬ ì €ì¥
        event['timestamp'] = timestamp
        self.alert_history.append(event)

        # 3. Streamlit í† ìŠ¤íŠ¸ (ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©)
        if 'alerts' not in st.session_state:
            st.session_state.alerts = []
        st.session_state.alerts.append(event)

    def get_recent_alerts(self, limit=10):
        \"\"\"ìµœê·¼ ì•Œë¦¼ ì¡°íšŒ\"\"\"
        return list(self.alert_history)[-limit:]

# Streamlitì—ì„œ ì•Œë¦¼ í‘œì‹œ
def show_alerts():
    if 'alerts' in st.session_state and st.session_state.alerts:
        st.subheader("ğŸš¨ Recent Alerts")

        for alert in st.session_state.alerts[-5:]:  # ìµœê·¼ 5ê°œ
            if alert['type'] == 'INTRUSION':
                st.error(f"{alert['timestamp']} - {alert['message']}")
            elif alert['type'] == 'LOITERING':
                st.warning(f"{alert['timestamp']} - {alert['message']}")
            else:
                st.info(f"{alert['timestamp']} - {alert['message']}")

        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("Clear Alerts"):
            st.session_state.alerts = []
            st.rerun()
        """, language="python")

        # í†µí•© ì˜ˆì œ
        st.markdown("---")
        st.subheader("4ï¸âƒ£ í†µí•© ì‹¤í–‰ ì˜ˆì œ")

        st.code("""
# ì „ì²´ ì‹œìŠ¤í…œ í†µí•©
import cv2
from ultralytics import YOLO

def main():
    # ì´ˆê¸°í™”
    model = YOLO('yolov8n.pt')
    tracker = SimpleByteTrack()

    # ROI ì„¤ì •
    roi = np.array([[100, 200], [500, 200], [500, 400], [100, 400]])
    intrusion_detector = IntrusionDetector(roi, alert_threshold_seconds=3)
    loitering_detector = LoiteringDetector(min_duration_seconds=10, max_movement_pixels=100)

    # íˆíŠ¸ë§µ
    heatmap_gen = HeatmapGenerator(frame_shape=(720, 1280))

    # ëŒ€ì‹œë³´ë“œ & ë¡œê¹…
    metrics = DashboardMetrics()
    logger = EventLogger()
    alert_system = SimpleAlertSystem()

    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    cap = cv2.VideoCapture('surveillance.mp4')
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_idx = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        start_time = time.time()

        # 1. YOLOv8 íƒì§€
        results = model(frame, conf=0.3, classes=[0, 2])  # ì‚¬ëŒ, ì°¨ëŸ‰

        detections = []
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                detections.append({
                    'bbox': [x1, y1, x2, y2],
                    'conf': float(box.conf[0]),
                    'class': int(box.cls[0])
                })

        # 2. ByteTrack ì¶”ì 
        tracks = tracker.update(detections)

        # 3. ì´ë²¤íŠ¸ ê°ì§€
        current_time = frame_idx / fps
        current_hour = datetime.now().hour

        intrusion_alerts = intrusion_detector.check_intrusion(tracks, current_time)
        loitering_alerts = loitering_detector.check_loitering(tracks, current_time, fps)

        all_alerts = intrusion_alerts + loitering_alerts

        # 4. ì•Œë¦¼ ë° ë¡œê¹…
        for alert in all_alerts:
            logger.log_event(alert)
            alert_system.send_alert(alert)

        # 5. íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸
        heatmap_gen.update(tracks)

        # 6. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        actual_fps = 1.0 / (time.time() - start_time)
        metrics.update(detections, tracks, all_alerts, actual_fps, current_hour)

        # 7. ì‹œê°í™”
        # íƒì§€/ì¶”ì  ê·¸ë¦¬ê¸°
        for track_id, track in tracks.items():
            x1, y1, x2, y2 = map(int, track.bbox)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"ID:{track_id}", (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # ì¹¨ì…/ë°°íšŒ ì˜¤ë²„ë ˆì´
        frame = intrusion_detector.draw_intrusion_overlay(frame, tracks)
        frame = loitering_detector.draw_loitering_overlay(frame, tracks)

        # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
        heatmap_overlay = heatmap_gen.get_heatmap_overlay(frame, alpha=0.4)

        # ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"FPS: {actual_fps:.1f}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"Tracks: {len(tracks)}", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # ê²°ê³¼ í‘œì‹œ
        cv2.imshow('Smart CCTV - Main', frame)
        cv2.imshow('Smart CCTV - Heatmap', heatmap_overlay)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        frame_idx += 1

    # ì¢…ë£Œ
    cap.release()
    cv2.destroyAllWindows()

    # ìµœì¢… ìš”ì•½
    summary = metrics.get_summary()
    print("\\n=== Final Summary ===")
    print(f"Total Detections: {summary['total_detections']}")
    print(f"Intrusion Events: {summary['intrusion_count']}")
    print(f"Loitering Events: {summary['loitering_count']}")
    print(f"Average FPS: {summary['avg_fps']:.1f}")

if __name__ == '__main__':
    main()
        """, language="python")

        st.success("""
        âœ… **êµìœ¡ìš© ì‹œìŠ¤í…œ ì™„ì„±**:
        - YOLOv8 + ByteTrack í†µí•©
        - ROI ì¹¨ì…/ë°°íšŒ ê°ì§€
        - íˆíŠ¸ë§µ ë¶„ì„
        - ê°„ë‹¨í•œ ë¡œê¹… ë° ì•Œë¦¼
        - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
        """)

    def render_simulation(self):
        """Tab 6: ì‹¤ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
        st.header("ğŸ® ì‹¤ìŠµ ì‹œë®¬ë ˆì´ì…˜")

        st.markdown("""
        ### êµìœ¡ìš© ì¸í„°ë™í‹°ë¸Œ ì‹œë®¬ë ˆì´ì…˜

        ì‹¤ì œ CCTV ì˜ìƒ ì—†ì´ë„ ìŠ¤ë§ˆíŠ¸ CCTV ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        **ì œê³µ ê¸°ëŠ¥**:
        1. ğŸ² í•©ì„± ë°ì´í„° ìƒì„± (ê°€ìƒ ê°ì²´ ì´ë™ ì‹œë®¬ë ˆì´ì…˜)
        2. ğŸ–¼ï¸ ì •ì  ì´ë¯¸ì§€ ì—…ë¡œë“œ (YOLOv8 íƒì§€ ì‹¤ìŠµ)
        3. âœï¸ ROI ì˜ì—­ ì„¤ì • (ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì˜ì—­ ì§€ì •)
        4. ğŸ“Š ì¶”ì  ë° íˆíŠ¸ë§µ ì‹œê°í™”
        """)

        st.markdown("---")

        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì„ íƒ
        sim_mode = st.radio(
            "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì„ íƒ:",
            ["ğŸ² í•©ì„± ë°ì´í„° ìƒì„±", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° íƒì§€"],
            horizontal=True
        )

        if sim_mode == "ğŸ² í•©ì„± ë°ì´í„° ìƒì„±":
            self.render_synthetic_simulation()
        else:
            self.render_image_detection_simulation()

    def render_synthetic_simulation(self):
        """í•©ì„± ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜"""
        st.subheader("ğŸ² í•©ì„± ë°ì´í„° ìƒì„± ì‹œë®¬ë ˆì´ì…˜")

        st.markdown("""
        ê°€ìƒì˜ ê°ì²´(ì‚¬ëŒ, ì°¨ëŸ‰)ê°€ ì´ë™í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
        ì‹¤ì œ ë¹„ë””ì˜¤ ì—†ì´ë„ ì¶”ì , ROI ì¹¨ì…, ë°°íšŒ ê°ì§€, íˆíŠ¸ë§µì„ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

        # ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •
        col1, col2 = st.columns(2)

        with col1:
            num_objects = st.slider("ê°ì²´ ìˆ˜", 1, 10, 5)
            frame_width = st.slider("í”„ë ˆì„ ë„ˆë¹„ (px)", 400, 1280, 800)
            frame_height = st.slider("í”„ë ˆì„ ë†’ì´ (px)", 300, 720, 600)

        with col2:
            num_frames = st.slider("ì‹œë®¬ë ˆì´ì…˜ í”„ë ˆì„ ìˆ˜", 30, 300, 100)
            speed_factor = st.slider("ì´ë™ ì†ë„", 1.0, 5.0, 2.0, 0.5)

        # ROI ì„¤ì •
        st.markdown("#### ROI (ê´€ì‹¬ ì˜ì—­) ì„¤ì •")
        roi_enabled = st.checkbox("ROI ì¹¨ì… ê°ì§€ í™œì„±í™”", value=True)

        if roi_enabled:
            roi_x = st.slider("ROI ì¤‘ì‹¬ X", 0, frame_width, frame_width // 2)
            roi_y = st.slider("ROI ì¤‘ì‹¬ Y", 0, frame_height, frame_height // 2)
            roi_size = st.slider("ROI í¬ê¸°", 50, 300, 150)

        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        if st.button("ğŸ¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘", type="primary"):
            with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ìƒì„± ì¤‘..."):
                # í•©ì„± ë°ì´í„° ìƒì„±
                synthetic_data = self.generate_synthetic_trajectories(
                    num_objects=num_objects,
                    num_frames=num_frames,
                    frame_width=frame_width,
                    frame_height=frame_height,
                    speed_factor=speed_factor
                )

                # ROI ì •ì˜
                roi_polygon = None
                if roi_enabled:
                    roi_polygon = np.array([
                        [roi_x - roi_size, roi_y - roi_size],
                        [roi_x + roi_size, roi_y - roi_size],
                        [roi_x + roi_size, roi_y + roi_size],
                        [roi_x - roi_size, roi_y + roi_size]
                    ], dtype=np.int32)

                # ì‹œê°í™”
                self.visualize_synthetic_simulation(
                    synthetic_data,
                    frame_width,
                    frame_height,
                    roi_polygon
                )

    def generate_synthetic_trajectories(self, num_objects, num_frames, frame_width, frame_height, speed_factor):
        """í•©ì„± ê¶¤ì  ë°ì´í„° ìƒì„±"""
        trajectories = {}

        for obj_id in range(num_objects):
            # ì‹œì‘ ìœ„ì¹˜ (ëœë¤)
            start_x = np.random.randint(50, frame_width - 50)
            start_y = np.random.randint(50, frame_height - 50)

            # ëª©í‘œ ìœ„ì¹˜ (ëœë¤)
            end_x = np.random.randint(50, frame_width - 50)
            end_y = np.random.randint(50, frame_height - 50)

            # ì´ë™ ê²½ë¡œ ìƒì„± (ì„ í˜• ë³´ê°„ + ë…¸ì´ì¦ˆ)
            t = np.linspace(0, 1, num_frames)
            base_x = start_x + (end_x - start_x) * t
            base_y = start_y + (end_y - start_y) * t

            # ë…¸ì´ì¦ˆ ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„)
            noise_x = np.cumsum(np.random.randn(num_frames) * speed_factor)
            noise_y = np.cumsum(np.random.randn(num_frames) * speed_factor)

            x_coords = np.clip(base_x + noise_x, 0, frame_width)
            y_coords = np.clip(base_y + noise_y, 0, frame_height)

            # ê°ì²´ íƒ€ì… (ì‚¬ëŒ ë˜ëŠ” ì°¨ëŸ‰)
            obj_type = np.random.choice(['person', 'car'], p=[0.7, 0.3])

            trajectories[obj_id] = {
                'x': x_coords,
                'y': y_coords,
                'type': obj_type,
                'bbox_size': 40 if obj_type == 'person' else 60
            }

        return trajectories

    def visualize_synthetic_simulation(self, trajectories, frame_width, frame_height, roi_polygon):
        """í•©ì„± ì‹œë®¬ë ˆì´ì…˜ ì‹œê°í™”"""
        num_frames = len(trajectories[0]['x'])

        # íˆíŠ¸ë§µ ì´ˆê¸°í™”
        heatmap = np.zeros((frame_height, frame_width), dtype=np.float32)

        # ì¹¨ì… ì¶”ì 
        intrusion_log = []

        # í”„ë ˆì„ë³„ ì‹œê°í™”
        st.markdown("#### ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
        progress_bar = st.progress(0)
        status_text = st.empty()

        # ê²°ê³¼ ì»¨í…Œì´ë„ˆ
        result_container = st.container()

        with result_container:
            col1, col2 = st.columns(2)

            with col1:
                frame_placeholder = st.empty()

            with col2:
                heatmap_placeholder = st.empty()

        # í†µê³„ í‘œì‹œ
        stats_cols = st.columns(4)
        stat_objects = stats_cols[0].empty()
        stat_intrusions = stats_cols[1].empty()
        stat_total_distance = stats_cols[2].empty()
        stat_avg_speed = stats_cols[3].empty()

        # í”„ë ˆì„ë³„ ì²˜ë¦¬
        for frame_idx in range(0, num_frames, 5):  # 5í”„ë ˆì„ë§ˆë‹¤ ì‹œê°í™”
            # ë¹ˆ í”„ë ˆì„ ìƒì„±
            frame = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 240

            # ROI ê·¸ë¦¬ê¸°
            if roi_polygon is not None:
                overlay = frame.copy()
                cv2.fillPoly(overlay, [roi_polygon], (200, 200, 255))
                frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
                cv2.polylines(frame, [roi_polygon], True, (0, 0, 255), 2)

            # ê°ì²´ ê·¸ë¦¬ê¸°
            for obj_id, traj in trajectories.items():
                x = int(traj['x'][frame_idx])
                y = int(traj['y'][frame_idx])
                bbox_size = traj['bbox_size']

                # ë°”ìš´ë”© ë°•ìŠ¤
                color = (0, 200, 0) if traj['type'] == 'person' else (200, 100, 0)
                cv2.rectangle(frame, (x - bbox_size//2, y - bbox_size//2),
                            (x + bbox_size//2, y + bbox_size//2), color, 2)

                # ID ë¼ë²¨
                cv2.putText(frame, f"ID:{obj_id}", (x - bbox_size//2, y - bbox_size//2 - 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

                # ê¶¤ì  ê·¸ë¦¬ê¸°
                if frame_idx > 0:
                    points = np.array([[int(traj['x'][i]), int(traj['y'][i])]
                                     for i in range(max(0, frame_idx - 20), frame_idx + 1)],
                                    dtype=np.int32)
                    cv2.polylines(frame, [points], False, (150, 150, 150), 1)

                # íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸
                if 0 <= x < frame_width and 0 <= y < frame_height:
                    cv2.circle(heatmap, (x, y), 10, 1.0, -1)

                # ROI ì¹¨ì… ê²€ì‚¬
                if roi_polygon is not None:
                    if cv2.pointPolygonTest(roi_polygon, (float(x), float(y)), False) >= 0:
                        intrusion_log.append({
                            'frame': frame_idx,
                            'object_id': obj_id,
                            'type': traj['type']
                        })
                        # ì¹¨ì… í‘œì‹œ
                        cv2.circle(frame, (x, y), bbox_size, (0, 0, 255), 2)

            # íˆíŠ¸ë§µ ì‹œê°í™”
            heatmap_normalized = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)

            # í”„ë ˆì„ ì •ë³´
            cv2.putText(frame, f"Frame: {frame_idx}/{num_frames}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 50, 50), 2)

            # ì—…ë°ì´íŠ¸
            frame_placeholder.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),
                                  caption="ì‹œë®¬ë ˆì´ì…˜ í”„ë ˆì„", use_container_width=True)
            heatmap_placeholder.image(cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB),
                                     caption="íˆíŠ¸ë§µ ëˆ„ì ", use_container_width=True)

            # í†µê³„ ì—…ë°ì´íŠ¸
            total_distance = sum([np.sum(np.sqrt(np.diff(traj['x'][:frame_idx+1])**2 +
                                                 np.diff(traj['y'][:frame_idx+1])**2))
                                 for traj in trajectories.values()])

            stat_objects.metric("í™œì„± ê°ì²´", len(trajectories))
            stat_intrusions.metric("ROI ì¹¨ì… íšŸìˆ˜", len(intrusion_log))
            stat_total_distance.metric("ì´ ì´ë™ ê±°ë¦¬", f"{total_distance:.0f}px")
            stat_avg_speed.metric("í‰ê·  ì†ë„", f"{total_distance/(frame_idx+1):.1f}px/frame")

            # í”„ë¡œê·¸ë ˆìŠ¤ ì—…ë°ì´íŠ¸
            progress_bar.progress((frame_idx + 1) / num_frames)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {frame_idx + 1}/{num_frames} í”„ë ˆì„")

        progress_bar.progress(1.0)
        status_text.text("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")

        # ì¹¨ì… ë¡œê·¸ í‘œì‹œ
        if intrusion_log:
            st.markdown("#### ğŸš¨ ROI ì¹¨ì… ì´ë²¤íŠ¸ ë¡œê·¸")
            st.dataframe({
                'í”„ë ˆì„': [e['frame'] for e in intrusion_log],
                'ê°ì²´ ID': [e['object_id'] for e in intrusion_log],
                'íƒ€ì…': [e['type'] for e in intrusion_log]
            })

    def render_image_detection_simulation(self):
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° íƒì§€ ì‹œë®¬ë ˆì´ì…˜"""
        st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° YOLOv8 íƒì§€")

        st.markdown("""
        ì •ì  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ YOLOv8 ê°ì²´ íƒì§€ë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.
        íƒì§€ëœ ê°ì²´ì— ROIë¥¼ ì„¤ì •í•˜ì—¬ ì¹¨ì… ê°ì§€ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ (JPG, PNG)",
            type=['jpg', 'jpeg', 'png'],
            help="ì‚¬ëŒì´ë‚˜ ì°¨ëŸ‰ì´ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        if uploaded_file is not None:
            # ì´ë¯¸ì§€ ì½ê¸°
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

            col1, col2 = st.columns(2)

            with col1:
                st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB),
                        caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

            # YOLOv8 ëª¨ë¸ ë¡œë“œ ì²´í¬
            try:
                from ultralytics import YOLO

                with col2:
                    st.info("ğŸ” YOLOv8 íƒì§€ ì¤‘...")

                    # ëª¨ë¸ ë¡œë“œ
                    with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
                        model = YOLO('yolov8n.pt')

                    # ì¶”ë¡ 
                    conf_threshold = st.slider("ì‹ ë¢°ë„ ì„ê³„ê°’", 0.1, 1.0, 0.5, 0.05)
                    results = model(image, conf=conf_threshold)

                    # ê²°ê³¼ ê·¸ë¦¬ê¸°
                    result_image = image.copy()
                    detections = []

                    for result in results:
                        boxes = result.boxes
                        for box in boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                            conf = float(box.conf[0])
                            class_id = int(box.cls[0])
                            class_name = result.names[class_id]

                            # ë°”ìš´ë”© ë°•ìŠ¤
                            cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)

                            # ë¼ë²¨
                            label = f"{class_name} {conf:.2f}"
                            cv2.putText(result_image, label, (x1, y1 - 10),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                            detections.append({
                                'class': class_name,
                                'confidence': conf,
                                'bbox': [x1, y1, x2, y2]
                            })

                    st.image(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB),
                            caption=f"íƒì§€ ê²°ê³¼ ({len(detections)}ê°œ ê°ì²´)", use_container_width=True)

                # íƒì§€ ê²°ê³¼ í‘œì‹œ
                if detections:
                    st.markdown("#### íƒì§€ëœ ê°ì²´")
                    st.dataframe({
                        'í´ë˜ìŠ¤': [d['class'] for d in detections],
                        'ì‹ ë¢°ë„': [f"{d['confidence']:.2%}" for d in detections],
                        'Bbox': [f"({d['bbox'][0]}, {d['bbox'][1]}, {d['bbox'][2]}, {d['bbox'][3]})"
                                for d in detections]
                    })

                    # ROI ì„¤ì • ë° ì¹¨ì… ê²€ì‚¬
                    st.markdown("#### ROI ì¹¨ì… ê²€ì‚¬")
                    st.markdown("ìŠ¬ë¼ì´ë”ë¡œ ROI ì˜ì—­ì„ ì„¤ì •í•˜ì—¬ ì¹¨ì… ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

                    h, w = image.shape[:2]
                    roi_x = st.slider("ROI ì¤‘ì‹¬ X", 0, w, w // 2, key="roi_x_img")
                    roi_y = st.slider("ROI ì¤‘ì‹¬ Y", 0, h, h // 2, key="roi_y_img")
                    roi_size = st.slider("ROI í¬ê¸°", 50, min(w, h) // 2, 100, key="roi_size_img")

                    # ROI í´ë¦¬ê³¤
                    roi_polygon = np.array([
                        [roi_x - roi_size, roi_y - roi_size],
                        [roi_x + roi_size, roi_y - roi_size],
                        [roi_x + roi_size, roi_y + roi_size],
                        [roi_x - roi_size, roi_y + roi_size]
                    ], dtype=np.int32)

                    # ROI ë° ì¹¨ì… ì‹œê°í™”
                    roi_image = result_image.copy()
                    overlay = roi_image.copy()
                    cv2.fillPoly(overlay, [roi_polygon], (200, 200, 255))
                    roi_image = cv2.addWeighted(roi_image, 0.7, overlay, 0.3, 0)
                    cv2.polylines(roi_image, [roi_polygon], True, (0, 0, 255), 3)

                    intrusion_count = 0
                    for det in detections:
                        x1, y1, x2, y2 = det['bbox']
                        center_x = (x1 + x2) // 2
                        center_y = (y1 + y2) // 2

                        # ROI ë‚´ë¶€ ê²€ì‚¬
                        if cv2.pointPolygonTest(roi_polygon, (float(center_x), float(center_y)), False) >= 0:
                            intrusion_count += 1
                            # ì¹¨ì… ê°ì²´ ê°•ì¡°
                            cv2.rectangle(roi_image, (x1, y1), (x2, y2), (0, 0, 255), 3)
                            cv2.putText(roi_image, "INTRUSION!", (x1, y1 - 30),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

                    st.image(cv2.cvtColor(roi_image, cv2.COLOR_BGR2RGB),
                            caption=f"ROI ì¹¨ì… ê²€ì‚¬ ê²°ê³¼ ({intrusion_count}ê°œ ì¹¨ì…)", use_container_width=True)

                    if intrusion_count > 0:
                        st.error(f"ğŸš¨ {intrusion_count}ê°œ ê°ì²´ê°€ ROI ì˜ì—­ì— ì¹¨ì…í–ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.success("âœ… ROI ì˜ì—­ì— ì¹¨ì…í•œ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            except ImportError:
                st.error("""
                âŒ YOLOv8ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

                ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:
                ```bash
                pip install ultralytics
                ```
                """)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        else:
            st.info("ğŸ‘† ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

            st.markdown("""
            **ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ì²œ**:
            - ê±°ë¦¬ ì‚¬ì§„ (ì‚¬ëŒ, ì°¨ëŸ‰ í¬í•¨)
            - ì£¼ì°¨ì¥ ì‚¬ì§„
            - ê³µê³µì¥ì†Œ ì‚¬ì§„
            - êµí†µ ìƒí™© ì‚¬ì§„

            ë˜ëŠ” ì˜¨ë¼ì¸ì—ì„œ ë¬´ë£Œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:
            - [Unsplash](https://unsplash.com) - ë¬´ë£Œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€
            - [Pexels](https://pexels.com) - ë¬´ë£Œ ìŠ¤í†¡ ì‚¬ì§„
            """)


def main():
    """Streamlit ì•± ì§„ì…ì """
    module = SmartCCTVModule()
    module.render()


if __name__ == "__main__":
    main()
