# Vision Transformer 시각적 다이어그램 모음

## 1. Vision Transformer 전체 아키텍처 다이어그램

```
입력 이미지 (224×224×3)
        │
        ├─────────────────────────────────────────┐
        │                                         │
        ▼                                         ▼
┌───────────────────┐                    ┌──────────────┐
│  Patch Embedding  │                    │ Linear Layer │
│  (16×16 patches)  │                    │  768 dims    │
└───────────────────┘                    └──────────────┘
        │                                         │
        │  196개 패치 생성                         │
        │  (14×14 = 196)                         │
        ▼                                         ▼
  [P1, P2, ..., P196]              각 패치를 768차원으로 변환
        │                                         │
        └─────────────────┬───────────────────────┘
                         │
                         ▼
              ┌───────────────────┐
              │  [CLS] 토큰 추가  │
              │  위치 임베딩 추가  │
              └───────────────────┘
                         │
                         ▼
          [CLS, P1, P2, ..., P196] + Position
                         │
                         ▼
        ╔═════════════════════════════════╗
        ║   Transformer Encoder (×12)     ║
        ║                                 ║
        ║  ┌─────────────────────────┐   ║
        ║  │  Multi-Head Attention   │   ║
        ║  │   (12 heads, 64 dims)   │   ║
        ║  └─────────────────────────┘   ║
        ║             │                   ║
        ║             ▼                   ║
        ║  ┌─────────────────────────┐   ║
        ║  │   Layer Normalization   │   ║
        ║  └─────────────────────────┘   ║
        ║             │                   ║
        ║             ▼                   ║
        ║  ┌─────────────────────────┐   ║
        ║  │   MLP (Feed Forward)    │   ║
        ║  │   768 → 3072 → 768      │   ║
        ║  └─────────────────────────┘   ║
        ║             │                   ║
        ║             ▼                   ║
        ║  ┌─────────────────────────┐   ║
        ║  │   Layer Normalization   │   ║
        ║  └─────────────────────────┘   ║
        ╚═════════════════════════════════╝
                         │
                         ▼
                  Layer Norm
                         │
                         ▼
              CLS 토큰만 추출 [0]
                         │
                         ▼
              ┌───────────────────┐
              │ Classification   │
              │ Head (Linear)    │
              │ 768 → 1000       │
              └───────────────────┘
                         │
                         ▼
                  분류 결과
              (1000개 클래스)
```

## 2. Self-Attention 메커니즘 상세 다이어그램

```
입력 시퀀스: [CLS, P1, P2, P3, ..., P196]
              │
              ├─────────┬─────────┬─────────┐
              │         │         │         │
              ▼         ▼         ▼         ▼
          Query(Q)   Key(K)   Value(V)  (각각 Linear 변환)
          W_q × X    W_k × X   W_v × X
              │         │         │
              │         │         │
              ▼         ▼         ▼
         [197×768] [197×768] [197×768]
              │         │         │
              └────┬────┘         │
                   │              │
                   ▼              │
           ┌──────────────┐      │
           │  Q × K^T     │      │
           │  (Dot Product)│     │
           └──────────────┘      │
                   │              │
                   ▼              │
           ┌──────────────┐      │
           │  ÷ √d_k      │      │
           │  (Scaling)   │      │
           └──────────────┘      │
                   │              │
                   ▼              │
           ┌──────────────┐      │
           │  Softmax     │      │
           │(확률 분포로 변환)│  │
           └──────────────┘      │
                   │              │
              Attention           │
               Weights            │
            [197×197]             │
                   │              │
                   └──────┬───────┘
                          │
                          ▼
                   ┌──────────────┐
                   │Attn_Weights×V│
                   │  (가중합)     │
                   └──────────────┘
                          │
                          ▼
                    출력 [197×768]



Attention Map 예시 (CLS 토큰 관점):

     P1   P2   P3   P4   ...  P196
CLS [0.05][0.12][0.03][0.08] ... [0.02]
     │    │    │    │         │
     └────┴────┴────┴─────────┘
     어느 패치에 얼마나 집중할지 결정
```

## 3. Multi-Head Attention 시각화

```
입력: [197×768]
        │
        ├──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐
        │      │      │      │      │      │      │      │      │
        ▼      ▼      ▼      ▼      ▼      ▼      ▼      ▼      ▼
     Head1  Head2  Head3  Head4  Head5  Head6  Head7  Head8  ...  Head12
     [64]   [64]   [64]   [64]   [64]   [64]   [64]   [64]  ...  [64]
        │      │      │      │      │      │      │      │      │
각 Head는 다른 관점에서 정보 처리:
        │      │      │      │      │      │      │      │      │
     공간적  색상   텍스처  형태   위치   크기   경계   패턴  ...  맥락
     관계   관계   관계   관계   관계   관계   관계   관계       정보
        │      │      │      │      │      │      │      │      │
        └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘
                                │
                                ▼
                          Concatenate
                                │
                                ▼
                         Linear Transform
                                │
                                ▼
                         출력 [197×768]
```

## 4. 패치 임베딩 과정 시각화

```
원본 이미지 (224×224×3)
┌─────────────────────────────────┐
│  R  G  B  R  G  B  R  G  B  ... │ ← 224 pixels
│  R  G  B  R  G  B  R  G  B  ... │
│  ...                            │
│  ...                            │
└─────────────────────────────────┘
           ↓ 16×16 패치로 분할

패치 분할 (14×14 = 196개 패치)
┌──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┐
│P1│P2│P3│P4│ ...              │P14│  ← Row 1
├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
│P15│  │  │  │ ...              │P28│  ← Row 2
├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
│...│  │  │  │ ...              │ . │
├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
│P183│ │  │  │ ...              │P196│ ← Row 14
└──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┘

각 패치 P1의 구조:
┌─────────────────┐
│ 16×16×3 pixels  │
│ = 768 values    │
└─────────────────┘
        ↓ Linear Projection (Conv2D or Linear)

768차원 임베딩 벡터
[v1, v2, v3, ..., v768]
```

## 5. 위치 임베딩 추가 과정

```
패치 임베딩                     위치 임베딩
[197×768]                      [197×768]
     │                              │
     │   P1  P2  P3  ...           │   Pos1 Pos2 Pos3 ...
     │   [768][768][768]...        │   [768][768][768]...
     │                              │
     └──────────┬───────────────────┘
                │
                ▼ Element-wise Addition

   패치 임베딩 + 위치 정보
        [197×768]

위치 임베딩의 역할:
┌──────────────────────────────────────┐
│  패치의 공간적 위치 정보 인코딩       │
│                                      │
│  예: P1 (좌상단) vs P196 (우하단)    │
│      서로 다른 위치 벡터를 가짐      │
│                                      │
│  학습 가능(Learnable) 또는           │
│  고정(Sinusoidal) 방식 사용          │
└──────────────────────────────────────┘
```

## 6. DINO 교사-학생 학습 구조

```
입력 이미지
      │
      ├──────────────────────────────┐
      │                              │
      ▼                              ▼
Global Crops (224×224)      Local Crops (96×96)
  (큰 이미지 2개)             (작은 이미지 8개)
      │                              │
      ├──────┬─────────┐             │
      ▼      ▼         ▼             ▼
    Crop1  Crop2    Crop3-10
      │      │         │
      │      │         │
      ▼      ▼         ▼
╔═══════════╗ ╔═══════════╗ ╔═══════════╗
║  Teacher  ║ ║  Student  ║ ║  Student  ║
║  Network  ║ ║  Network  ║ ║  Network  ║
║           ║ ║           ║ ║           ║
║ ViT-Base  ║ ║ ViT-Base  ║ ║ ViT-Base  ║
║(Frozen)   ║ ║(Trainable)║ ║(Trainable)║
╚═══════════╝ ╚═══════════╝ ╚═══════════╝
      │            │             │
      ▼            ▼             ▼
  Teacher      Student       Student
  Output       Output        Output
  (Target)   (Prediction)  (Prediction)
      │            │             │
      └────────┬───┴─────────────┘
               │
               ▼
        Cross-Entropy Loss
        (Student → Teacher)
               │
               ▼
         Backpropagation
        (Student만 업데이트)
               │
               ▼
        EMA Update Teacher
      (momentum = 0.996)

Teacher 업데이트 공식:
θ_teacher ← m·θ_teacher + (1-m)·θ_student
(m = 0.996, 매우 천천히 업데이트)
```

## 7. CNN vs Transformer 처리 방식 비교

```
CNN 방식:
────────────────────────────────────────

입력 이미지 (224×224)
        │
        ▼
┌──────────────────┐
│  3×3 Conv Layer  │ ← 지역적 수용 영역
│  (Local Receptive│    (9개 픽셀만 봄)
│   Field)         │
└──────────────────┘
        │
        ▼
┌──────────────────┐
│  Pooling         │ ← 점진적 축소
└──────────────────┘
        │
        ▼
   여러 층 반복
        │
        ▼
   전역 특징 생성


Transformer 방식:
────────────────────────────────────────

입력 이미지 (224×224)
        │
        ▼
196개 패치로 분할
        │
        ▼
┌──────────────────┐
│  Self-Attention  │ ← 전역적 수용 영역
│  (모든 패치와의   │    (196개 패치 모두 봄)
│   관계 계산)     │
└──────────────────┘
        │
        ▼
   한 번에 전역 특징


시각적 비교:

CNN:
[이미지] → [작은창] → [작은창] → [작은창] → ... → [전체]
          점진적으로 수용 영역 확장

Transformer:
[이미지] → [모든 패치 동시에 보기] → [전체]
          처음부터 전역 관계 파악
```

## 8. Attention Weights 시각화 예시

```
입력 이미지: 고양이 사진
┌─────────────────────────┐
│       고양이            │
│   ╱￣￣╲              │
│  │ ● ● │  배경        │
│   ╲  ▽ ╱              │
│    ￣￣               │
└─────────────────────────┘

Layer 1 Attention:
(저수준 특징 - 엣지, 텍스처)
┌─────────────────────────┐
│  ████                   │ ← 윤곽선에 집중
│  █  █                   │
│  █  █                   │
│  ████                   │
└─────────────────────────┘

Layer 6 Attention:
(중간 수준 특징 - 부분)
┌─────────────────────────┐
│  ████████               │ ← 얼굴 전체에 집중
│  ████████               │
│  ████████               │
│    ████                 │
└─────────────────────────┘

Layer 12 Attention:
(고수준 특징 - 객체)
┌─────────────────────────┐
│  ████████               │ ← 고양이 전체에 집중
│  ████████               │
│  ████████████           │
│  ████████████           │
└─────────────────────────┘

색상 범례:
█ = 높은 attention (0.8-1.0)
▓ = 중간 attention (0.4-0.8)
░ = 낮은 attention (0.0-0.4)
```

## 9. ViT 모델 크기 비교

```
모델 사양 비교표:
═══════════════════════════════════════════════════════════

Model       Layers  Hidden  Heads  Params   ImageNet
                    Size           (M)      Acc(%)
───────────────────────────────────────────────────────
ViT-Tiny      12     192      3      5.5      72.2
ViT-Small     12     384      6     22.1      79.9
ViT-Base      12     768     12     86.6      81.8
ViT-Large     24    1024     16    304.3      82.6
ViT-Huge      32    1280     16    632.0      83.1
───────────────────────────────────────────────────────

시각적 크기 비교:

Tiny:   ▓
Small:  ▓▓▓▓
Base:   ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
Large:  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
Huge:   ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
```

## 10. 실제 이미지 처리 흐름도

```
사용자 입력
     │
     ▼
┌──────────────────────────┐
│ 이미지 로드              │
│ (PIL.Image)              │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ 전처리                   │
│ - Resize (224×224)       │
│ - Normalize              │
│ - To Tensor              │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ Patch Embedding          │
│ - 16×16 패치 분할        │
│ - Linear Projection      │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ Add Position Embedding   │
│ Add CLS Token            │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ Transformer Encoder      │
│ (12 layers)              │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ Classification Head      │
│ (Linear Layer)           │
└──────────────────────────┘
     │
     ▼
┌──────────────────────────┐
│ 결과 출력                │
│ - Top-5 클래스           │
│ - 확률 분포              │
└──────────────────────────┘
```
