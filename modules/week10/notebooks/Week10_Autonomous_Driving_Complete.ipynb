{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 10: 자율주행 인식 시스템 (Complete)\n",
        "\n",
        "## 목차\n",
        "1. 환경 설정 및 설치\n",
        "2. 차선 인식 (Tier 1-3 비교)\n",
        "3. 객체 탐지 (YOLOv8)\n",
        "4. 객체 추적 (ByteTrack)\n",
        "5. 거리 추정 (IPM)\n",
        "6. 통합 시스템 (완전판)\n",
        "7. 성능 벤치마크\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 환경 설정 및 설치"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install -q opencv-python ultralytics numpy matplotlib\n",
        "\n",
        "# ByteTrack (선택적)\n",
        "!pip install -q git+https://github.com/ifzhang/ByteTrack.git\n",
        "\n",
        "print(\"✅ 설치 완료!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "print(\"✅ 임포트 완료!\")"
      ],
      "metadata": {
        "id": "import"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 영상 다운로드\n",
        "!wget -q https://hsackr-my.sharepoint.com/your-road-video.mp4 -O road_video.mp4\n",
        "# 또는 본인의 영상 업로드\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()  # 파일 업로드\n",
        "\n",
        "print(\"✅ 영상 준비 완료!\")"
      ],
      "metadata": {
        "id": "data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 차선 인식 (Tier 1-3 비교)"
      ],
      "metadata": {
        "id": "lane"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 1: Hough Transform (직선 차선)"
      ],
      "metadata": {
        "id": "tier1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_lanes_hough(frame):\n",
        "    \"\"\"Tier 1: Hough Transform 차선 인식\"\"\"\n",
        "    \n",
        "    # 1. 전처리\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    # 2. Canny Edge\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    \n",
        "    # 3. ROI 설정\n",
        "    height, width = frame.shape[:2]\n",
        "    roi_vertices = np.array([[\n",
        "        (0, height),\n",
        "        (width//2, height//2),\n",
        "        (width, height)\n",
        "    ]], dtype=np.int32)\n",
        "    \n",
        "    mask = np.zeros_like(edges)\n",
        "    cv2.fillPoly(mask, roi_vertices, 255)\n",
        "    masked_edges = cv2.bitwise_and(edges, mask)\n",
        "    \n",
        "    # 4. Hough Transform\n",
        "    lines = cv2.HoughLinesP(\n",
        "        masked_edges,\n",
        "        rho=2,\n",
        "        theta=np.pi/180,\n",
        "        threshold=50,\n",
        "        minLineLength=40,\n",
        "        maxLineGap=100\n",
        "    )\n",
        "    \n",
        "    # 5. 시각화\n",
        "    line_image = np.zeros_like(frame)\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "    \n",
        "    result = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "    return result\n",
        "\n",
        "\n",
        "# 테스트\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = detect_lanes_hough(frame)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Tier 1: Hough Transform')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"❌ 프레임 읽기 실패\")"
      ],
      "metadata": {
        "id": "tier1_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 2: Polynomial Fitting (곡선 차선)"
      ],
      "metadata": {
        "id": "tier2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_lanes_polynomial(frame):\n",
        "    \"\"\"Tier 2: Polynomial Fitting 차선 인식\"\"\"\n",
        "    \n",
        "    # 1. 전처리\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    \n",
        "    # 2. Perspective Transform\n",
        "    height, width = frame.shape[:2]\n",
        "    src = np.float32([\n",
        "        [width * 0.2, height],\n",
        "        [width * 0.45, height * 0.6],\n",
        "        [width * 0.55, height * 0.6],\n",
        "        [width * 0.8, height]\n",
        "    ])\n",
        "    dst = np.float32([\n",
        "        [width * 0.2, height],\n",
        "        [width * 0.2, 0],\n",
        "        [width * 0.8, 0],\n",
        "        [width * 0.8, height]\n",
        "    ])\n",
        "    \n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(edges, M, (width, height))\n",
        "    \n",
        "    # 3. Histogram\n",
        "    histogram = np.sum(warped[height//2:, :], axis=0)\n",
        "    midpoint = len(histogram) // 2\n",
        "    left_base = np.argmax(histogram[:midpoint])\n",
        "    right_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "    \n",
        "    # 4. Sliding Window (간략화)\n",
        "    nwindows = 9\n",
        "    window_height = height // nwindows\n",
        "    margin = 100\n",
        "    minpix = 50\n",
        "    \n",
        "    nonzero = warped.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "    \n",
        "    left_current = left_base\n",
        "    right_current = right_base\n",
        "    \n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "    \n",
        "    for window in range(nwindows):\n",
        "        win_y_low = height - (window + 1) * window_height\n",
        "        win_y_high = height - window * window_height\n",
        "        \n",
        "        win_xleft_low = left_current - margin\n",
        "        win_xleft_high = left_current + margin\n",
        "        win_xright_low = right_current - margin\n",
        "        win_xright_high = right_current + margin\n",
        "        \n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "        \n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "        \n",
        "        if len(good_left_inds) > minpix:\n",
        "            left_current = int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "            right_current = int(np.mean(nonzerox[good_right_inds]))\n",
        "    \n",
        "    # 5. Polynomial Fitting\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "    \n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "    \n",
        "    if len(leftx) > 0 and len(rightx) > 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "        \n",
        "        ploty = np.linspace(0, height-1, height)\n",
        "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
        "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "        \n",
        "        # 6. 시각화\n",
        "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
        "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "        \n",
        "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "        pts = np.hstack((pts_left, pts_right))\n",
        "        \n",
        "        cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
        "        \n",
        "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
        "        newwarp = cv2.warpPerspective(color_warp, Minv, (width, height))\n",
        "        \n",
        "        result = cv2.addWeighted(frame, 1, newwarp, 0.3, 0)\n",
        "        return result\n",
        "    \n",
        "    return frame\n",
        "\n",
        "\n",
        "# 테스트\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = detect_lanes_polynomial(frame)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Tier 2: Polynomial Fitting')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tier2_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 1 vs Tier 2 비교"
      ],
      "metadata": {
        "id": "compare_tiers"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FPS 비교\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "# Tier 1 FPS\n",
        "start = time.time()\n",
        "count = 0\n",
        "while count < 100:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = detect_lanes_hough(frame)\n",
        "    count += 1\n",
        "tier1_time = time.time() - start\n",
        "tier1_fps = 100 / tier1_time\n",
        "\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # 처음으로\n",
        "\n",
        "# Tier 2 FPS\n",
        "start = time.time()\n",
        "count = 0\n",
        "while count < 100:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = detect_lanes_polynomial(frame)\n",
        "    count += 1\n",
        "tier2_time = time.time() - start\n",
        "tier2_fps = 100 / tier2_time\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"Tier 1 (Hough): {tier1_fps:.1f} FPS\")\n",
        "print(f\"Tier 2 (Polynomial): {tier2_fps:.1f} FPS\")\n",
        "print(f\"속도 차이: {tier1_fps/tier2_fps:.1f}배\")"
      ],
      "metadata": {
        "id": "compare"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 객체 탐지 (YOLOv8)"
      ],
      "metadata": {
        "id": "yolo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 모델 다운로드\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# YOLOv8m 모델 (중간 크기)\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "print(\"✅ YOLOv8 모델 로드 완료!\")"
      ],
      "metadata": {
        "id": "yolo_load"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 테스트\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    # 추론\n",
        "    results = model(frame, conf=0.3)\n",
        "    \n",
        "    # 시각화\n",
        "    annotated = results[0].plot()\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('YOLOv8 Object Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    # 탐지된 객체 출력\n",
        "    print(\"\\n탐지된 객체:\")\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            label = model.names[cls]\n",
        "            print(f\"  - {label}: {conf:.2f}\")"
      ],
      "metadata": {
        "id": "yolo_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 객체 추적 (ByteTrack) - 간단 버전"
      ],
      "metadata": {
        "id": "track"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 추적 (ByteTrack 없이 IoU 기반)\n",
        "class SimpleTracker:\n",
        "    def __init__(self):\n",
        "        self.tracks = {}\n",
        "        self.next_id = 1\n",
        "    \n",
        "    def iou(self, box1, box2):\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "        \n",
        "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0\n",
        "    \n",
        "    def update(self, detections):\n",
        "        if len(self.tracks) == 0:\n",
        "            for det in detections:\n",
        "                self.tracks[self.next_id] = det\n",
        "                self.next_id += 1\n",
        "            return self.tracks\n",
        "        \n",
        "        # 매칭\n",
        "        new_tracks = {}\n",
        "        used_dets = set()\n",
        "        \n",
        "        for track_id, track_box in self.tracks.items():\n",
        "            best_iou = 0\n",
        "            best_det_idx = -1\n",
        "            \n",
        "            for i, det in enumerate(detections):\n",
        "                if i in used_dets:\n",
        "                    continue\n",
        "                iou_score = self.iou(track_box, det)\n",
        "                if iou_score > best_iou:\n",
        "                    best_iou = iou_score\n",
        "                    best_det_idx = i\n",
        "            \n",
        "            if best_iou > 0.3:\n",
        "                new_tracks[track_id] = detections[best_det_idx]\n",
        "                used_dets.add(best_det_idx)\n",
        "        \n",
        "        # 새 객체\n",
        "        for i, det in enumerate(detections):\n",
        "            if i not in used_dets:\n",
        "                new_tracks[self.next_id] = det\n",
        "                self.next_id += 1\n",
        "        \n",
        "        self.tracks = new_tracks\n",
        "        return self.tracks\n",
        "\n",
        "\n",
        "# 테스트\n",
        "tracker = SimpleTracker()\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "for i in range(10):  # 10프레임만\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    # YOLOv8 탐지\n",
        "    results = model(frame, verbose=False)\n",
        "    \n",
        "    # 박스 추출\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            detections.append([x1, y1, x2, y2])\n",
        "    \n",
        "    # 추적 업데이트\n",
        "    tracks = tracker.update(detections)\n",
        "    \n",
        "    # 시각화\n",
        "    for track_id, bbox in tracks.items():\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (x1, y1-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 마지막 프레임 표시\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Simple Tracking')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "track_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 거리 추정 (IPM)"
      ],
      "metadata": {
        "id": "distance"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_distance(bbox_bottom_y, image_height=720):\n",
        "    \"\"\"간단한 거리 추정\"\"\"\n",
        "    horizon_y = image_height * 0.5\n",
        "    \n",
        "    if bbox_bottom_y <= horizon_y:\n",
        "        return float('inf')\n",
        "    \n",
        "    distance = (image_height - horizon_y) / (bbox_bottom_y - horizon_y)\n",
        "    distance *= 50  # 스케일 (캘리브레이션 필요)\n",
        "    \n",
        "    return min(distance, 100)\n",
        "\n",
        "\n",
        "# 테스트\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    height, width = frame.shape[:2]\n",
        "    results = model(frame, verbose=False)\n",
        "    \n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            label = model.names[cls]\n",
        "            \n",
        "            # 거리 추정\n",
        "            distance = estimate_distance(y2, height)\n",
        "            \n",
        "            # 색상 (거리별)\n",
        "            if distance < 10:\n",
        "                color = (0, 0, 255)  # 빨강\n",
        "            elif distance < 20:\n",
        "                color = (0, 165, 255)  # 주황\n",
        "            else:\n",
        "                color = (0, 255, 0)  # 초록\n",
        "            \n",
        "            # 그리기\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, f\"{label} {distance:.1f}m\", (x1, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Distance Estimation')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "distance_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 통합 시스템 (완전판)"
      ],
      "metadata": {
        "id": "integrated"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 통합 시스템\n",
        "class AutonomousDrivingSystem:\n",
        "    def __init__(self, model_path='yolov8m.pt'):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.tracker = SimpleTracker()\n",
        "        self.track_history = {}\n",
        "    \n",
        "    def process_frame(self, frame):\n",
        "        height, width = frame.shape[:2]\n",
        "        \n",
        "        # 1. 차선 인식\n",
        "        lane_frame = detect_lanes_hough(frame.copy())\n",
        "        \n",
        "        # 2. 객체 탐지\n",
        "        results = self.model(frame, verbose=False)\n",
        "        \n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                detections.append([x1, y1, x2, y2, cls, conf])\n",
        "        \n",
        "        # 3. 추적\n",
        "        det_boxes = [[d[0], d[1], d[2], d[3]] for d in detections]\n",
        "        tracks = self.tracker.update(det_boxes)\n",
        "        \n",
        "        # 4. 시각화\n",
        "        output = lane_frame\n",
        "        \n",
        "        for track_id, bbox in tracks.items():\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            \n",
        "            # 거리 추정\n",
        "            distance = estimate_distance(y2, height)\n",
        "            \n",
        "            # 위험도\n",
        "            if distance < 10:\n",
        "                color = (0, 0, 255)\n",
        "                risk = \"HIGH\"\n",
        "            elif distance < 20:\n",
        "                color = (0, 165, 255)\n",
        "                risk = \"MEDIUM\"\n",
        "            else:\n",
        "                color = (0, 255, 0)\n",
        "                risk = \"LOW\"\n",
        "            \n",
        "            # 그리기\n",
        "            cv2.rectangle(output, (x1, y1), (x2, y2), color, 2)\n",
        "            label = f\"ID:{track_id} {distance:.1f}m {risk}\"\n",
        "            cv2.putText(output, label, (x1, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "# 실행\n",
        "system = AutonomousDrivingSystem('yolov8m.pt')\n",
        "\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = system.process_frame(frame)\n",
        "    \n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Integrated Autonomous Driving System')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "integrated_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 성능 벤치마크"
      ],
      "metadata": {
        "id": "benchmark"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 시스템 FPS 측정\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "start = time.time()\n",
        "count = 0\n",
        "\n",
        "while count < 50:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = system.process_frame(frame)\n",
        "    count += 1\n",
        "\n",
        "total_time = time.time() - start\n",
        "fps = 50 / total_time\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"\\n🚀 성능 벤치마크 (Google Colab T4 GPU)\")\n",
        "print(f\"  - 총 처리 시간: {total_time:.2f}초\")\n",
        "print(f\"  - FPS: {fps:.1f}\")\n",
        "print(f\"  - 프레임당 시간: {1000/fps:.1f}ms\")\n",
        "print(f\"\\n💡 실시간 처리 기준: 30 FPS (33.3ms/frame)\")\n",
        "\n",
        "if fps >= 30:\n",
        "    print(\"  ✅ 실시간 처리 가능!\")\n",
        "else:\n",
        "    print(\"  ⚠️ 최적화 필요\")"
      ],
      "metadata": {
        "id": "benchmark_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 과제 및 다음 단계\n",
        "\n",
        "### 과제\n",
        "1. **Tier 3 딥러닝 차선 인식**: HuggingFace Segformer 적용\n",
        "2. **ByteTrack 통합**: 공식 ByteTrack 라이브러리 사용\n",
        "3. **카메라 캘리브레이션**: 체스보드로 정확한 거리 계산\n",
        "4. **TensorRT 최적화**: YOLOv8 → TensorRT 변환\n",
        "5. **BEV 시각화**: Bird's Eye View 변환 구현\n",
        "\n",
        "### 참고 자료\n",
        "- [YOLOv8 공식 문서](https://docs.ultralytics.com/)\n",
        "- [ByteTrack GitHub](https://github.com/ifzhang/ByteTrack)\n",
        "- [TuSimple Lane Detection Dataset](https://github.com/TuSimple/tusimple-benchmark)\n",
        "- [Week 10 강의 자료](lecture_slides.md)\n",
        "\n",
        "---\n",
        "\n",
        "**완성!** 🎉\n",
        "\n",
        "이 노트북은 자율주행 인식 시스템의 핵심 기능을 모두 포함합니다.\n",
        "실제 프로젝트에 적용하여 더 발전시켜 보세요!"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
