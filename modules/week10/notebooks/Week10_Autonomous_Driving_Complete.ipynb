{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 10: ììœ¨ì£¼í–‰ ì¸ì‹ ì‹œìŠ¤í…œ (Complete)\n",
        "\n",
        "## ëª©ì°¨\n",
        "1. í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜\n",
        "2. ì°¨ì„  ì¸ì‹ (Tier 1-3 ë¹„êµ)\n",
        "3. ê°ì²´ íƒì§€ (YOLOv8)\n",
        "4. ê°ì²´ ì¶”ì  (ByteTrack)\n",
        "5. ê±°ë¦¬ ì¶”ì • (IPM)\n",
        "6. í†µí•© ì‹œìŠ¤í…œ (ì™„ì „íŒ)\n",
        "7. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q opencv-python ultralytics numpy matplotlib\n",
        "\n",
        "# ByteTrack (ì„ íƒì )\n",
        "!pip install -q git+https://github.com/ifzhang/ByteTrack.git\n",
        "\n",
        "print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "print(\"âœ… ì„í¬íŠ¸ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "import"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìƒ˜í”Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ\n",
        "!wget -q https://hsackr-my.sharepoint.com/your-road-video.mp4 -O road_video.mp4\n",
        "# ë˜ëŠ” ë³¸ì¸ì˜ ì˜ìƒ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()  # íŒŒì¼ ì—…ë¡œë“œ\n",
        "\n",
        "print(\"âœ… ì˜ìƒ ì¤€ë¹„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ì°¨ì„  ì¸ì‹ (Tier 1-3 ë¹„êµ)"
      ],
      "metadata": {
        "id": "lane"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 1: Hough Transform (ì§ì„  ì°¨ì„ )"
      ],
      "metadata": {
        "id": "tier1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_lanes_hough(frame):\n",
        "    \"\"\"Tier 1: Hough Transform ì°¨ì„  ì¸ì‹\"\"\"\n",
        "    \n",
        "    # 1. ì „ì²˜ë¦¬\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    # 2. Canny Edge\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    \n",
        "    # 3. ROI ì„¤ì •\n",
        "    height, width = frame.shape[:2]\n",
        "    roi_vertices = np.array([[\n",
        "        (0, height),\n",
        "        (width//2, height//2),\n",
        "        (width, height)\n",
        "    ]], dtype=np.int32)\n",
        "    \n",
        "    mask = np.zeros_like(edges)\n",
        "    cv2.fillPoly(mask, roi_vertices, 255)\n",
        "    masked_edges = cv2.bitwise_and(edges, mask)\n",
        "    \n",
        "    # 4. Hough Transform\n",
        "    lines = cv2.HoughLinesP(\n",
        "        masked_edges,\n",
        "        rho=2,\n",
        "        theta=np.pi/180,\n",
        "        threshold=50,\n",
        "        minLineLength=40,\n",
        "        maxLineGap=100\n",
        "    )\n",
        "    \n",
        "    # 5. ì‹œê°í™”\n",
        "    line_image = np.zeros_like(frame)\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "    \n",
        "    result = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "    return result\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = detect_lanes_hough(frame)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Tier 1: Hough Transform')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨\")"
      ],
      "metadata": {
        "id": "tier1_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 2: Polynomial Fitting (ê³¡ì„  ì°¨ì„ )"
      ],
      "metadata": {
        "id": "tier2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_lanes_polynomial(frame):\n",
        "    \"\"\"Tier 2: Polynomial Fitting ì°¨ì„  ì¸ì‹\"\"\"\n",
        "    \n",
        "    # 1. ì „ì²˜ë¦¬\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    \n",
        "    # 2. Perspective Transform\n",
        "    height, width = frame.shape[:2]\n",
        "    src = np.float32([\n",
        "        [width * 0.2, height],\n",
        "        [width * 0.45, height * 0.6],\n",
        "        [width * 0.55, height * 0.6],\n",
        "        [width * 0.8, height]\n",
        "    ])\n",
        "    dst = np.float32([\n",
        "        [width * 0.2, height],\n",
        "        [width * 0.2, 0],\n",
        "        [width * 0.8, 0],\n",
        "        [width * 0.8, height]\n",
        "    ])\n",
        "    \n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(edges, M, (width, height))\n",
        "    \n",
        "    # 3. Histogram\n",
        "    histogram = np.sum(warped[height//2:, :], axis=0)\n",
        "    midpoint = len(histogram) // 2\n",
        "    left_base = np.argmax(histogram[:midpoint])\n",
        "    right_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "    \n",
        "    # 4. Sliding Window (ê°„ëµí™”)\n",
        "    nwindows = 9\n",
        "    window_height = height // nwindows\n",
        "    margin = 100\n",
        "    minpix = 50\n",
        "    \n",
        "    nonzero = warped.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "    \n",
        "    left_current = left_base\n",
        "    right_current = right_base\n",
        "    \n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "    \n",
        "    for window in range(nwindows):\n",
        "        win_y_low = height - (window + 1) * window_height\n",
        "        win_y_high = height - window * window_height\n",
        "        \n",
        "        win_xleft_low = left_current - margin\n",
        "        win_xleft_high = left_current + margin\n",
        "        win_xright_low = right_current - margin\n",
        "        win_xright_high = right_current + margin\n",
        "        \n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "        \n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "        \n",
        "        if len(good_left_inds) > minpix:\n",
        "            left_current = int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "            right_current = int(np.mean(nonzerox[good_right_inds]))\n",
        "    \n",
        "    # 5. Polynomial Fitting\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "    \n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "    \n",
        "    if len(leftx) > 0 and len(rightx) > 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "        \n",
        "        ploty = np.linspace(0, height-1, height)\n",
        "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
        "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "        \n",
        "        # 6. ì‹œê°í™”\n",
        "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
        "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "        \n",
        "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "        pts = np.hstack((pts_left, pts_right))\n",
        "        \n",
        "        cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
        "        \n",
        "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
        "        newwarp = cv2.warpPerspective(color_warp, Minv, (width, height))\n",
        "        \n",
        "        result = cv2.addWeighted(frame, 1, newwarp, 0.3, 0)\n",
        "        return result\n",
        "    \n",
        "    return frame\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = detect_lanes_polynomial(frame)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Tier 2: Polynomial Fitting')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tier2_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tier 1 vs Tier 2 ë¹„êµ"
      ],
      "metadata": {
        "id": "compare_tiers"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FPS ë¹„êµ\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "# Tier 1 FPS\n",
        "start = time.time()\n",
        "count = 0\n",
        "while count < 100:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = detect_lanes_hough(frame)\n",
        "    count += 1\n",
        "tier1_time = time.time() - start\n",
        "tier1_fps = 100 / tier1_time\n",
        "\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # ì²˜ìŒìœ¼ë¡œ\n",
        "\n",
        "# Tier 2 FPS\n",
        "start = time.time()\n",
        "count = 0\n",
        "while count < 100:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = detect_lanes_polynomial(frame)\n",
        "    count += 1\n",
        "tier2_time = time.time() - start\n",
        "tier2_fps = 100 / tier2_time\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"Tier 1 (Hough): {tier1_fps:.1f} FPS\")\n",
        "print(f\"Tier 2 (Polynomial): {tier2_fps:.1f} FPS\")\n",
        "print(f\"ì†ë„ ì°¨ì´: {tier1_fps/tier2_fps:.1f}ë°°\")"
      ],
      "metadata": {
        "id": "compare"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ê°ì²´ íƒì§€ (YOLOv8)"
      ],
      "metadata": {
        "id": "yolo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# YOLOv8m ëª¨ë¸ (ì¤‘ê°„ í¬ê¸°)\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "print(\"âœ… YOLOv8 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "yolo_load"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 í…ŒìŠ¤íŠ¸\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    # ì¶”ë¡ \n",
        "    results = model(frame, conf=0.3)\n",
        "    \n",
        "    # ì‹œê°í™”\n",
        "    annotated = results[0].plot()\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('YOLOv8 Object Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    # íƒì§€ëœ ê°ì²´ ì¶œë ¥\n",
        "    print(\"\\níƒì§€ëœ ê°ì²´:\")\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            label = model.names[cls]\n",
        "            print(f\"  - {label}: {conf:.2f}\")"
      ],
      "metadata": {
        "id": "yolo_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ê°ì²´ ì¶”ì  (ByteTrack) - ê°„ë‹¨ ë²„ì „"
      ],
      "metadata": {
        "id": "track"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê°„ë‹¨í•œ ì¶”ì  (ByteTrack ì—†ì´ IoU ê¸°ë°˜)\n",
        "class SimpleTracker:\n",
        "    def __init__(self):\n",
        "        self.tracks = {}\n",
        "        self.next_id = 1\n",
        "    \n",
        "    def iou(self, box1, box2):\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "        \n",
        "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0\n",
        "    \n",
        "    def update(self, detections):\n",
        "        if len(self.tracks) == 0:\n",
        "            for det in detections:\n",
        "                self.tracks[self.next_id] = det\n",
        "                self.next_id += 1\n",
        "            return self.tracks\n",
        "        \n",
        "        # ë§¤ì¹­\n",
        "        new_tracks = {}\n",
        "        used_dets = set()\n",
        "        \n",
        "        for track_id, track_box in self.tracks.items():\n",
        "            best_iou = 0\n",
        "            best_det_idx = -1\n",
        "            \n",
        "            for i, det in enumerate(detections):\n",
        "                if i in used_dets:\n",
        "                    continue\n",
        "                iou_score = self.iou(track_box, det)\n",
        "                if iou_score > best_iou:\n",
        "                    best_iou = iou_score\n",
        "                    best_det_idx = i\n",
        "            \n",
        "            if best_iou > 0.3:\n",
        "                new_tracks[track_id] = detections[best_det_idx]\n",
        "                used_dets.add(best_det_idx)\n",
        "        \n",
        "        # ìƒˆ ê°ì²´\n",
        "        for i, det in enumerate(detections):\n",
        "            if i not in used_dets:\n",
        "                new_tracks[self.next_id] = det\n",
        "                self.next_id += 1\n",
        "        \n",
        "        self.tracks = new_tracks\n",
        "        return self.tracks\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "tracker = SimpleTracker()\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "for i in range(10):  # 10í”„ë ˆì„ë§Œ\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    # YOLOv8 íƒì§€\n",
        "    results = model(frame, verbose=False)\n",
        "    \n",
        "    # ë°•ìŠ¤ ì¶”ì¶œ\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            detections.append([x1, y1, x2, y2])\n",
        "    \n",
        "    # ì¶”ì  ì—…ë°ì´íŠ¸\n",
        "    tracks = tracker.update(detections)\n",
        "    \n",
        "    # ì‹œê°í™”\n",
        "    for track_id, bbox in tracks.items():\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (x1, y1-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# ë§ˆì§€ë§‰ í”„ë ˆì„ í‘œì‹œ\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Simple Tracking')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "track_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ê±°ë¦¬ ì¶”ì • (IPM)"
      ],
      "metadata": {
        "id": "distance"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_distance(bbox_bottom_y, image_height=720):\n",
        "    \"\"\"ê°„ë‹¨í•œ ê±°ë¦¬ ì¶”ì •\"\"\"\n",
        "    horizon_y = image_height * 0.5\n",
        "    \n",
        "    if bbox_bottom_y <= horizon_y:\n",
        "        return float('inf')\n",
        "    \n",
        "    distance = (image_height - horizon_y) / (bbox_bottom_y - horizon_y)\n",
        "    distance *= 50  # ìŠ¤ì¼€ì¼ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)\n",
        "    \n",
        "    return min(distance, 100)\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    height, width = frame.shape[:2]\n",
        "    results = model(frame, verbose=False)\n",
        "    \n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            label = model.names[cls]\n",
        "            \n",
        "            # ê±°ë¦¬ ì¶”ì •\n",
        "            distance = estimate_distance(y2, height)\n",
        "            \n",
        "            # ìƒ‰ìƒ (ê±°ë¦¬ë³„)\n",
        "            if distance < 10:\n",
        "                color = (0, 0, 255)  # ë¹¨ê°•\n",
        "            elif distance < 20:\n",
        "                color = (0, 165, 255)  # ì£¼í™©\n",
        "            else:\n",
        "                color = (0, 255, 0)  # ì´ˆë¡\n",
        "            \n",
        "            # ê·¸ë¦¬ê¸°\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, f\"{label} {distance:.1f}m\", (x1, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Distance Estimation')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "distance_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. í†µí•© ì‹œìŠ¤í…œ (ì™„ì „íŒ)"
      ],
      "metadata": {
        "id": "integrated"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ í†µí•© ì‹œìŠ¤í…œ\n",
        "class AutonomousDrivingSystem:\n",
        "    def __init__(self, model_path='yolov8m.pt'):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.tracker = SimpleTracker()\n",
        "        self.track_history = {}\n",
        "    \n",
        "    def process_frame(self, frame):\n",
        "        height, width = frame.shape[:2]\n",
        "        \n",
        "        # 1. ì°¨ì„  ì¸ì‹\n",
        "        lane_frame = detect_lanes_hough(frame.copy())\n",
        "        \n",
        "        # 2. ê°ì²´ íƒì§€\n",
        "        results = self.model(frame, verbose=False)\n",
        "        \n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                detections.append([x1, y1, x2, y2, cls, conf])\n",
        "        \n",
        "        # 3. ì¶”ì \n",
        "        det_boxes = [[d[0], d[1], d[2], d[3]] for d in detections]\n",
        "        tracks = self.tracker.update(det_boxes)\n",
        "        \n",
        "        # 4. ì‹œê°í™”\n",
        "        output = lane_frame\n",
        "        \n",
        "        for track_id, bbox in tracks.items():\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            \n",
        "            # ê±°ë¦¬ ì¶”ì •\n",
        "            distance = estimate_distance(y2, height)\n",
        "            \n",
        "            # ìœ„í—˜ë„\n",
        "            if distance < 10:\n",
        "                color = (0, 0, 255)\n",
        "                risk = \"HIGH\"\n",
        "            elif distance < 20:\n",
        "                color = (0, 165, 255)\n",
        "                risk = \"MEDIUM\"\n",
        "            else:\n",
        "                color = (0, 255, 0)\n",
        "                risk = \"LOW\"\n",
        "            \n",
        "            # ê·¸ë¦¬ê¸°\n",
        "            cv2.rectangle(output, (x1, y1), (x2, y2), color, 2)\n",
        "            label = f\"ID:{track_id} {distance:.1f}m {risk}\"\n",
        "            cv2.putText(output, label, (x1, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "# ì‹¤í–‰\n",
        "system = AutonomousDrivingSystem('yolov8m.pt')\n",
        "\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    result = system.process_frame(frame)\n",
        "    \n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Integrated Autonomous Driving System')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "integrated_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
      ],
      "metadata": {
        "id": "benchmark"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ ì‹œìŠ¤í…œ FPS ì¸¡ì •\n",
        "cap = cv2.VideoCapture('road_video.mp4')\n",
        "\n",
        "start = time.time()\n",
        "count = 0\n",
        "\n",
        "while count < 50:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    _ = system.process_frame(frame)\n",
        "    count += 1\n",
        "\n",
        "total_time = time.time() - start\n",
        "fps = 50 / total_time\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"\\nğŸš€ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (Google Colab T4 GPU)\")\n",
        "print(f\"  - ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ\")\n",
        "print(f\"  - FPS: {fps:.1f}\")\n",
        "print(f\"  - í”„ë ˆì„ë‹¹ ì‹œê°„: {1000/fps:.1f}ms\")\n",
        "print(f\"\\nğŸ’¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê¸°ì¤€: 30 FPS (33.3ms/frame)\")\n",
        "\n",
        "if fps >= 30:\n",
        "    print(\"  âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥!\")\n",
        "else:\n",
        "    print(\"  âš ï¸ ìµœì í™” í•„ìš”\")"
      ],
      "metadata": {
        "id": "benchmark_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. ê³¼ì œ ë° ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "### ê³¼ì œ\n",
        "1. **Tier 3 ë”¥ëŸ¬ë‹ ì°¨ì„  ì¸ì‹**: HuggingFace Segformer ì ìš©\n",
        "2. **ByteTrack í†µí•©**: ê³µì‹ ByteTrack ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n",
        "3. **ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜**: ì²´ìŠ¤ë³´ë“œë¡œ ì •í™•í•œ ê±°ë¦¬ ê³„ì‚°\n",
        "4. **TensorRT ìµœì í™”**: YOLOv8 â†’ TensorRT ë³€í™˜\n",
        "5. **BEV ì‹œê°í™”**: Bird's Eye View ë³€í™˜ êµ¬í˜„\n",
        "\n",
        "### ì°¸ê³  ìë£Œ\n",
        "- [YOLOv8 ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com/)\n",
        "- [ByteTrack GitHub](https://github.com/ifzhang/ByteTrack)\n",
        "- [TuSimple Lane Detection Dataset](https://github.com/TuSimple/tusimple-benchmark)\n",
        "- [Week 10 ê°•ì˜ ìë£Œ](lecture_slides.md)\n",
        "\n",
        "---\n",
        "\n",
        "**ì™„ì„±!** ğŸ‰\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ììœ¨ì£¼í–‰ ì¸ì‹ ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.\n",
        "ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•˜ì—¬ ë” ë°œì „ì‹œì¼œ ë³´ì„¸ìš”!"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
