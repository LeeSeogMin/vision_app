"""
Week 9: ìƒì„± ëª¨ë¸ ì´ë¡  + Stable Diffusion (Streamlit Module)

ê¸°ëŠ¥ íƒ­
- ğŸ“š ê°œë… ì†Œê°œ
- ğŸ§ª Diffusers ë°ëª¨
- âœï¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- â±ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ
- ğŸ§© ControlNet/Adapter
- ğŸ—ºï¸ ComfyUI ê°€ì´ë“œ
"""

from typing import Dict, Any, Optional
import os
import io

import streamlit as st
from PIL import Image

from core.base_processor import BaseImageProcessor


class GenerationModule(BaseImageProcessor):
    """Week 9 Streamlit UI module for text-to-image generation."""

    def __init__(self):
        super().__init__()
        self.name = 'Week 9: Text-to-Image Generation'

    def render(self):
        st.title('ğŸ§ª Week 9: Stable Diffusion & Diffusers')
        st.caption('ë¬´ë£Œ í™˜ê²½(Colab) + Hugging Face Diffusers ì¤‘ì‹¬ì˜ ì‹¤ìŠµ')

        # í™˜ê²½ ì²´í¬ íŒ¨ë„
        self._display_environment_status()

        tabs = st.tabs([
            'ğŸ“š ê°œë… ì†Œê°œ',
            'ğŸ› ï¸ ë°©ë²•(Colab/ë¡œì»¬)',
            'ğŸ§ª Diffusers ë°ëª¨',
            'âœï¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§',
            'â±ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ',
            'ğŸ§© ControlNet/Adapter',
            'ğŸ—ºï¸ ComfyUI ê°€ì´ë“œ',
        ])

        with tabs[0]:
            self.render_theory()
        with tabs[1]:
            self.render_method()
        with tabs[2]:
            self.render_diffusers_demo()
        with tabs[3]:
            self.render_prompt_lab()
        with tabs[4]:
            self.render_scheduler_lab()
        with tabs[5]:
            self.render_controlnet_lab()
        with tabs[6]:
            self.render_comfyui_guide()

    def render_theory(self):
        st.header('ğŸ“š ìƒì„± ëª¨ë¸ ì´ë¡  + Stable Diffusion')

        st.markdown("""
        ### ğŸ¯ í•™ìŠµ ëª©í‘œ
        - Diffusion ëª¨ë¸ì˜ ì›ë¦¬ ì´í•´
        - Stable Diffusion íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ íŒŒì•…
        - VAEì™€ ì ì¬ ê³µê°„ì˜ ì—­í•  ì´í•´
        - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²• ìŠµë“
        """)

        st.markdown('---')

        # 1. ìƒì„± ëª¨ë¸ ê°œë¡ 
        st.subheader('ğŸŒŸ 1. ìƒì„± ëª¨ë¸ì˜ ë°œì „')

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **ìƒì„± ëª¨ë¸ íƒ€ì„ë¼ì¸**
            ```
            GAN (2014)
              â†“
            VAE (2013-2016)
              â†“
            Diffusion Models (2020)
              â†“
            Stable Diffusion (2022)
            ```
            """)

        with col2:
            st.markdown("""
            | ëª¨ë¸ | ì¥ì  | ë‹¨ì  |
            |------|------|------|
            | **GAN** | ë¹ ë¥¸ ìƒì„± | í•™ìŠµ ë¶ˆì•ˆì • |
            | **VAE** | ì•ˆì •ì  í•™ìŠµ | íë¦¿í•œ ê²°ê³¼ |
            | **Diffusion** | ê³ í’ˆì§ˆ | ëŠë¦° ìƒì„± |
            """)

        st.markdown('---')

        # 2. Diffusion ëª¨ë¸ ì›ë¦¬
        st.subheader('ğŸ”¬ 2. Diffusion ëª¨ë¸ì˜ ì›ë¦¬')

        st.markdown("""
        **Forward Process (ìˆœë°©í–¥ ê³¼ì •)**
        ```
        ì›ë³¸ ì´ë¯¸ì§€ â†’ ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ ... â†’ ìˆœìˆ˜ ë…¸ì´ì¦ˆ
        xâ‚€          xâ‚              ...   xâ‚œ
        ```

        **Reverse Process (ì—­ë°©í–¥ ê³¼ì •)**
        ```
        ìˆœìˆ˜ ë…¸ì´ì¦ˆ â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ... â†’ ì›ë³¸ ì´ë¯¸ì§€
        xâ‚œ           xâ‚œâ‚‹â‚            ...   xâ‚€
        ```

        **í•™ìŠµ ëª©í‘œ**: ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹ ê²½ë§ í•™ìŠµ
        """)

        with st.expander('ğŸ“– ìˆ˜ì‹ ì„¤ëª…'):
            st.latex(r'q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)')
            st.latex(r'L = \mathbb{E}[||\epsilon - \epsilon_\theta(x_t, t)||^2]')
            st.caption('ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì†ì‹¤ í•¨ìˆ˜')

        st.markdown('---')

        # 3. Stable Diffusion ì•„í‚¤í…ì²˜
        st.subheader('ğŸ—ï¸ 3. Stable Diffusion ì•„í‚¤í…ì²˜')

        st.markdown("""
        **ì „ì²´ íŒŒì´í”„ë¼ì¸**
        ```
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            â†“
        CLIP Text Encoder â†’ Text Embeddings
                             â†“
        ëœë¤ ë…¸ì´ì¦ˆ â†’ U-Net (ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡) â†’ ì ì¬ í‘œí˜„
                             â†‘
                        Time Step
                             â†“
                        VAE Decoder â†’ ìµœì¢… ì´ë¯¸ì§€
        ```
        """)

        # 3.1 VAE
        with st.expander('ğŸ’¡ VAE (Variational Autoencoder)'):
            st.markdown("""
            **ëª©ì **: ê³ ì°¨ì› ì´ë¯¸ì§€ â†’ ì €ì°¨ì› ì ì¬ ê³µê°„

            - **Encoder**: 512Ã—512 ì´ë¯¸ì§€ â†’ 64Ã—64 ì ì¬ í‘œí˜„ (8ë°° ì••ì¶•)
            - **Decoder**: 64Ã—64 ì ì¬ í‘œí˜„ â†’ 512Ã—512 ì´ë¯¸ì§€

            **ì¥ì **:
            - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (64ë°° ê°ì†Œ)
            - ë¹ ë¥¸ ìƒ˜í”Œë§
            - ê³ í’ˆì§ˆ ì¬êµ¬ì„±
            """)

        # 3.2 CLIP Text Encoder
        with st.expander('ğŸ’¡ CLIP Text Encoder'):
            st.markdown("""
            **ëª©ì **: í…ìŠ¤íŠ¸ â†’ ì˜ë¯¸ ë²¡í„°

            ```
            "A beautiful sunset" â†’ [0.23, -0.45, 0.67, ...]
                                   (77 í† í° Ã— 768 ì°¨ì›)
            ```

            - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì¼í•œ ì˜ë¯¸ ê³µê°„ìœ¼ë¡œ ë§¤í•‘
            - Cross-Attentionì„ í†µí•´ U-Netê³¼ ì—°ê²°
            """)

        # 3.3 U-Net
        with st.expander('ğŸ’¡ U-Net'):
            st.markdown("""
            **êµ¬ì¡°**:
            ```
                Input (64Ã—64)
                     â†“
               Encoder (DownBlock)
                32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8
                     â†“
               Middle Block
                     â†“
               Decoder (UpBlock)
                8Ã—8 â†’ 16Ã—16 â†’ 32Ã—32
                     â†“
                Output (64Ã—64)
            ```

            **Cross-Attention**:
            - Query: ì´ë¯¸ì§€ íŠ¹ì§• (U-Net)
            - Key/Value: í…ìŠ¤íŠ¸ ì„ë² ë”© (CLIP)
            - â†’ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •ë ¬
            """)

        st.markdown('---')

        # 4. ìŠ¤ì¼€ì¤„ëŸ¬
        st.subheader('â±ï¸ 4. ìƒ˜í”Œë§ ìŠ¤ì¼€ì¤„ëŸ¬')

        scheduler_cols = st.columns(4)

        with scheduler_cols[0]:
            st.markdown("""
            **DDIM**
            - ë¹ ë¥¸ ìƒ˜í”Œë§
            - 20-50 ìŠ¤í…
            - ì¬í˜„ ê°€ëŠ¥
            """)

        with scheduler_cols[1]:
            st.markdown("""
            **DPM-Solver++**
            - í’ˆì§ˆ/ì†ë„ ê· í˜•
            - 20-30 ìŠ¤í…
            - ìµœì‹  ê¸°ë³¸ê°’
            """)

        with scheduler_cols[2]:
            st.markdown("""
            **Euler**
            - ìƒ¤í”„í•œ ë””í…Œì¼
            - 20-40 ìŠ¤í…
            - ì•ˆì •ì 
            """)

        with scheduler_cols[3]:
            st.markdown("""
            **Euler A**
            - ì°½ì˜ì  ê²°ê³¼
            - 30-40 ìŠ¤í…
            - ì‹¤í—˜ì 
            """)

        st.markdown('---')

        # 5. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
        st.subheader('âœï¸ 5. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§')

        st.markdown("""
        **íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°**
        ```
        [ì£¼ì²´] + [ìŠ¤íƒ€ì¼] + [ì¡°ëª…] + [êµ¬ë„] + [í’ˆì§ˆ í† í°]
        ```

        **ì˜ˆì‹œ**:
        ```
        Portrait of a wise old wizard,        â† ì£¼ì²´
        fantasy art style,                    â† ìŠ¤íƒ€ì¼
        cinematic lighting,                   â† ì¡°ëª…
        close-up shot,                        â† êµ¬ë„
        ultra-detailed, 8k, sharp focus       â† í’ˆì§ˆ í† í°
        ```
        """)

        prompt_cols = st.columns(2)

        with prompt_cols[0]:
            st.markdown("""
            **ìŠ¤íƒ€ì¼ í† í°**
            - `oil painting`
            - `digital art`
            - `photorealistic`
            - `cinematic lighting`
            - `8k resolution`
            """)

        with prompt_cols[1]:
            st.markdown("""
            **ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸**
            - `low quality`
            - `blurry`
            - `artifacts`
            - `deformed hands`
            - `bad anatomy`
            """)

        st.markdown('---')

        # 6. ì£¼ìš” íŒŒë¼ë¯¸í„°
        st.subheader('ğŸšï¸ 6. ì£¼ìš” íŒŒë¼ë¯¸í„°')

        param_cols = st.columns(3)

        with param_cols[0]:
            st.markdown("""
            **CFG Scale**
            - 1-5: ì°½ì˜ì 
            - 7-9: ê· í˜• (ê¶Œì¥)
            - 10-15: ì¶©ì‹¤, ê³¼í¬í™”
            """)

        with param_cols[1]:
            st.markdown("""
            **Inference Steps**
            - 10-20: ë¹ ë¦„, í’ˆì§ˆ ì €í•˜
            - 25-35: ê· í˜• (ê¶Œì¥)
            - 40-50: ëŠë¦¼, ë¯¸ë¯¸í•œ ê°œì„ 
            """)

        with param_cols[2]:
            st.markdown("""
            **Seed**
            - ë™ì¼ ì‹œë“œ = ì¬í˜„ ê°€ëŠ¥
            - ë‹¤ë¥¸ ì‹œë“œ = ë‹¤ë¥¸ ê²°ê³¼
            - ì‹¤í—˜: ì‹œë“œ ê³ ì • í›„ ë¹„êµ
            """)

        st.markdown('---')

        # 7. ControlNet
        st.subheader('ğŸ§© 7. ControlNet')

        st.markdown("""
        **ëª©ì **: ì¶”ê°€ ì¡°ê±´ ì‹ í˜¸ë¡œ ìƒì„± ê³¼ì • ì œì–´

        ```
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ + ì¡°ê±´ ì´ë¯¸ì§€ â†’ êµ¬ë„ê°€ ì œì–´ëœ ê²°ê³¼
        ```
        """)

        controlnet_cols = st.columns(4)

        with controlnet_cols[0]:
            st.markdown("""
            **Canny Edge**
            - ìœ¤ê³½ì„  ê¸°ë°˜
            - ëª…í™•í•œ í˜•íƒœ
            - ìŠ¤ì¼€ì¹˜ â†’ ì´ë¯¸ì§€
            """)

        with controlnet_cols[1]:
            st.markdown("""
            **OpenPose**
            - í¬ì¦ˆ ê¸°ë°˜
            - ì¸ì²´ ìì„¸ ì œì–´
            - ìºë¦­í„° ìƒì„±
            """)

        with controlnet_cols[2]:
            st.markdown("""
            **Depth**
            - ê¹Šì´ ì •ë³´
            - 3D êµ¬ì¡° ë³´ì¡´
            - ê³µê°„ê° ì œì–´
            """)

        with controlnet_cols[3]:
            st.markdown("""
            **Scribble**
            - ë‚™ì„œ ê¸°ë°˜
            - ë¹ ë¥¸ ìŠ¤ì¼€ì¹˜
            - ììœ ë¡œìš´ í‘œí˜„
            """)

        st.markdown('---')

        # 8. LoRA
        st.subheader('ğŸ¨ 8. ê²½ëŸ‰ ë¯¸ì„¸íŠœë‹ (LoRA)')

        st.markdown("""
        **LoRA (Low-Rank Adaptation)**

        - **ì „ì²´ ëª¨ë¸**: 4GB
        - **LoRA ê°€ì¤‘ì¹˜**: 10-100MB (400ë°° ì‘ìŒ)

        **ì¥ì **:
        - ë¹ ë¥¸ í•™ìŠµ
        - ë‚®ì€ ë©”ëª¨ë¦¬ ìš”êµ¬
        - ì—¬ëŸ¬ LoRA ì¡°í•© ê°€ëŠ¥
        - ìŠ¤íƒ€ì¼ ë¯¸ì„¸ ì¡°ì •
        """)

        st.markdown('---')

        # 9. ì•ˆì „ ë° ìœ¤ë¦¬
        st.subheader('ğŸ›¡ï¸ 9. ì•ˆì „ ë° ìœ¤ë¦¬')

        safety_cols = st.columns(2)

        with safety_cols[0]:
            st.success("""
            **í—ˆìš©ë˜ëŠ” ì‚¬ìš©**
            - âœ… í•™ìŠµ ëª©ì 
            - âœ… ê°œì¸ í”„ë¡œì íŠ¸
            - âœ… ì—°êµ¬ ë° ì‹¤í—˜
            - âœ… ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬
            """)

        with safety_cols[1]:
            st.error("""
            **ì£¼ì˜ì‚¬í•­**
            - âš ï¸ ìƒì—…ì  ì‚¬ìš© ì‹œ ë¼ì´ì„ ìŠ¤ í™•ì¸
            - âŒ ì €ì‘ê¶Œ ì¹¨í•´ ì´ë¯¸ì§€ ìƒì„± ê¸ˆì§€
            - âŒ ìœ í•´ ì½˜í…ì¸  ìƒì„± ê¸ˆì§€
            - âŒ ë”¥í˜ì´í¬ ì•…ìš© ë°©ì§€
            """)

        st.markdown('---')

        # 10. ì‹¤ìŠµ í™˜ê²½
        st.subheader('ğŸ’» 10. ì‹¤ìŠµ í™˜ê²½')

        env_cols = st.columns(2)

        with env_cols[0]:
            st.markdown("""
            **Google Colab (ê¶Œì¥)**
            - GPU: T4 (ë¬´ë£Œ)
            - ëŸ°íƒ€ì„ ìœ í˜•: GPU
            - ì„¤ì¹˜:
            ```bash
            pip install -q diffusers transformers accelerate torch --upgrade
            ```
            """)

        with env_cols[1]:
            st.markdown("""
            **ë¡œì»¬ í™˜ê²½**
            - GPU: 4GB VRAM ì´ìƒ ê¶Œì¥
            - RAM: 8GB ì´ìƒ
            - ì €ì¥ ê³µê°„: 10GB ì´ìƒ
            - Python 3.8+
            """)

        st.info("""
        ğŸ’¡ **íŒ**: GPUê°€ ì—†ìœ¼ë©´ CPUë¡œë„ ë™ì‘í•˜ì§€ë§Œ ë§¤ìš° ëŠë¦½ë‹ˆë‹¤.
        ì‹¤ìŠµì€ Google Colabì˜ ë¬´ë£Œ GPU ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        """)

    def _ensure_diffusers(self) -> bool:
        try:
            import diffusers  # noqa: F401
            import torch  # noqa: F401
            return True
        except Exception:
            st.warning('âš ï¸ diffusers/torch íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. Colab ë˜ëŠ” ë¡œì»¬ì—ì„œ ì„¤ì¹˜í•˜ì„¸ìš”: `pip install diffusers transformers accelerate torch --upgrade`')
            return False

    def _check_environment(self) -> Dict[str, bool]:
        status: Dict[str, bool] = {}
        try:
            import diffusers  # noqa: F401
            status['diffusers'] = True
        except Exception:
            status['diffusers'] = False
        try:
            import torch  # noqa: F401
            status['torch'] = True
        except Exception:
            status['torch'] = False
        try:
            import transformers  # noqa: F401
            status['transformers'] = True
        except Exception:
            status['transformers'] = False
        try:
            import accelerate  # noqa: F401
            status['accelerate'] = True
        except Exception:
            status['accelerate'] = False
        return status

    def _display_environment_status(self):
        status = self._check_environment()
        cols = st.columns(4)
        with cols[0]:
            st.success('âœ… diffusers') if status.get('diffusers') else st.warning('âš ï¸ diffusers ë¯¸ì„¤ì¹˜')
        with cols[1]:
            st.success('âœ… torch') if status.get('torch') else st.warning('âš ï¸ torch ë¯¸ì„¤ì¹˜')
        with cols[2]:
            st.success('âœ… transformers') if status.get('transformers') else st.warning('âš ï¸ transformers ë¯¸ì„¤ì¹˜')
        with cols[3]:
            st.success('âœ… accelerate') if status.get('accelerate') else st.warning('âš ï¸ accelerate ë¯¸ì„¤ì¹˜')

    def render_method(self):
        st.header('ğŸ› ï¸ ë°©ë²• (Colab/ë¡œì»¬)')
        st.markdown(
            """
            **Colab(ê¶Œì¥)**
            1) ëŸ°íƒ€ì„: GPU(T4)
            2) ì„¤ì¹˜:
            ```bash
            pip install -q diffusers transformers accelerate torch --upgrade
            ```
            3) ëª¨ë¸: `runwayml/stable-diffusion-v1-5`

            **ë¡œì»¬(ì´ venv)**
            - `venv` í™œì„±í™” í›„ ë™ì¼ ì„¤ì¹˜
            - GPUê°€ ì—†ìœ¼ë©´ CPUë¡œ ë™ì‘(ëŠë¦´ ìˆ˜ ìˆìŒ)
            """
        )

    def render_diffusers_demo(self):
        st.header('ğŸ§ª Diffusers ë°ëª¨ (CPU/GPU í™˜ê²½ í•„ìš”)')
        st.info('Colabì—ì„œ ì‹¤í–‰ ê¶Œì¥. ë¡œì»¬ë„ ê°€ëŠ¥(venv)')

        if not self._ensure_diffusers():
            return

        model_id = st.selectbox('ëª¨ë¸ ì„ íƒ', [
            'runwayml/stable-diffusion-v1-5',
            'stabilityai/sd-turbo'
        ], index=0, help='ë™ì¼ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ìœ„ì£¼')

        scheduler_name = st.selectbox('ìŠ¤ì¼€ì¤„ëŸ¬', [
            'DPMSolverMultistep',
            'DDIM',
            'Euler',
            'EulerAncestral'
        ], index=0)

        cols = st.columns(2)
        with cols[0]:
            steps = st.slider('Inference Steps', 5, 50, 25)
            guidance = st.slider('CFG Scale', 1.0, 12.0, 7.0)
            seed = st.number_input('Seed', min_value=0, max_value=2**31 - 1, value=42)
        with cols[1]:
            width = st.selectbox('Width', [512, 640, 768], index=0)
            height = st.selectbox('Height', [512, 640, 768], index=0)

        prompt = st.text_area('í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸', 'A high quality portrait photo of a friendly teacher, studio lighting')
        negative = st.text_input('ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)', 'low quality, blurry, artifacts')

        if st.button('ğŸš€ ì´ë¯¸ì§€ ìƒì„±', type='primary', use_container_width=True):
            with st.spinner('Stable Diffusionìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„± ì¤‘...'):
                try:
                    import torch
                    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, DDIMScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler

                    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)

                    if scheduler_name == 'DPMSolverMultistep':
                        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
                    elif scheduler_name == 'DDIM':
                        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
                    elif scheduler_name == 'Euler':
                        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
                    elif scheduler_name == 'EulerAncestral':
                        pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
                    if torch.cuda.is_available():
                        pipe = pipe.to('cuda')

                    generator = torch.Generator(device='cuda' if torch.cuda.is_available() else 'cpu').manual_seed(int(seed))
                    image = pipe(
                        prompt,
                        negative_prompt=negative or None,
                        num_inference_steps=int(steps),
                        guidance_scale=float(guidance),
                        generator=generator,
                        height=int(height),
                        width=int(width),
                    ).images[0]

                    st.image(image, caption='Generated Image', use_container_width=True)
                    buf = io.BytesIO()
                    image.save(buf, format='PNG')
                    st.download_button('ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (PNG)', buf.getvalue(), file_name='generated.png', mime='image/png', use_container_width=True)
                except Exception as e:
                    st.error(f'ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}')

    def render_prompt_lab(self):
        st.header('âœï¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‹¤ìŠµ')

        st.markdown("""
        ### ğŸ¯ í•™ìŠµ ëª©í‘œ
        - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ì´í•´
        - ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ì˜ ì˜í–¥ íŒŒì•…
        - ìŠ¤íƒ€ì¼ í† í° í™œìš©ë²• ìµíˆê¸°
        """)

        st.markdown('---')

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ
        st.subheader('ğŸ“ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ')

        comp_cols = st.columns(5)

        with comp_cols[0]:
            st.markdown("""
            **1. ì£¼ì²´**
            - portrait
            - landscape
            - character
            - object
            """)

        with comp_cols[1]:
            st.markdown("""
            **2. ìŠ¤íƒ€ì¼**
            - photorealistic
            - oil painting
            - digital art
            - anime
            """)

        with comp_cols[2]:
            st.markdown("""
            **3. ì¡°ëª…**
            - cinematic
            - studio
            - natural
            - dramatic
            """)

        with comp_cols[3]:
            st.markdown("""
            **4. êµ¬ë„**
            - close-up
            - wide shot
            - portrait
            - panoramic
            """)

        with comp_cols[4]:
            st.markdown("""
            **5. í’ˆì§ˆ**
            - 8k
            - detailed
            - sharp focus
            - high quality
            """)

        st.markdown('---')

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        st.subheader('ğŸ¨ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿')

        template_tabs = st.tabs(['ì¸ë¬¼ ì‚¬ì§„', 'í’ê²½', 'ì»¨ì…‰ ì•„íŠ¸', 'ì¼ëŸ¬ìŠ¤íŠ¸'])

        with template_tabs[0]:
            st.code("""
Portrait of {subject},
{style} photography,
{lighting} lighting,
{composition} shot,
ultra-detailed, 8k, sharp focus,
professional photography

ì˜ˆì‹œ:
Portrait of a wise old wizard,
cinematic photography,
dramatic lighting with rim light,
close-up shot,
ultra-detailed, 8k, sharp focus,
professional photography
            """, language='text')

        with template_tabs[1]:
            st.code("""
{subject} landscape,
{time_of_day},
{weather} weather,
{style} style,
{composition},
ultra-detailed, 8k resolution

ì˜ˆì‹œ:
Mountain valley landscape,
golden hour sunset,
clear weather with volumetric lighting,
photorealistic style,
wide panoramic shot,
ultra-detailed, 8k resolution
            """, language='text')

        with template_tabs[2]:
            st.code("""
{subject} concept art,
{art_style},
{mood} atmosphere,
trending on artstation,
highly detailed,
digital painting

ì˜ˆì‹œ:
Futuristic city concept art,
sci-fi cyberpunk style,
neon-lit atmospheric mood,
trending on artstation,
highly detailed architectural design,
digital painting
            """, language='text')

        with template_tabs[3]:
            st.code("""
{subject} illustration,
{art_style} art style,
{color_palette},
{detail_level},
digital art

ì˜ˆì‹œ:
Cute cat character illustration,
anime art style,
vibrant pastel colors,
highly detailed with soft shading,
digital art
            """, language='text')

        st.markdown('---')

        # ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
        st.subheader('ğŸš« ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸')

        neg_cols = st.columns(3)

        with neg_cols[0]:
            st.markdown("""
            **ì¼ë°˜ì ì¸ í’ˆì§ˆ ë¬¸ì œ**
            ```
            low quality, blurry, pixelated,
            artifacts, jpeg compression,
            noise, grainy, distorted
            ```
            """)

        with neg_cols[1]:
            st.markdown("""
            **ì¸ë¬¼/í•´ë¶€í•™ì  ë¬¸ì œ**
            ```
            deformed hands, extra fingers,
            bad anatomy, poorly drawn face,
            mutation, malformed limbs,
            extra limbs, ugly
            ```
            """)

        with neg_cols[2]:
            st.markdown("""
            **êµ¬ë„/ìŠ¤íƒ€ì¼ ë¬¸ì œ**
            ```
            cropped, out of frame,
            watermark, text, logo,
            duplicate, cloned face,
            cartoon (if not wanted)
            ```
            """)

        st.markdown('---')

        # Google Colab ì½”ë“œ
        st.subheader('ğŸ’» Google Colab ì‹¤ìŠµ ì½”ë“œ')

        st.info('ğŸ”— **ê¶Œì¥**: ì•„ë˜ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬í•˜ì—¬ ë¬´ë£Œ GPUë¡œ ì‹¤í–‰í•˜ì„¸ìš”!')

        with st.expander('ğŸ“‹ ì „ì²´ Colab ì½”ë“œ ë³´ê¸°'):
            st.code("""
# ========================================
# Week 9: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‹¤ìŠµ
# Google Colabì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”!
# ========================================

# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install -q diffusers transformers accelerate torch

# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import matplotlib.pyplot as plt

# 3. ëª¨ë¸ ë¡œë“œ
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompts = {
    "realistic": '''
        Portrait of a wise old wizard,
        cinematic photography,
        dramatic lighting with rim light,
        close-up shot,
        ultra-detailed, 8k, sharp focus,
        professional photography
    ''',

    "artistic": '''
        Portrait of a wise old wizard,
        oil painting style,
        soft warm lighting,
        classical composition,
        highly detailed brushwork,
        masterpiece
    ''',

    "fantasy": '''
        Portrait of a wise old wizard,
        fantasy art style,
        magical glowing effects,
        mystical atmosphere,
        trending on artstation,
        digital painting
    '''
}

# 5. ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
negative_prompt = '''
    low quality, blurry, artifacts,
    deformed hands, bad anatomy,
    poorly drawn face, ugly,
    watermark, text
'''

# 6. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
def generate_image(prompt, negative, seed=42):
    generator = torch.Generator("cuda").manual_seed(seed)

    image = pipe(
        prompt=prompt,
        negative_prompt=negative,
        num_inference_steps=30,
        guidance_scale=7.5,
        generator=generator,
        height=512,
        width=512
    ).images[0]

    return image

# 7. ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ ë¹„êµ
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for idx, (style, prompt) in enumerate(prompts.items()):
    print(f"\\nìƒì„± ì¤‘: {style}...")
    image = generate_image(prompt, negative_prompt)

    axes[idx].imshow(image)
    axes[idx].set_title(f"{style.upper()}", fontsize=14)
    axes[idx].axis('off')

plt.tight_layout()
plt.savefig('prompt_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\\nâœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
print("ğŸ“ ì €ì¥ ìœ„ì¹˜: prompt_comparison.png")

# 8. ì‹¤í—˜: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ íš¨ê³¼ ë¹„êµ
print("\\nì‹¤í—˜: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ íš¨ê³¼...")

fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# ë„¤ê±°í‹°ë¸Œ ì—†ìŒ
image_no_neg = generate_image(prompts["realistic"], "", seed=42)
axes[0].imshow(image_no_neg)
axes[0].set_title("ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì—†ìŒ")
axes[0].axis('off')

# ë„¤ê±°í‹°ë¸Œ ìˆìŒ
image_with_neg = generate_image(prompts["realistic"], negative_prompt, seed=42)
axes[1].imshow(image_with_neg)
axes[1].set_title("ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì ìš©")
axes[1].axis('off')

plt.tight_layout()
plt.savefig('negative_prompt_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\\nâœ… ë¹„êµ ì™„ë£Œ!")
            """, language='python')

        st.markdown('---')

        # ì‹¤ìŠµ ê³¼ì œ
        st.subheader('ğŸ“ ì‹¤ìŠµ ê³¼ì œ')

        st.warning("""
        **ê³¼ì œ**: íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ê°œë°œ

        1. **3ê°€ì§€ ìŠ¤íƒ€ì¼ ë¹„êµ**
           - Realistic, Artistic, Fantasy ìŠ¤íƒ€ì¼ë¡œ ë™ì¼ ì£¼ì œ ìƒì„±
           - ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)

        2. **ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ íš¨ê³¼ ì¸¡ì •**
           - ë™ì¼ í”„ë¡¬í”„íŠ¸ì— ë„¤ê±°í‹°ë¸Œ ìˆìŒ/ì—†ìŒ ë¹„êµ
           - í’ˆì§ˆ ê°œì„  ì •ë„ ë¶„ì„

        3. **í”„ë¡¬í”„íŠ¸ ìµœì í™”**
           - 5ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë³€í˜• í…ŒìŠ¤íŠ¸
           - ìµœì  ì¡°í•© ë¬¸ì„œí™”

        **ì œì¶œë¬¼**: ìƒì„± ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸ + ë¶„ì„ ë³´ê³ ì„œ
        """)

    def render_scheduler_lab(self):
        st.header('â±ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ì‹¤ìŠµ')

        st.markdown("""
        ### ğŸ¯ í•™ìŠµ ëª©í‘œ
        - ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ íŠ¹ì„± ì´í•´
        - ìŠ¤ì¼€ì¤„ëŸ¬ë³„ í’ˆì§ˆê³¼ ì†ë„ ë¹„êµ
        - ìš©ë„ì— ë§ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ ì„ íƒí•˜ê¸°
        """)

        st.markdown('---')

        # ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµí‘œ
        st.subheader('ğŸ“Š ìŠ¤ì¼€ì¤„ëŸ¬ íŠ¹ì„± ë¹„êµ')

        import pandas as pd
        scheduler_data = pd.DataFrame({
            'ìŠ¤ì¼€ì¤„ëŸ¬': ['DDPM', 'DDIM', 'DPM-Solver++', 'Euler', 'Euler Ancestral'],
            'ê¶Œì¥ ìŠ¤í…': ['1000', '20-50', '20-30', '20-40', '30-40'],
            'ì†ë„': ['ë§¤ìš° ëŠë¦¼', 'ë¹ ë¦„', 'ë§¤ìš° ë¹ ë¦„', 'ë¹ ë¦„', 'ì¤‘ê°„'],
            'í’ˆì§ˆ': ['ìµœê³ ', 'ë†’ìŒ', 'ë§¤ìš° ë†’ìŒ', 'ë†’ìŒ', 'ë†’ìŒ'],
            'ì¬í˜„ì„±': ['âœ…', 'âœ…', 'âœ…', 'âœ…', 'âŒ (í™•ë¥ ì )'],
            'íŠ¹ì§•': ['ì›ë³¸, ë§ì€ ìŠ¤í…', 'ì ì€ ìŠ¤í… ìµœì í™”', 'ìµœì‹  ê¸°ë³¸ê°’', 'ìƒ¤í”„í•œ ë””í…Œì¼', 'ì°½ì˜ì  ë³€í™”']
        })
        st.dataframe(scheduler_data, use_container_width=True, hide_index=True)

        st.markdown('---')

        # ìŠ¤ì¼€ì¤„ëŸ¬ë³„ ìƒì„¸ ì„¤ëª…
        st.subheader('ğŸ”¬ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„¸ ì„¤ëª…')

        sched_tabs = st.tabs(['DDIM', 'DPM-Solver++', 'Euler', 'Euler Ancestral'])

        with sched_tabs[0]:
            st.markdown("""
            ### DDIM (Denoising Diffusion Implicit Models)

            **íŠ¹ì§•**:
            - ì ì€ ìŠ¤í…ì—ì„œë„ ë†’ì€ í’ˆì§ˆ
            - ê²°ì •ë¡ ì  (deterministic) ìƒ˜í”Œë§
            - ë¹ ë¥¸ ì¶”ë¡  ì†ë„

            **ì¥ì **:
            - 20-50 ìŠ¤í…ìœ¼ë¡œ ì¶©ë¶„
            - ë™ì¼ ì‹œë“œë¡œ ì¬í˜„ ê°€ëŠ¥
            - ì•ˆì •ì ì¸ ê²°ê³¼

            **ë‹¨ì **:
            - DDPMë³´ë‹¤ëŠ” í’ˆì§ˆì´ ì•½ê°„ ë‚®ìŒ
            - ë§¤ìš° ì ì€ ìŠ¤í…(<20)ì—ì„œëŠ” ì•„í‹°íŒ©íŠ¸ ë°œìƒ

            **ì¶”ì²œ ìš©ë„**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ì‹¤ì‹œê°„ ìƒì„±
            """)

        with sched_tabs[1]:
            st.markdown("""
            ### DPM-Solver++ (ìµœì‹  ê¸°ë³¸ê°’)

            **íŠ¹ì§•**:
            - ODE ì†”ë²„ ê¸°ë°˜
            - í’ˆì§ˆê³¼ ì†ë„ì˜ ìµœì  ê· í˜•
            - Stable Diffusionì˜ ê¸°ë³¸ ìŠ¤ì¼€ì¤„ëŸ¬

            **ì¥ì **:
            - 20-30 ìŠ¤í…ìœ¼ë¡œ ìµœê³  í’ˆì§ˆ
            - ë§¤ìš° ë¹ ë¥¸ ìˆ˜ë ´
            - ë‹¤ì–‘í•œ ëª¨ë¸ì—ì„œ ì•ˆì •ì 

            **ë‹¨ì **:
            - íŠ¹ì • ìŠ¤íƒ€ì¼ì—ì„œëŠ” ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë” ë‚˜ì„ ìˆ˜ ìˆìŒ

            **ì¶”ì²œ ìš©ë„**: ì¼ë°˜ì ì¸ ëª¨ë“  ìš©ë„, í”„ë¡œë•ì…˜ í™˜ê²½
            """)

        with sched_tabs[2]:
            st.markdown("""
            ### Euler

            **íŠ¹ì§•**:
            - ì˜¤ì¼ëŸ¬ ë°©ë²• ê¸°ë°˜
            - ìƒ¤í”„í•˜ê³  ì„ ëª…í•œ ë””í…Œì¼
            - ë‹¨ìˆœí•˜ê³  íš¨ìœ¨ì 

            **ì¥ì **:
            - ë¹ ë¥¸ ìˆ˜ë ´
            - ìƒ¤í”„í•œ ê²°ê³¼
            - êµ¬í˜„ì´ ë‹¨ìˆœ

            **ë‹¨ì **:
            - ë•Œë¡œëŠ” ê³¼ë„í•˜ê²Œ ìƒ¤í”„í•  ìˆ˜ ìˆìŒ
            - íŠ¹ì • ìŠ¤íƒ€ì¼ì— í¸í–¥ ê°€ëŠ¥

            **ì¶”ì²œ ìš©ë„**: ì„ ëª…í•œ ë””í…Œì¼ì´ ì¤‘ìš”í•œ ê²½ìš°
            """)

        with sched_tabs[3]:
            st.markdown("""
            ### Euler Ancestral (í™•ë¥ ì )

            **íŠ¹ì§•**:
            - í™•ë¥ ì  (stochastic) ìƒ˜í”Œë§
            - ë§¤ ìŠ¤í…ë§ˆë‹¤ ë…¸ì´ì¦ˆ ì¶”ê°€
            - ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ê²°ê³¼

            **ì¥ì **:
            - ë†’ì€ ë‹¤ì–‘ì„±
            - ì°½ì˜ì ì¸ ë³€í™”
            - ì˜ˆìƒì¹˜ ëª»í•œ ì¢‹ì€ ê²°ê³¼

            **ë‹¨ì **:
            - ì¬í˜„ ë¶ˆê°€ (ë™ì¼ ì‹œë“œë„ ë‹¤ë¥¸ ê²°ê³¼)
            - ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
            - ë” ë§ì€ ìŠ¤í… í•„ìš”

            **ì¶”ì²œ ìš©ë„**: ì‹¤í—˜ì  ìƒì„±, ë‹¤ì–‘ì„±ì´ ì¤‘ìš”í•œ ê²½ìš°
            """)

        st.markdown('---')

        # Google Colab ì½”ë“œ
        st.subheader('ğŸ’» Google Colab ì‹¤ìŠµ ì½”ë“œ')

        st.info('ğŸ”— **ê¶Œì¥**: ì•„ë˜ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬í•˜ì—¬ ë¬´ë£Œ GPUë¡œ ì‹¤í–‰í•˜ì„¸ìš”!')

        with st.expander('ğŸ“‹ ì „ì²´ Colab ì½”ë“œ ë³´ê¸°'):
            st.code("""
# ========================================
# Week 9: ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ì‹¤ìŠµ
# Google Colabì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”!
# ========================================

# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install -q diffusers transformers accelerate torch

# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
from diffusers import (
    StableDiffusionPipeline,
    DDIMScheduler,
    DPMSolverMultistepScheduler,
    EulerDiscreteScheduler,
    EulerAncestralDiscreteScheduler
)
from PIL import Image
import matplotlib.pyplot as plt
import time

# 3. ëª¨ë¸ ë¡œë“œ
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# 4. í”„ë¡¬í”„íŠ¸ ì„¤ì •
prompt = '''
A serene mountain landscape at sunset,
golden hour lighting,
photorealistic style,
ultra-detailed, 8k resolution
'''

negative_prompt = '''
low quality, blurry, artifacts,
distorted, ugly
'''

# 5. ìŠ¤ì¼€ì¤„ëŸ¬ ë”•ì…”ë„ˆë¦¬
schedulers = {
    'DDIM': DDIMScheduler.from_config(pipe.scheduler.config),
    'DPM-Solver++': DPMSolverMultistepScheduler.from_config(pipe.scheduler.config),
    'Euler': EulerDiscreteScheduler.from_config(pipe.scheduler.config),
    'Euler A': EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
}

# 6. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
def generate_with_scheduler(scheduler_name, scheduler, steps=25):
    pipe.scheduler = scheduler
    generator = torch.Generator("cuda").manual_seed(42)

    start_time = time.time()

    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        num_inference_steps=steps,
        guidance_scale=7.5,
        generator=generator,
        height=512,
        width=512
    ).images[0]

    elapsed_time = time.time() - start_time

    return image, elapsed_time

# 7. ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ì‹¤í—˜
print("ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ì‹¤í—˜ ì‹œì‘...")
print("=" * 50)

results = {}
fig, axes = plt.subplots(2, 2, figsize=(12, 12))
axes = axes.flatten()

for idx, (name, scheduler) in enumerate(schedulers.items()):
    print(f"\\n{idx+1}. {name} ìƒì„± ì¤‘...")

    image, elapsed = generate_with_scheduler(name, scheduler)
    results[name] = {'image': image, 'time': elapsed}

    # ì‹œê°í™”
    axes[idx].imshow(image)
    axes[idx].set_title(f"{name}\\nìƒì„± ì‹œê°„: {elapsed:.2f}ì´ˆ", fontsize=12)
    axes[idx].axis('off')

    print(f"âœ… {name}: {elapsed:.2f}ì´ˆ")

plt.tight_layout()
plt.savefig('scheduler_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\\n" + "=" * 50)
print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ì™„ë£Œ!")
print("ğŸ“ ì €ì¥ ìœ„ì¹˜: scheduler_comparison.png")

# 8. ê²°ê³¼ ìš”ì•½
print("\\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
for name, result in results.items():
    print(f"  - {name:15s}: {result['time']:.2f}ì´ˆ")

# 9. ìŠ¤í… ìˆ˜ì— ë”°ë¥¸ ë¹„êµ (ì˜µì…˜)
print("\\n\\nì‹¤í—˜: ìŠ¤í… ìˆ˜ ì˜í–¥ ë¶„ì„...")
print("=" * 50)

steps_to_test = [15, 25, 35]
scheduler_to_test = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for idx, steps in enumerate(steps_to_test):
    print(f"\\n{steps} ìŠ¤í… ìƒì„± ì¤‘...")
    image, elapsed = generate_with_scheduler("DPM-Solver++", scheduler_to_test, steps)

    axes[idx].imshow(image)
    axes[idx].set_title(f"{steps} Steps\\n{elapsed:.2f}ì´ˆ", fontsize=12)
    axes[idx].axis('off')

plt.tight_layout()
plt.savefig('steps_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\\nâœ… ìŠ¤í… ë¹„êµ ì™„ë£Œ!")
            """, language='python')

        st.markdown('---')

        # ì‹¤ìŠµ ê°€ì´ë“œ
        st.subheader('ğŸ“ ì‹¤ìŠµ ê°€ì´ë“œ')

        guide_cols = st.columns(2)

        with guide_cols[0]:
            st.success("""
            **ì‹¤ìŠµ 1: ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ**

            1. ë™ì¼ í”„ë¡¬í”„íŠ¸/ì‹œë“œ ì‚¬ìš©
            2. 4ê°€ì§€ ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ìƒì„±
            3. í’ˆì§ˆê³¼ ì†ë„ ë¹„êµ
            4. ìŠ¤í¬ë¦°ìƒ· ì €ì¥

            **ë¹„êµ í•­ëª©**:
            - ë””í…Œì¼ ì„ ëª…ë„
            - ìƒ‰ê° ë° ëŒ€ë¹„
            - ìƒì„± ì‹œê°„
            - ì „ì²´ì ì¸ í’ˆì§ˆ
            """)

        with guide_cols[1]:
            st.success("""
            **ì‹¤ìŠµ 2: ìŠ¤í… ìˆ˜ ì˜í–¥**

            1. í•˜ë‚˜ì˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì„ íƒ
            2. 15, 25, 35 ìŠ¤í…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
            3. í’ˆì§ˆ ê°œì„  ì •ë„ ì¸¡ì •
            4. ìµœì  ìŠ¤í… ìˆ˜ ê²°ì •

            **ë¶„ì„ í•­ëª©**:
            - ìŠ¤í…ë³„ í’ˆì§ˆ ì°¨ì´
            - ì‹œê°„ ëŒ€ë¹„ í’ˆì§ˆ íš¨ìœ¨
            - ìµœì†Œ í•„ìš” ìŠ¤í… ìˆ˜
            """)

        st.warning("""
        **ê³¼ì œ**: ìŠ¤ì¼€ì¤„ëŸ¬ ìµœì í™” ë³´ê³ ì„œ

        1. **4ê°€ì§€ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ** (ë™ì¼ ì¡°ê±´)
        2. **ìŠ¤í… ìˆ˜ ìµœì í™”** (15/25/35 ìŠ¤í…)
        3. **ìš©ë„ë³„ ì¶”ì²œ** (ì†ë„ ìš°ì„  vs í’ˆì§ˆ ìš°ì„ )

        **ì œì¶œë¬¼**: ë¹„êµ ì´ë¯¸ì§€ + ì‹œê°„ ì¸¡ì • + ì¶”ì²œ ê°€ì´ë“œ
        """)

    def render_controlnet_lab(self):
        st.header('ğŸ§© ControlNet ì‹¤ìŠµ')

        st.markdown("""
        ### ğŸ¯ í•™ìŠµ ëª©í‘œ
        - ControlNetì˜ ì›ë¦¬ì™€ í™œìš©ë²• ì´í•´
        - ë‹¤ì–‘í•œ ì¡°ê±´ ì‹ í˜¸ í™œìš©í•˜ê¸°
        - êµ¬ë„ë¥¼ ì œì–´í•œ ì´ë¯¸ì§€ ìƒì„±
        """)

        st.markdown('---')

        # ControlNet íƒ€ì… ë¹„êµ
        st.subheader('ğŸ¨ ControlNet íƒ€ì…')

        cn_cols = st.columns(4)

        with cn_cols[0]:
            st.markdown("""
            **Canny Edge**
            - ìœ¤ê³½ì„  ê¸°ë°˜
            - ëª…í™•í•œ í˜•íƒœ
            - ìŠ¤ì¼€ì¹˜ â†’ ì´ë¯¸ì§€
            """)

        with cn_cols[1]:
            st.markdown("""
            **OpenPose**
            - í¬ì¦ˆ ê¸°ë°˜
            - ì¸ì²´ ìì„¸ ì œì–´
            - ìºë¦­í„° ìƒì„±
            """)

        with cn_cols[2]:
            st.markdown("""
            **Depth**
            - ê¹Šì´ ì •ë³´
            - 3D êµ¬ì¡° ë³´ì¡´
            - ê³µê°„ê° ì œì–´
            """)

        with cn_cols[3]:
            st.markdown("""
            **Scribble**
            - ë‚™ì„œ ê¸°ë°˜
            - ë¹ ë¥¸ ìŠ¤ì¼€ì¹˜
            - ììœ ë¡œìš´ í‘œí˜„
            """)

        st.markdown('---')

        # Google Colab ì½”ë“œ
        st.subheader('ğŸ’» Google Colab ì‹¤ìŠµ ì½”ë“œ')

        st.info('ğŸ”— **ê¶Œì¥**: ì•„ë˜ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”!')

        with st.expander('ğŸ“‹ Colab ì½”ë“œ: Canny Edge ControlNet'):
            st.code("""
# Week 9: ControlNet ì‹¤ìŠµ (Canny Edge)

!pip install -q diffusers transformers accelerate torch opencv-python

import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from PIL import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt

# 1. ControlNet ëª¨ë¸ ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# 2. ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ Canny edge ì¶”ì¶œ
def get_canny_edge(image, low_threshold=100, high_threshold=200):
    image_np = np.array(image)
    if len(image_np.shape) == 3:
        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)

    edges = cv2.Canny(image_np, low_threshold, high_threshold)
    edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

    return Image.fromarray(edges)

# 3. ìƒ˜í”Œ ì´ë¯¸ì§€ ë¡œë“œ (URL ë˜ëŠ” ë¡œì»¬ íŒŒì¼)
from urllib.request import urlopen
url = "https://huggingface.co/lllyasviel/sd-controlnet-canny/resolve/main/images/bird.png"
image = Image.open(urlopen(url))

# Canny edge ì¶”ì¶œ
canny_image = get_canny_edge(image)

# 4. ControlNetìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
prompt = "a beautiful bird, digital art style, colorful, detailed"
negative_prompt = "low quality, blurry, ugly"

output = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    image=canny_image,
    num_inference_steps=30,
    guidance_scale=7.5,
    controlnet_conditioning_scale=1.0
).images[0]

# 5. ê²°ê³¼ ì‹œê°í™”
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(image)
axes[0].set_title("Original")
axes[0].axis('off')

axes[1].imshow(canny_image)
axes[1].set_title("Canny Edge")
axes[1].axis('off')

axes[2].imshow(output)
axes[2].set_title("ControlNet Output")
axes[2].axis('off')

plt.tight_layout()
plt.savefig('controlnet_result.png', dpi=300)
plt.show()

print("âœ… ControlNet ìƒì„± ì™„ë£Œ!")
            """, language='python')

        st.markdown('---')

        st.warning("""
        **ì‹¤ìŠµ ê³¼ì œ**: ControlNetìœ¼ë¡œ êµ¬ë„ ì œì–´

        1. **Canny Edge ì‹¤í—˜**: ì…ë ¥ ì´ë¯¸ì§€ì˜ ìœ¤ê³½ì„  ì¶”ì¶œ ë° ìƒì„±
        2. **ì¡°ê±´ ê°•ë„ ì¡°ì ˆ**: `controlnet_conditioning_scale` 0.5, 1.0, 1.5 ë¹„êµ
        3. **ìŠ¤íƒ€ì¼ ë³€ê²½**: ë™ì¼ êµ¬ë„ì— ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì ìš©

        **ì œì¶œë¬¼**: ì…ë ¥ ì´ë¯¸ì§€ + Canny edge + ìƒì„± ê²°ê³¼ 3ê°€ì§€
        """)

    def render_comfyui_guide(self):
        st.header('ğŸ—ºï¸ ComfyUI ì›Œí¬í”Œë¡œìš° ê°€ì´ë“œ')

        st.markdown("""
        ### ğŸ¯ í•™ìŠµ ëª©í‘œ
        - ComfyUIì˜ ë…¸ë“œ ì‹œìŠ¤í…œ ì´í•´
        - ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        - ì¬í˜„ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ ë§Œë“¤ê¸°
        """)

        st.markdown('---')

        # ComfyUI ì¥ì 
        st.subheader('âœ¨ ComfyUI ì¥ì ')

        adv_cols = st.columns(4)

        with adv_cols[0]:
            st.markdown("""
            **ğŸ”§ ì‹œê°ì  í¸ì§‘**
            - ë…¸ë“œ ê¸°ë°˜
            - ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤
            - ë“œë˜ê·¸ & ë“œë¡­
            """)

        with adv_cols[1]:
            st.markdown("""
            **ğŸ”„ ì¬í˜„ì„±**
            - ì›Œí¬í”Œë¡œìš° ì €ì¥
            - JSON ê³µìœ 
            - ë²„ì „ ê´€ë¦¬
            """)

        with adv_cols[2]:
            st.markdown("""
            **ğŸ¯ ìœ ì—°ì„±**
            - ë³µì¡í•œ íŒŒì´í”„ë¼ì¸
            - ì»¤ìŠ¤í…€ ë…¸ë“œ
            - ëª¨ë“ˆì‹ êµ¬ì„±
            """)

        with adv_cols[3]:
            st.markdown("""
            **ğŸ“Š í˜‘ì—…**
            - íŒ€ ê³µìœ 
            - í‘œì¤€í™”
            - ë¬¸ì„œí™” ìš©ì´
            """)

        st.markdown('---')

        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°
        st.subheader('ğŸ”¨ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°')

        st.code("""
[Load Checkpoint]
     â†“
[CLIP Text Encode (Positive)]
     â†“
[CLIP Text Encode (Negative)]
     â†“
[Empty Latent Image]
     â†“
[KSampler]
     â†“
[VAE Decode]
     â†“
[Save Image]
        """, language='text')

        st.markdown('---')

        # ì„¤ì¹˜ ê°€ì´ë“œ
        st.subheader('ğŸ’» ComfyUI ì„¤ì¹˜')

        install_tabs = st.tabs(['Windows', 'Mac/Linux', 'Google Colab'])

        with install_tabs[0]:
            st.code("""
# Windows ì„¤ì¹˜

# 1. Git í´ë¡ 
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI

# 2. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
venv\\Scripts\\activate

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 4. ì‹¤í–‰
python main.py

# 5. ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
# http://127.0.0.1:8188
            """, language='bash')

        with install_tabs[1]:
            st.code("""
# Mac/Linux ì„¤ì¹˜

# 1. Git í´ë¡ 
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI

# 2. ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv
source venv/bin/activate

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 4. ì‹¤í–‰
python main.py

# 5. ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
# http://127.0.0.1:8188
            """, language='bash')

        with install_tabs[2]:
            st.code("""
# Google Colab ì„¤ì¹˜

# 1. ì„¤ì¹˜ ë° ì‹¤í–‰
!git clone https://github.com/comfyanonymous/ComfyUI.git
%cd ComfyUI
!pip install -q -r requirements.txt

# 2. Colabì—ì„œ ì‹¤í–‰ (ngrok í„°ë„)
!pip install pyngrok
from pyngrok import ngrok

# ngrok í„°ë„ ì‹œì‘
public_url = ngrok.connect(8188)
print(f"ComfyUI URL: {public_url}")

# ComfyUI ì‹¤í–‰
!python main.py --listen 0.0.0.0 --port 8188
            """, language='python')

        st.markdown('---')

        # ì‹¤ìŠµ ê°€ì´ë“œ
        st.subheader('ğŸ“ ì‹¤ìŠµ ê°€ì´ë“œ')

        st.success("""
        **ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì‹¤ìŠµ**

        **1. ëª¨ë¸ ë¡œë“œ**
        - `Load Checkpoint` ë…¸ë“œ ì¶”ê°€
        - Stable Diffusion v1.5 ì„ íƒ

        **2. í…ìŠ¤íŠ¸ ì…ë ¥**
        - `CLIP Text Encode` ë…¸ë“œ 2ê°œ (positive, negative)
        - í”„ë¡¬í”„íŠ¸ ì…ë ¥

        **3. ìƒ˜í”Œë§ ì„¤ì •**
        - `Empty Latent Image` (512x512)
        - `KSampler` (steps: 25, cfg: 7.5, seed: 42)

        **4. ì´ë¯¸ì§€ ë””ì½”ë”©**
        - `VAE Decode` ë…¸ë“œ
        - `Save Image` ë…¸ë“œ

        **5. ë…¸ë“œ ì—°ê²° ë° ì‹¤í–‰**
        - ëª¨ë“  ë…¸ë“œë¥¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°
        - Queue Prompt ë²„íŠ¼ í´ë¦­
        """)

        st.markdown('---')

        # ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°
        st.subheader('ğŸš€ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°')

        adv_workflow_tabs = st.tabs(['LoRA ì ìš©', 'ControlNet', 'ë°°ì¹˜ ìƒì„±'])

        with adv_workflow_tabs[0]:
            st.markdown("""
            **LoRA ì›Œí¬í”Œë¡œìš°**
            ```
            [Load Checkpoint]
                 â†“
            [Load LoRA]
                 â†“
            [CLIP Text Encode]
                 â†“
            [KSampler]
                 â†“
            [VAE Decode]
                 â†“
            [Save Image]
            ```

            **ì¶”ê°€ ë…¸ë“œ**:
            - `Load LoRA`: LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ
            - `LoRA Stack`: ì—¬ëŸ¬ LoRA ì¡°í•©
            """)

        with adv_workflow_tabs[1]:
            st.markdown("""
            **ControlNet ì›Œí¬í”Œë¡œìš°**
            ```
            [Load Checkpoint]
                 â†“
            [Load ControlNet Model]
                 â†“
            [Load Image] â†’ [ControlNet Preprocessor]
                 â†“
            [Apply ControlNet]
                 â†“
            [CLIP Text Encode]
                 â†“
            [KSampler]
                 â†“
            [VAE Decode]
                 â†“
            [Save Image]
            ```

            **ì£¼ìš” ë…¸ë“œ**:
            - `ControlNet Preprocessor`: ì¡°ê±´ ì‹ í˜¸ ì¶”ì¶œ
            - `Apply ControlNet`: ControlNet ì ìš©
            """)

        with adv_workflow_tabs[2]:
            st.markdown("""
            **ë°°ì¹˜ ìƒì„± ì›Œí¬í”Œë¡œìš°**
            ```
            [Load Checkpoint]
                 â†“
            [CLIP Text Encode (Multiple)]
                 â†“
            [Empty Latent Image Batch]
                 â†“
            [KSampler] (batch_size: N)
                 â†“
            [VAE Decode]
                 â†“
            [Save Image] (ê°ê° ì €ì¥)
            ```

            **íŠ¹ì§•**:
            - ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ìƒì„±
            - ë‹¤ë¥¸ ì‹œë“œ ìë™ ì ìš©
            - íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
            """)

        st.markdown('---')

        st.warning("""
        **ì‹¤ìŠµ ê³¼ì œ**: ComfyUI ì›Œí¬í”Œë¡œìš° êµ¬ì„±

        1. **ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„±**
           - Text-to-Image íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
           - ë™ì¼ ê²°ê³¼ ì¬í˜„ (ì‹œë“œ ê³ ì •)

        2. **ì›Œí¬í”Œë¡œìš° ì €ì¥ ë° ê³µìœ **
           - JSON íŒŒì¼ ì €ì¥
           - íŒ€ì›ê³¼ ê³µìœ 

        3. **3ê°€ì§€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ìƒì„±**
           - ë™ì¼ ì›Œí¬í”Œë¡œìš°
           - í”„ë¡¬í”„íŠ¸ë§Œ ë³€ê²½
           - ê²°ê³¼ ë¹„êµ

        **ì œì¶œë¬¼**: ì›Œí¬í”Œë¡œìš° JSON + ìƒì„± ì´ë¯¸ì§€ 3ì¥ + ìŠ¤í¬ë¦°ìƒ·
        """)


