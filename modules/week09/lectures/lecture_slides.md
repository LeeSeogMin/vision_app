# Week 9: ìƒì„± ëª¨ë¸ ì´ë¡  + Stable Diffusion

## ê°•ì˜ ê°œìš”

**ì£¼ì œ**: Text-to-Image ìƒì„± ëª¨ë¸ì˜ ì´ë¡ ê³¼ ì‹¤ìŠµ

**í•™ìŠµ ëª©í‘œ**:
- Diffusion ëª¨ë¸ì˜ ì›ë¦¬ ì´í•´
- Stable Diffusion íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ íŒŒì•…
- íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²• ìŠµë“
- ControlNetì„ í™œìš©í•œ ì¡°ê±´ë¶€ ìƒì„±
- ComfyUI ì›Œí¬í”Œë¡œìš° êµ¬ì„±

---

## 1. ìƒì„± ëª¨ë¸ ê°œë¡ 

### 1.1 ìƒì„± ëª¨ë¸ì˜ ë°œì „

```
GAN (2014)
  â†“
VAE (Variational Autoencoder)
  â†“
Diffusion Models (2020)
  â†“
Stable Diffusion (2022)
```

### 1.2 ì£¼ìš” ìƒì„± ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | ì¥ì  | ë‹¨ì  | ëŒ€í‘œ ì‚¬ë¡€ |
|------|------|------|-----------|
| **GAN** | ë¹ ë¥¸ ìƒì„± | í•™ìŠµ ë¶ˆì•ˆì • | StyleGAN, DALL-E 1 |
| **VAE** | ì•ˆì •ì  í•™ìŠµ | íë¦¿í•œ ê²°ê³¼ | Variational AE |
| **Diffusion** | ê³ í’ˆì§ˆ ê²°ê³¼ | ëŠë¦° ìƒì„± | Stable Diffusion, Imagen |

---

## 2. Diffusion ëª¨ë¸ì˜ ì›ë¦¬

### 2.1 Forward Process (ìˆœë°©í–¥ ê³¼ì •)

```
ì›ë³¸ ì´ë¯¸ì§€ â†’ ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ ... â†’ ìˆœìˆ˜ ë…¸ì´ì¦ˆ
xâ‚€          xâ‚              xâ‚‚              ...   xâ‚œ
```

**ìˆ˜ì‹**:
```
q(xâ‚œ | xâ‚œâ‚‹â‚) = N(xâ‚œ; âˆš(1-Î²â‚œ)xâ‚œâ‚‹â‚, Î²â‚œI)
```

### 2.2 Reverse Process (ì—­ë°©í–¥ ê³¼ì •)

```
ìˆœìˆ˜ ë…¸ì´ì¦ˆ â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ë…¸ì´ì¦ˆ ì œê±° â†’ ... â†’ ì›ë³¸ ì´ë¯¸ì§€
xâ‚œ           xâ‚œâ‚‹â‚            xâ‚œâ‚‹â‚‚            ...   xâ‚€
```

**í•™ìŠµ ëª©í‘œ**: ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹ ê²½ë§ í•™ìŠµ
```
Îµ_Î¸(xâ‚œ, t) â‰ˆ Îµ (ì‹¤ì œ ë…¸ì´ì¦ˆ)
```

### 2.3 ì†ì‹¤ í•¨ìˆ˜

```
L = E[||Îµ - Îµ_Î¸(xâ‚œ, t)||Â²]
```

---

## 3. Stable Diffusion ì•„í‚¤í…ì²˜

### 3.1 ì „ì²´ íŒŒì´í”„ë¼ì¸

```
í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
    â†“
CLIP Text Encoder â†’ Text Embeddings
                         â†“
ëœë¤ ë…¸ì´ì¦ˆ â†’ U-Net (ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡) â†’ ì ì¬ í‘œí˜„
                         â†‘
                    Time Step
                         â†“
                    VAE Decoder â†’ ìµœì¢… ì´ë¯¸ì§€
```

### 3.2 ì£¼ìš” êµ¬ì„± ìš”ì†Œ

#### 3.2.1 VAE (Variational Autoencoder)

**ëª©ì **: ê³ ì°¨ì› ì´ë¯¸ì§€ â†’ ì €ì°¨ì› ì ì¬ ê³µê°„

```
Encoder: 512Ã—512 ì´ë¯¸ì§€ â†’ 64Ã—64 ì ì¬ í‘œí˜„ (8ë°° ì••ì¶•)
Decoder: 64Ã—64 ì ì¬ í‘œí˜„ â†’ 512Ã—512 ì´ë¯¸ì§€
```

**ì¥ì **:
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (64ë°° ê°ì†Œ)
- ë¹ ë¥¸ ìƒ˜í”Œë§
- ê³ í’ˆì§ˆ ì¬êµ¬ì„±

#### 3.2.2 CLIP Text Encoder

**ëª©ì **: í…ìŠ¤íŠ¸ â†’ ì˜ë¯¸ ë²¡í„°

```
"A beautiful sunset" â†’ [0.23, -0.45, 0.67, ...]
                       (77 í† í° Ã— 768 ì°¨ì›)
```

#### 3.2.3 U-Net

**êµ¬ì¡°**:
```
    Input (64Ã—64)
         â†“
   Encoder (DownBlock)
    32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8
         â†“
   Middle Block
         â†“
   Decoder (UpBlock)
    8Ã—8 â†’ 16Ã—16 â†’ 32Ã—32
         â†“
    Output (64Ã—64)
```

**Cross-Attention**:
```
Query: ì´ë¯¸ì§€ íŠ¹ì§• (U-Net)
Key/Value: í…ìŠ¤íŠ¸ ì„ë² ë”© (CLIP)
â†’ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •ë ¬
```

---

## 4. ìƒ˜í”Œë§ ìŠ¤ì¼€ì¤„ëŸ¬

### 4.1 ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ì—­í• 

**ëª©ì **: ë…¸ì´ì¦ˆ ì œê±° ê³¼ì •ì˜ íƒ€ì„ìŠ¤í… ê´€ë¦¬

### 4.2 ì£¼ìš” ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ

#### 4.2.1 DDPM (Denoising Diffusion Probabilistic Models)

```python
# ì „í†µì  ë°©ë²•, ë§ì€ ìŠ¤í… í•„ìš”
steps = 1000  # ëŠë¦¼
quality = "High"
```

#### 4.2.2 DDIM (Denoising Diffusion Implicit Models)

```python
# ë¹ ë¥¸ ìƒ˜í”Œë§
steps = 20-50  # ë¹ ë¦„
quality = "High"
deterministic = True  # ì¬í˜„ ê°€ëŠ¥
```

#### 4.2.3 DPM-Solver++

```python
# ìµœì‹  ê¸°ë³¸ê°’
steps = 20-30
quality = "Very High"
speed = "Fast"
```

#### 4.2.4 Euler / Euler Ancestral

```python
# Euler: ì•ˆì •ì , ìƒ¤í”„
# Euler A: ì°½ì˜ì , ë³€í™” í¼
steps = 20-40
```

### 4.3 ìŠ¤ì¼€ì¤„ëŸ¬ ì„ íƒ ê°€ì´ë“œ

| ìš©ë„ | ì¶”ì²œ ìŠ¤ì¼€ì¤„ëŸ¬ | ìŠ¤í… ìˆ˜ |
|------|---------------|---------|
| ì¼ë°˜ ìƒì„± | DPM-Solver++ | 25-30 |
| ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ | DDIM | 20-25 |
| ê³ í’ˆì§ˆ | DPM-Solver++ | 40-50 |
| ì‹¤í—˜ì  | Euler Ancestral | 30-40 |

---

## 5. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

### 5.1 íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°

```
[ì£¼ì²´] + [ìŠ¤íƒ€ì¼] + [ì¡°ëª…] + [êµ¬ë„] + [í’ˆì§ˆ í† í°]
```

**ì˜ˆì‹œ**:
```
Portrait of a wise old wizard,        â† ì£¼ì²´
fantasy art style,                    â† ìŠ¤íƒ€ì¼
cinematic lighting,                   â† ì¡°ëª…
close-up shot,                        â† êµ¬ë„
ultra-detailed, 8k, sharp focus       â† í’ˆì§ˆ í† í°
```

### 5.2 ìŠ¤íƒ€ì¼ í† í°

#### ì˜ˆìˆ  ìŠ¤íƒ€ì¼
```
- "oil painting"
- "watercolor"
- "digital art"
- "concept art"
- "photorealistic"
```

#### í’ˆì§ˆ í–¥ìƒ
```
- "highly detailed"
- "ultra-detailed"
- "8k resolution"
- "sharp focus"
- "professional"
```

#### ì¡°ëª…
```
- "cinematic lighting"
- "studio lighting"
- "natural lighting"
- "dramatic lighting"
- "soft lighting"
```

### 5.3 ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸

**ëª©ì **: ì›í•˜ì§€ ì•ŠëŠ” ìš”ì†Œ ì œê±°

```python
negative_prompt = """
low quality, blurry, artifacts,
deformed hands, extra fingers,
bad anatomy, poorly drawn face,
mutation, distorted
"""
```

### 5.4 ê°€ì¤‘ì¹˜ ì¡°ì •

```python
# ê°•ì¡° (ê°€ì¤‘ì¹˜ ì¦ê°€)
"(beautiful landscape:1.3)"  # 1.3ë°° ê°•ì¡°

# ì•½í™” (ê°€ì¤‘ì¹˜ ê°ì†Œ)
"(people:0.7)"  # 0.7ë°° ì•½í™”
```

---

## 6. íŒŒë¼ë¯¸í„° ìµœì í™”

### 6.1 ì£¼ìš” íŒŒë¼ë¯¸í„°

#### 6.1.1 CFG Scale (Classifier-Free Guidance)

```python
guidance_scale = 7.5  # ê¸°ë³¸ê°’

# ë‚®ì€ ê°’ (1-5): ì°½ì˜ì , í”„ë¡¬í”„íŠ¸ ì´íƒˆ
# ì¤‘ê°„ ê°’ (7-9): ê· í˜•ì¡íŒ ê²°ê³¼
# ë†’ì€ ê°’ (10-15): í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤, ê³¼í¬í™”
```

#### 6.1.2 Inference Steps

```python
num_inference_steps = 25  # ê¸°ë³¸ê°’

# ì ì€ ìŠ¤í… (10-20): ë¹ ë¦„, í’ˆì§ˆ ì €í•˜
# ì¤‘ê°„ ìŠ¤í… (25-35): ê· í˜•
# ë§ì€ ìŠ¤í… (40-50): ëŠë¦¼, í’ˆì§ˆ í–¥ìƒ (ë¯¸ë¯¸)
```

#### 6.1.3 Seed

```python
generator = torch.Generator().manual_seed(42)
# ë™ì¼ ì‹œë“œ = ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
```

### 6.2 íŒŒë¼ë¯¸í„° ì¡°í•© ê°€ì´ë“œ

| ëª©ì  | Steps | CFG | ì¶”ì²œ ìŠ¤ì¼€ì¤„ëŸ¬ |
|------|-------|-----|---------------|
| ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ | 15-20 | 7.0 | DDIM |
| ì¼ë°˜ ìƒì„± | 25-30 | 7.5 | DPM-Solver++ |
| ê³ í’ˆì§ˆ | 40-50 | 8.0 | DPM-Solver++ |
| ì‹¤í—˜ì  | 30-40 | 6.0-9.0 | Euler A |

---

## 7. ControlNet

### 7.1 ControlNetì´ë€?

**ëª©ì **: ì¶”ê°€ ì¡°ê±´ ì‹ í˜¸ë¡œ ìƒì„± ê³¼ì • ì œì–´

```
í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ + ì¡°ê±´ ì´ë¯¸ì§€ â†’ êµ¬ë„ê°€ ì œì–´ëœ ê²°ê³¼
```

### 7.2 ì£¼ìš” ControlNet íƒ€ì…

#### 7.2.1 Canny Edge

```python
# ìœ¤ê³½ì„  ê¸°ë°˜ ì œì–´
use_case = "ìŠ¤ì¼€ì¹˜ â†’ ì´ë¯¸ì§€"
ê°•ì  = "ëª…í™•í•œ í˜•íƒœ ë³´ì¡´"
```

#### 7.2.2 OpenPose

```python
# í¬ì¦ˆ ê¸°ë°˜ ì œì–´
use_case = "ì¸ì²´ ìì„¸ ì œì–´"
ê°•ì  = "ìºë¦­í„° í¬ì¦ˆ ì •í™•ë„"
```

#### 7.2.3 Depth

```python
# ê¹Šì´ ì •ë³´ ê¸°ë°˜
use_case = "3D êµ¬ì¡° ë³´ì¡´"
ê°•ì  = "ê³µê°„ê°, ì›ê·¼ê°"
```

#### 7.2.4 Scribble

```python
# ê°„ë‹¨í•œ ë‚™ì„œ ê¸°ë°˜
use_case = "ë¹ ë¥¸ ìŠ¤ì¼€ì¹˜ â†’ ì´ë¯¸ì§€"
ê°•ì  = "ììœ ë¡œìš´ í‘œí˜„"
```

### 7.3 ControlNet ì‚¬ìš© ì˜ˆì‹œ

```python
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel

# ControlNet ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny"
)

# íŒŒì´í”„ë¼ì¸ êµ¬ì„±
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet
)

# ìƒì„±
output = pipe(
    prompt="A beautiful landscape",
    image=canny_edge_image,
    num_inference_steps=30,
    controlnet_conditioning_scale=1.0  # ì¡°ê±´ ê°•ë„
).images[0]
```

---

## 8. ê²½ëŸ‰ ë¯¸ì„¸íŠœë‹

### 8.1 LoRA (Low-Rank Adaptation)

**ëª©ì **: ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ìŠ¤íƒ€ì¼ í•™ìŠµ

```
ì „ì²´ ëª¨ë¸: 4GB
LoRA ê°€ì¤‘ì¹˜: 10-100MB (400ë°° ì‘ìŒ)
```

**ì¥ì **:
- ë¹ ë¥¸ í•™ìŠµ
- ë‚®ì€ ë©”ëª¨ë¦¬ ìš”êµ¬
- ì—¬ëŸ¬ LoRA ì¡°í•© ê°€ëŠ¥

### 8.2 LoRA ì ìš©

```python
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5"
)

# LoRA ë¡œë“œ
pipe.load_lora_weights("path/to/lora")

# ê°€ì¤‘ì¹˜ ì¡°ì •
pipe.set_lora_scale(0.8)  # 0.0-1.0
```

---

## 9. ComfyUI

### 9.1 ComfyUIë€?

**íŠ¹ì§•**:
- ğŸ”§ ë…¸ë“œ ê¸°ë°˜ ì‹œê°ì  í¸ì§‘
- ğŸ”„ ì›Œí¬í”Œë¡œìš° ì €ì¥/ê³µìœ 
- ğŸ¯ ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
- ğŸ“Š íŒ€ í˜‘ì—… ìš©ì´

### 9.2 ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°

```
[Load Checkpoint]
      â†“
[CLIP Text Encode (Positive)]
      â†“
[CLIP Text Encode (Negative)]
      â†“
[KSampler]
      â†“
[VAE Decode]
      â†“
[Save Image]
```

### 9.3 ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°

#### ControlNet + LoRA

```
[Load Checkpoint]
      â†“
[Load LoRA]
      â†“
[Load ControlNet Model]
      â†“
[Load Image] â†’ [ControlNet Preprocessor]
      â†“
[Apply ControlNet]
      â†“
[CLIP Text Encode]
      â†“
[KSampler]
      â†“
[VAE Decode]
      â†“
[Save Image]
```

---

## 10. ì•ˆì „ ë° ìœ¤ë¦¬

### 10.1 ì €ì‘ê¶Œ ê³ ë ¤ì‚¬í•­

- âœ… í•™ìŠµ ëª©ì  ì‚¬ìš©
- âœ… ê°œì¸ í”„ë¡œì íŠ¸
- âš ï¸ ìƒì—…ì  ì‚¬ìš© ì‹œ ë¼ì´ì„ ìŠ¤ í™•ì¸
- âŒ ì €ì‘ê¶Œ ì¹¨í•´ ì´ë¯¸ì§€ ìƒì„±

### 10.2 ì•ˆì „ í•„í„°

```python
# Stable Diffusionì˜ Safety Checker
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    safety_checker=safety_checker,  # ê¸°ë³¸ í™œì„±í™”
    requires_safety_checker=True
)
```

### 10.3 í¸í–¥ ë° ìœ¤ë¦¬

**ì£¼ì˜ì‚¬í•­**:
- ì„±ë³„, ì¸ì¢…, ì—°ë ¹ í¸í–¥ ì¸ì‹
- ìœ í•´ ì½˜í…ì¸  ìƒì„± ê¸ˆì§€
- í”„ë¼ì´ë²„ì‹œ ì¡´ì¤‘
- ë”¥í˜ì´í¬ ì•…ìš© ë°©ì§€

---

## 11. ì‹¤ìŠµ í™˜ê²½

### 11.1 Google Colab (ê¶Œì¥)

```python
# GPU ì„¤ì •: T4 (ë¬´ë£Œ)
# ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ GPU

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install -q diffusers transformers accelerate torch --upgrade

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 5GB)
from diffusers import StableDiffusionPipeline
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5"
)
```

### 11.2 ë¡œì»¬ í™˜ê²½

```bash
# venv í™œì„±í™”
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install diffusers transformers accelerate torch --upgrade
```

**ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**:
- GPU: 4GB VRAM ì´ìƒ ê¶Œì¥
- RAM: 8GB ì´ìƒ
- ì €ì¥ ê³µê°„: 10GB ì´ìƒ (ëª¨ë¸ í¬í•¨)

---

## 12. ì‹¤ìŠµ ê³¼ì œ

### ê³¼ì œ 1: ê¸°ë³¸ ìƒì„±

**ëª©í‘œ**: Stable Diffusionìœ¼ë¡œ 3ê°€ì§€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ìƒì„±

**ìš”êµ¬ì‚¬í•­**:
- ë™ì¼ í”„ë¡¬í”„íŠ¸
- ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ í† í° (realistic, anime, oil painting)
- íŒŒë¼ë¯¸í„° ë¹„êµ ë¶„ì„

### ê³¼ì œ 2: í”„ë¡¬í”„íŠ¸ ìµœì í™”

**ëª©í‘œ**: íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ê°œë°œ

**ìš”êµ¬ì‚¬í•­**:
- 5ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë³€í˜• í…ŒìŠ¤íŠ¸
- ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ íš¨ê³¼ ë¹„êµ
- ìµœì  ì¡°í•© ë¬¸ì„œí™”

### ê³¼ì œ 3: ControlNet ì‹¤ìŠµ

**ëª©í‘œ**: ControlNetìœ¼ë¡œ êµ¬ë„ ì œì–´

**ìš”êµ¬ì‚¬í•­**:
- Canny edge ì¶”ì¶œ
- ë™ì¼ êµ¬ë„, ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ 3ì¥
- ê²°ê³¼ ë¹„êµ ë¶„ì„

---

## 13. ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Hugging Face Diffusers](https://huggingface.co/docs/diffusers)
- [Stable Diffusion ê³µì‹ GitHub](https://github.com/Stability-AI/stablediffusion)

### ë…¼ë¬¸
- "Denoising Diffusion Probabilistic Models" (DDPM)
- "High-Resolution Image Synthesis with Latent Diffusion Models" (Stable Diffusion)
- "Adding Conditional Control to Text-to-Image Diffusion Models" (ControlNet)

### ì»¤ë®¤ë‹ˆí‹°
- [r/StableDiffusion](https://reddit.com/r/StableDiffusion)
- [Civitai](https://civitai.com) - ëª¨ë¸ ë° LoRA ê³µìœ 

---

## ìš”ì•½

### í•µì‹¬ ê°œë…
1. **Diffusion ì›ë¦¬**: ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ ë…¸ì´ì¦ˆ ì œê±° í•™ìŠµ
2. **Stable Diffusion**: VAE + U-Net + CLIP
3. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ + ë„¤ê±°í‹°ë¸Œ
4. **ìŠ¤ì¼€ì¤„ëŸ¬**: ìƒ˜í”Œë§ ê³¼ì • ìµœì í™”
5. **ControlNet**: ì¡°ê±´ë¶€ ìƒì„±
6. **LoRA**: ê²½ëŸ‰ ìŠ¤íƒ€ì¼ ë¯¸ì„¸íŠœë‹

### ë‹¤ìŒ ì£¼ ì˜ˆê³ 
**Week 10**: ì‹¤ì „ í”„ë¡œì íŠ¸ ë° ì¢…í•© ì‹¤ìŠµ
- ë©€í‹°ëª¨ë‹¬ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ
- ì „ì²´ ëª¨ë“ˆ í†µí•©
- ìµœì¢… í”„ë¡œì íŠ¸ ë°œí‘œ

---

**ì§ˆë¬¸ & í† ë¡ **

Q&A ì‹œê°„ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸ™‹â€â™‚ï¸ğŸ™‹â€â™€ï¸
