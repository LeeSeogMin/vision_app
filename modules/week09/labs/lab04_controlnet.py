"""
Lab 04: ControlNet ì‹¤ìŠµ
ì¡°ê±´ë¶€ ìƒì„±ì„ ìœ„í•œ ControlNet í™œìš©
"""

import streamlit as st


def render():
    st.subheader("Lab 04: ControlNet ì‹¤ìŠµ")
    st.markdown("""
    ### í•™ìŠµ ëª©í‘œ
    - ControlNetì˜ ì›ë¦¬ ì´í•´í•˜ê¸°
    - ë‹¤ì–‘í•œ ì¡°ê±´ ì‹ í˜¸ í™œìš©í•˜ê¸°
    - êµ¬ë„ë¥¼ ì œì–´í•œ ì´ë¯¸ì§€ ìƒì„±

    ### ControlNet íƒ€ì…
    """)

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        **Canny Edge**
        - ìœ¤ê³½ì„  ê¸°ë°˜
        - ëª…í™•í•œ í˜•íƒœ ë³´ì¡´
        - ìŠ¤ì¼€ì¹˜ â†’ ì´ë¯¸ì§€
        """)

    with col2:
        st.markdown("""
        **OpenPose**
        - í¬ì¦ˆ ê¸°ë°˜
        - ì¸ì²´ ìì„¸ ì œì–´
        - ìºë¦­í„° ìƒì„±
        """)

    with col3:
        st.markdown("""
        **Depth**
        - ê¹Šì´ ì •ë³´ ê¸°ë°˜
        - 3D êµ¬ì¡° ë³´ì¡´
        - ê³µê°„ê° ì œì–´
        """)

    st.markdown("### ì‹¤ìŠµ ì‹œë‚˜ë¦¬ì˜¤")
    st.info("""
    1. ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì¡°ê±´ ì‹ í˜¸ ì¶”ì¶œ (ì˜ˆ: Canny edge)
    2. ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    3. í”„ë¡¬í”„íŠ¸ì™€ ì¡°ê±´ ì‹ í˜¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
    4. ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
    """)

    with st.expander("ğŸ“ ì˜ˆì œ ì½”ë“œ"):
        st.code("""
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from PIL import Image
import cv2
import numpy as np

# ControlNet ëª¨ë¸ ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
).to("cuda")

# Canny edge ì¶”ì¶œ
image = Image.open("input.jpg")
image_np = np.array(image)
edges = cv2.Canny(image_np, 100, 200)
edges = Image.fromarray(edges)

# ControlNet ìƒì„±
output = pipe(
    prompt="A beautiful landscape painting",
    image=edges,
    num_inference_steps=30,
    guidance_scale=7.5
).images[0]

output.save("controlnet_output.png")
        """, language="python")
